{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "k-OWRYMLzzG0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "58699ca984314969992c99c558e3ba89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b1c8171307641c39fabd376dcce6a00",
              "IPY_MODEL_2125d4b25c9e4ec7911bf8c999977f84"
            ],
            "layout": "IPY_MODEL_8bc6416469d146bba30f025be339064d"
          }
        },
        "4b1c8171307641c39fabd376dcce6a00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13c584d4116e4d4091ad24639346a407",
            "placeholder": "​",
            "style": "IPY_MODEL_208ffca44d284f209021a10a015c1d18",
            "value": "0.137 MB of 0.137 MB uploaded\r"
          }
        },
        "2125d4b25c9e4ec7911bf8c999977f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24508b676bc9494bb3ffc54cdb189c60",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2d5f10f1c834380bbbfca7c8e1c43f2",
            "value": 1
          }
        },
        "8bc6416469d146bba30f025be339064d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13c584d4116e4d4091ad24639346a407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "208ffca44d284f209021a10a015c1d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24508b676bc9494bb3ffc54cdb189c60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2d5f10f1c834380bbbfca7c8e1c43f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c14e54a8ca94835a986347ca36c0852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a35c41f085c74ca7878fda73c7b71a12",
              "IPY_MODEL_87a1657b1fa24959a9365c892b31d4ea"
            ],
            "layout": "IPY_MODEL_62901a4c10f341f986ad769299d9d2ff"
          }
        },
        "a35c41f085c74ca7878fda73c7b71a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c39c30618834e938fde0ce6f435aafe",
            "placeholder": "​",
            "style": "IPY_MODEL_c7b0fab9806a414c97cd71741edd7fa7",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "87a1657b1fa24959a9365c892b31d4ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e92aaf5c8b664f86b736d9ea8fe1f0f2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_491ba1f556ef42898dd7638b1423812e",
            "value": 1
          }
        },
        "62901a4c10f341f986ad769299d9d2ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c39c30618834e938fde0ce6f435aafe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7b0fab9806a414c97cd71741edd7fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e92aaf5c8b664f86b736d9ea8fe1f0f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "491ba1f556ef42898dd7638b1423812e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## pip installs"
      ],
      "metadata": {
        "id": "k-OWRYMLzzG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Levenshtein\n",
        "!pip install einops\n",
        "!pip install einops_exts\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install black\n",
        "!pip install fair-esm\n",
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOlB53XWXSmW",
        "outputId": "b193aecb-f7ad-4b63-e6c3-c8f59a0db316"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Levenshtein\n",
            "  Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.8.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.25.1 rapidfuzz-3.9.6\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Collecting einops_exts\n",
            "  Downloading einops_exts-0.0.4-py3-none-any.whl.metadata (621 bytes)\n",
            "Requirement already satisfied: einops>=0.4 in /usr/local/lib/python3.10/dist-packages (from einops_exts) (0.8.0)\n",
            "Downloading einops_exts-0.0.4-py3-none-any.whl (3.9 kB)\n",
            "Installing collected packages: einops_exts\n",
            "Successfully installed einops_exts-0.0.4\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting black\n",
            "  Downloading black-24.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from black) (24.1)\n",
            "Collecting pathspec>=0.9.0 (from black)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black) (4.2.2)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black) (4.12.2)\n",
            "Downloading black-24.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: pathspec, mypy-extensions, black\n",
            "Successfully installed black-24.8.0 mypy-extensions-1.0.0 pathspec-0.12.1\n",
            "Collecting fair-esm\n",
            "  Downloading fair_esm-2.0.0-py3-none-any.whl.metadata (37 kB)\n",
            "Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fair-esm\n",
            "Successfully installed fair-esm-2.0.0\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.17.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading wandb-0.17.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.13.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataset"
      ],
      "metadata": {
        "id": "lCVCpLwsz2ZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7PkQA3ZYDcT",
        "outputId": "00e02381-e4dc-4b2e-f410-942ffb952681"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "zYIaRxvBMU0G",
        "outputId": "fc87508a-08c5-4112-ef2c-3f9a9669eef7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D.pt\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D-contact-regression.pt\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import re\n",
        "import esm\n",
        "from einops import rearrange, repeat\n",
        "import math\n",
        "import numpy as np\n",
        "from torch import einsum\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import wandb\n",
        "wandb.login()\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Programmable Biology Group/Srikar/flamingo-diffusion/data_dump/old_dat/')\n",
        "\n",
        "# ESM Model Setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "batch_converter = alphabet.get_batch_converter()\n",
        "esm_model = esm_model.to(device)\n",
        "esm_model.eval()\n",
        "for param in esm_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Data Preprocessing\n",
        "def preprocess_snp_data(file_path):\n",
        "    snp_df = pd.read_csv(file_path)\n",
        "\n",
        "    def transform_energy_scores(energy_scores):\n",
        "        transformed_scores = []\n",
        "        for score in energy_scores:\n",
        "            score = re.sub(r'[\\s\\n]+', ',', score)\n",
        "            score = re.sub(r'\\[\\s*,', '[', score)\n",
        "            score = re.sub(r'^[\\s,]+', '', score)\n",
        "            transformed_scores.append(score)\n",
        "        return transformed_scores\n",
        "\n",
        "    snp_df['energy_scores'] = transform_energy_scores(snp_df['energy_scores'])\n",
        "    snp_df['energy_scores_lengths'] = snp_df['energy_scores'].apply(\n",
        "        lambda x: x.count(',') + 1 - (1 if x.startswith(',') else 0)\n",
        "    )\n",
        "\n",
        "    snp_df['peptide_source_RCSB_lengths'] = snp_df['peptide_source_RCSB'].apply(len)\n",
        "    snp_df['protein_RCSB_lengths'] = snp_df['protein_RCSB'].apply(len)\n",
        "    snp_df['protein_derived_seq_length'] = snp_df['protein_derived_sequence'].apply(len)\n",
        "    snp_df['peptide_derived_seq_length'] = snp_df['peptide_derived_sequence'].apply(len)\n",
        "\n",
        "    return snp_df\n",
        "\n",
        "def filter_datasets(dataset):\n",
        "    return dataset[dataset['protein_RCSB'] != dataset['peptide_source_RCSB']]\n",
        "\n",
        "# Dataset Class\n",
        "class ProteinInteractionDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = dataframe\n",
        "        self.mismatched_lengths = 0\n",
        "        self.total_samples = len(dataframe)\n",
        "        self.check_lengths()\n",
        "\n",
        "    def check_lengths(self):\n",
        "        for idx in range(self.total_samples):\n",
        "            row = self.dataframe.iloc[idx]\n",
        "            peptide_seq = row['peptide_derived_sequence']\n",
        "            energy_scores = row['energy_scores']\n",
        "\n",
        "            energy_scores = re.findall(r'-?\\d+\\.?\\d*(?:e[-+]?\\d+)?', energy_scores)\n",
        "            energy_scores = [float(score) for score in energy_scores]\n",
        "\n",
        "            if len(energy_scores) != len(peptide_seq):\n",
        "                self.mismatched_lengths += 1\n",
        "\n",
        "        print(f\"Total samples: {self.total_samples}\")\n",
        "        print(f\"Mismatched lengths: {self.mismatched_lengths}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        peptide_seq = row['peptide_derived_sequence']\n",
        "        protein_seq = row['protein_derived_sequence']\n",
        "        energy_scores = row['energy_scores']\n",
        "\n",
        "        energy_scores = re.findall(r'-?\\d+\\.?\\d*(?:e[-+]?\\d+)?', energy_scores)\n",
        "        energy_scores = [float(score) for score in energy_scores]\n",
        "        energy_scores = self.one_hot_encode_energy_scores(energy_scores)\n",
        "\n",
        "        # Convert energy scores to tensor\n",
        "        energy_scores = torch.tensor(energy_scores, dtype=torch.float32)\n",
        "\n",
        "        return energy_scores, peptide_seq, protein_seq # energy scores are aligned with the peptide (we will keep peptide as protien)\n",
        "\n",
        "    @staticmethod\n",
        "    def one_hot_encode_energy_scores(scores):\n",
        "        return [1 if score <= -1 else 0 for score in scores]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load and preprocess data\n",
        "train_snp = preprocess_snp_data('training_dataset.csv')\n",
        "val_snp = preprocess_snp_data('validation_dataset.csv')\n",
        "test_snp = preprocess_snp_data('testing_dataset.csv')\n",
        "\n",
        "train_snp = filter_datasets(train_snp)\n",
        "val_snp = filter_datasets(val_snp)\n",
        "test_snp = filter_datasets(test_snp)\n",
        "\n",
        "train_snp, val_snp, test_snp = train_snp[:16], val_snp[16:24], test_snp[24:32] # subset code\n",
        "\n",
        "# Calculate max_length\n",
        "all_seqs = pd.concat([\n",
        "    train_snp['peptide_derived_sequence'], train_snp['protein_derived_sequence'],\n",
        "    val_snp['peptide_derived_sequence'], val_snp['protein_derived_sequence'],\n",
        "    test_snp['peptide_derived_sequence'], test_snp['protein_derived_sequence']\n",
        "])\n",
        "max_length = max(len(seq) for seq in all_seqs)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ProteinInteractionDataset(train_snp)\n",
        "val_dataset = ProteinInteractionDataset(val_snp)\n",
        "test_dataset = ProteinInteractionDataset(test_snp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53-ZaGmiF1Hh",
        "outputId": "44b369cb-6e09-4749-906f-912630d6cf3f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 16\n",
            "Mismatched lengths: 0\n",
            "Total samples: 8\n",
            "Mismatched lengths: 0\n",
            "Total samples: 8\n",
            "Mismatched lengths: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):  # Adjust range to view more samples\n",
        "    energy_scores, protein_seq, peptide_seq = train_dataset[i]\n",
        "    print(f\"Sample {i}:\")\n",
        "\n",
        "    # Print energy scores and their length\n",
        "    print(f\"Energy Scores: {energy_scores}\")\n",
        "    print(f\"Length of Energy Scores: {energy_scores.shape[0]}\")\n",
        "\n",
        "    # Print protein sequence and its length\n",
        "    print(f\"Protein Sequence: {protein_seq}\")\n",
        "    print(f\"Length of Protein Sequence: {len(protein_seq)}\")\n",
        "\n",
        "    # Print peptide sequence and its length\n",
        "    print(f\"Peptide Sequence: {peptide_seq}\")\n",
        "    print(f\"Length of Peptide Sequence: {len(peptide_seq)}\")\n",
        "\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk9sFe_PF5uB",
        "outputId": "133967d8-1463-41c3-b38d-cf56b4622f77"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 0:\n",
            "Energy Scores: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0.])\n",
            "Length of Energy Scores: 221\n",
            "Protein Sequence: EVQLVQSGAEVKKPGESLNISCKASGYSFTIYWIAWVRQLPGKGLEWMGIIYPGDSDTRYSPSFQGQVTISADKSISTAYLQWRSLKASDSAVYYCARGVAVDWYFDLWGRGTLVTVSSASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKRVEPKS\n",
            "Length of Protein Sequence: 221\n",
            "Peptide Sequence: QSVLTQPPSVSGAPGQRVTISCAGSSSNIGAGFDVYWYQQLPGTAPKLLIYGNNNRPSGVPDRFSGSKSGTSASLAITGLQAEDEADYYCQSSGSVLSDLYVFGTGTKVTVLGQPKAAPSVTLFPPSSEELQANKATLVCLISDFYPGAVTVAWKADSSPVKAGVETTTPSKQSNNKYAASSYLSLTPEQWKSHRSYSCQVTHEGSTVEKTVAPTE\n",
            "Length of Peptide Sequence: 216\n",
            "\n",
            "\n",
            "Sample 1:\n",
            "Energy Scores: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.])\n",
            "Length of Energy Scores: 270\n",
            "Protein Sequence: NLTCDFNDVYKLEFHPNQQTSVTKLCNLTPNVLEKVTIKCGSDKLNYNLYPPTCFEEVYASRNMMHLKKIKEFVIGSSMFMRRSLTPNKINEVSFRIPPNMMPEKPIYCFCENKKTITINGSNGNPSSKKDIINRGIVEIIIPSLNEKVKGCDFTTSESTIFSKGYSINEISQDIVCTVKAHANDLIGFKCPSNYSVEPHDCFVSAFNLSGKNENLENKLKLTNIIMDHYNNTFYSRLPSLISDNWKFFCVCSKDNEKKLVFTVEASISS\n",
            "Length of Protein Sequence: 270\n",
            "Peptide Sequence: LQESGGGLVQAGGSLRLSCAASGRTFSSYGMGWFRQAPGTEREFVAAISWSGDSTYYADSVKGRFTISIDKAKNTVYLQMNSLKPEDTAVYYCAADHALVVGGTYNYWGQGTQVTVSS\n",
            "Length of Peptide Sequence: 118\n",
            "\n",
            "\n",
            "Sample 2:\n",
            "Energy Scores: tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "Length of Energy Scores: 110\n",
            "Protein Sequence: NMFKSKHKLDFSLVSMDQRGKHILGYELVNMGGYDLVHYDDLAYVASAHQELLKTGASGMIAYRYQKKDGEWQWLQTSSRLVYKNSKPDFVICTHRQLMDEEGHDLLGKR\n",
            "Length of Protein Sequence: 110\n",
            "Peptide Sequence: TEFISRHNIEGIFTFVDHRCVATVGYQPQELLGKNIVEFCHPEDQQLLRDSFQQVVKLKGQVLSVMFRFRSKTREWLWMRTSSFTFQNPYSDEIEYIICTNTNV\n",
            "Length of Peptide Sequence: 104\n",
            "\n",
            "\n",
            "Sample 3:\n",
            "Energy Scores: tensor([1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0.])\n",
            "Length of Energy Scores: 132\n",
            "Protein Sequence: ANAFLLRPGSLRCKQCSFARIFKDARTKLFWISYSDGDQCASSPCQNGGSCKDQLQSYICFCLPAFEGRNCETHKDDQLICVNENGGCEQYCSDHTGTKRSCRCHEGYSLLADGVSCTPTVEYPCGKIPILE\n",
            "Length of Protein Sequence: 132\n",
            "Peptide Sequence: EPLYENSPEFTPYLETNLGQPTIQSFEQVGTKVNVTVEDERTLVRRNNTFLSLRDVFGKDLIYTLYYWSGKKTAKTNTNEFLIDVDKGENYCFSVQAVIPSRTVNRKSTDSPVECM\n",
            "Length of Peptide Sequence: 116\n",
            "\n",
            "\n",
            "Sample 4:\n",
            "Energy Scores: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Length of Energy Scores: 154\n",
            "Protein Sequence: SMAASRRLMKELEEIRKCGMKNFRNIQVDEANLLTWQGLIVPDNPPYDKGAFRIEINFPAEYPFKPPKITFKTKIYHPNIDEKGQVCLPVISAENWKPATKTDQVIQSLIALVNDPQPEHPLRADLAEEYSKDRKKFCKNAEEFTKKYGEKRPV\n",
            "Length of Protein Sequence: 154\n",
            "Peptide Sequence: GSEFQECAVCGWALPHNRMQALTSCECTICPDCFRQHFTIALKEKHITDMVCPACGRPDLTDDTQLLSYFSTLDIQLRESLEPDAYALFHKKLTEGVLMRD\n",
            "Length of Peptide Sequence: 101\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model"
      ],
      "metadata": {
        "id": "b5j2iJtxz8rB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from einops import reduce\n"
      ],
      "metadata": {
        "id": "Wf5YhBM3mjBy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class RefinedLatentDiffusion(nn.Module):\n",
        "    def __init__(self, esm_model, num_steps, device):\n",
        "        super().__init__()\n",
        "        self.esm_model = esm_model\n",
        "        self.num_steps = num_steps\n",
        "        self.device = device\n",
        "        self.latent_dim = esm_model.embed_dim  # Using full ESM latent space (1280)\n",
        "\n",
        "        # CLIP model\n",
        "        self.clip_model = CLIPModel(embed_dim=self.latent_dim, projection_dim=self.latent_dim)\n",
        "\n",
        "        # Refined representation\n",
        "        self.refined_representation = RefinedRepresentation(seq_len=1000)  # Adjust seq_len as needed\n",
        "\n",
        "        # ESM attention layers for self and cross attention\n",
        "        self.esm_attention_layers = nn.ModuleList([\n",
        "            self.esm_model.layers[i] for i in range(-4, 0)  # Using the last 4 layers\n",
        "        ])\n",
        "\n",
        "        # Attention modules\n",
        "        self.self_attention = SelfAttentionModule(self.esm_attention_layers)\n",
        "        self.cross_attention = CrossAttentionModule(self.esm_attention_layers)\n",
        "\n",
        "        # Define beta schedule\n",
        "        self.beta = torch.linspace(1e-4, 0.02, num_steps).to(device)\n",
        "        self.alpha = 1 - self.beta\n",
        "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
        "        self.sqrt_alpha_bar = torch.sqrt(self.alpha_bar)\n",
        "        self.sqrt_one_minus_alpha_bar = torch.sqrt(1 - self.alpha_bar)\n",
        "\n",
        "        # Add epitope projection layer\n",
        "        self.epitope_proj = nn.Sequential(\n",
        "            nn.LazyLinear(256),\n",
        "            nn.LayerNorm(256),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(512),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(1024),\n",
        "            nn.Linear(1024, 1280),\n",
        "        )\n",
        "\n",
        "        # Noise prediction network (new)\n",
        "        self.noise_prediction_network = nn.Sequential(\n",
        "            nn.Linear(self.latent_dim, 512),\n",
        "            nn.LayerNorm(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, self.latent_dim),\n",
        "            nn.LayerNorm(self.latent_dim)\n",
        "        )\n",
        "\n",
        "        # SNR-based loss weighting parameters\n",
        "        self.p2_loss_weight_k = 1\n",
        "        self.p2_loss_weight_gamma = 1\n",
        "\n",
        "    def q_sample(self, x_start, t, noise=None):\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x_start).to(self.device)\n",
        "\n",
        "        sqrt_alpha_bar = self.sqrt_alpha_bar[t][:, None, None]\n",
        "        sqrt_one_minus_alpha_bar = self.sqrt_one_minus_alpha_bar[t][:, None, None]\n",
        "\n",
        "        x_noisy = sqrt_alpha_bar * x_start + sqrt_one_minus_alpha_bar * noise\n",
        "        log_snr = torch.log(self.alpha_bar[t] / (1 - self.alpha_bar[t]))\n",
        "\n",
        "        return x_noisy, log_snr\n",
        "\n",
        "    def p_losses(self, ab_latent, ag_latent, epitope_latent, t, target_seq):\n",
        "        noise = torch.randn_like(ab_latent).to(self.device)\n",
        "        x_noisy, log_snr = self.q_sample(x_start=ab_latent, t=t, noise=noise)\n",
        "\n",
        "        # Project epitope_latent to match ab_latent dimension\n",
        "        epitope_latent = self.epitope_proj(epitope_latent)\n",
        "\n",
        "        # Apply self and cross attention\n",
        "        ag_latent = self.self_attention(ag_latent)\n",
        "        x_noisy = self.self_attention(x_noisy)\n",
        "        x_noisy, epitope_latent = self.cross_attention(x_noisy, epitope_latent)\n",
        "\n",
        "        # Predict noise using the dedicated network\n",
        "        predicted_noise = self.noise_prediction_network(x_noisy)\n",
        "\n",
        "        # Calculate diffusion loss\n",
        "        diff_losses = F.mse_loss(predicted_noise, noise, reduction='none')\n",
        "        print('diff losses noise',noise)\n",
        "        print('diff losses pred noise',predicted_noise)\n",
        "        diff_losses = reduce(diff_losses, 'b ... -> b', 'mean')\n",
        "\n",
        "        # Apply SNR-based loss weighting\n",
        "        if self.p2_loss_weight_gamma >= 0:\n",
        "            loss_weight = (self.p2_loss_weight_k + log_snr.exp()) ** -self.p2_loss_weight_gamma\n",
        "            diff_losses = diff_losses * loss_weight\n",
        "\n",
        "        diff_loss = diff_losses.mean()\n",
        "        print('diff loss', diff_loss)\n",
        "        diff_loss = torch.clamp(diff_loss, max=10.0)  # Prevent extremely large values\n",
        "        print('diff loss clipped',diff_loss)\n",
        "\n",
        "        # Calculate CLIP loss\n",
        "        ab_clip, ag_clip, clip_loss = self.clip_model(ab_latent, ag_latent)\n",
        "\n",
        "        # Calculate categorical cross-entropy loss\n",
        "        logits = self.esm_model.lm_head(x_noisy)\n",
        "        ce_loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target_seq.view(-1))\n",
        "\n",
        "        # Combine losses\n",
        "        total_loss = diff_loss + clip_loss + ce_loss\n",
        "        return total_loss, clip_loss, ce_loss, diff_loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def p_sample(self, x, ag_latent, epitope_latent, t):\n",
        "        betas_t = self.beta[t][:, None, None]\n",
        "        sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alpha_bar[t][:, None, None]\n",
        "        sqrt_recip_alphas_t = torch.sqrt(1.0 / self.alpha[t])[:, None, None]\n",
        "\n",
        "        # Project epitope_latent to match ab_latent dimension\n",
        "        epitope_latent = self.epitope_proj(epitope_latent)\n",
        "\n",
        "        # Apply self and cross attention\n",
        "        ag_latent = self.self_attention(ag_latent)  # ag<>ag self-attention\n",
        "        x = self.self_attention(x)  # ab<>ab self-attention\n",
        "        x, epitope_latent = self.cross_attention(x, epitope_latent)  # ab<>epitope and epitope<>ab cross-attention\n",
        "\n",
        "        noise_pred = x - ag_latent  # Simplified noise prediction\n",
        "\n",
        "        model_mean = sqrt_recip_alphas_t * (\n",
        "            x - betas_t * noise_pred / sqrt_one_minus_alphas_cumprod_t\n",
        "        )\n",
        "\n",
        "        if t[0] > 0:\n",
        "            noise = torch.randn_like(x).to(self.device)\n",
        "            x0_t = model_mean + torch.sqrt(betas_t) * noise\n",
        "        else:\n",
        "            x0_t = model_mean\n",
        "\n",
        "        # Dynamic thresholding (eagle and imagegen both include)\n",
        "        p = 0.995  # Set this to desired percentile (e.g., 99.5%)\n",
        "        s = torch.quantile(torch.abs(x0_t), p, dim=(1, 2), keepdim=True)\n",
        "        s = torch.maximum(s, torch.ones_like(s))\n",
        "        x0_t = torch.clip(x0_t, -s, s) / s\n",
        "\n",
        "        return x0_t\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, ag_seq, epitope_seq, num_samples=1, guidance_scale=2.0):\n",
        "        device = next(self.parameters()).device\n",
        "        batch_converter = esm_model.alphabet.get_batch_converter()\n",
        "        _, _, ag_tokens = batch_converter([(i, seq) for i, seq in enumerate(ag_seq)])\n",
        "        _, _, epitope_tokens = batch_converter([(i, seq) for i, seq in enumerate(epitope_seq)])\n",
        "        ag_tokens = ag_tokens.to(device)\n",
        "        epitope_tokens = epitope_tokens.to(device)\n",
        "\n",
        "        max_seq_length = max(ag_tokens.size(1), epitope_tokens.size(1))\n",
        "\n",
        "        ag_tokens = pad_or_truncate(ag_tokens, max_seq_length, pad_value=esm_model.alphabet.padding_idx)\n",
        "        epitope_tokens = pad_or_truncate(ag_tokens, max_seq_length, pad_value=esm_model.alphabet.padding_idx)\n",
        "\n",
        "        ag_latent = self.esm_model(ag_tokens, repr_layers=[33], return_contacts=False)[\"representations\"][33]\n",
        "        epitope_latent = self.esm_model(epitope_tokens, repr_layers=[33], return_contacts=False)[\"representations\"][33]\n",
        "\n",
        "        shape = (num_samples, ag_latent.shape[1], self.latent_dim)\n",
        "        x = torch.randn(shape, device=device)\n",
        "\n",
        "        for t in reversed(range(0, self.num_steps)):\n",
        "            t_batch = torch.full((num_samples,), t, device=device, dtype=torch.long)\n",
        "\n",
        "            # Generate both conditional and unconditional samples\n",
        "            x_cond = self.p_sample(x, ag_latent, epitope_latent, t_batch)\n",
        "            x_uncond = self.p_sample(x, torch.zeros_like(ag_latent), torch.zeros_like(epitope_latent), t_batch)\n",
        "\n",
        "            # Apply classifier-free guidance\n",
        "            x = x_uncond + guidance_scale * (x_cond - x_uncond)\n",
        "\n",
        "        # Convert latent to amino acid sequence\n",
        "        logits = self.esm_model.lm_head(x)\n",
        "        sequences = logits.argmax(dim=-1)\n",
        "        return self.esm_model.decode(sequences)\n",
        "\n",
        "class SelfAttentionModule(nn.Module):\n",
        "    def __init__(self, esm_layers):\n",
        "        super().__init__()\n",
        "        self.esm_attention_layers = esm_layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Create attention mask\n",
        "        attention_mask = torch.ones(x.shape[0], x.shape[1], dtype=torch.bool, device=x.device)\n",
        "\n",
        "        for esm_layer in self.esm_attention_layers:\n",
        "            # Transpose x to match ESM's expected format: (seq_length, batch_size, embed_dim)\n",
        "            x = x.transpose(0, 1)\n",
        "\n",
        "            # Apply self-attention\n",
        "            residual = x\n",
        "            x = esm_layer.self_attn_layer_norm(x)\n",
        "            x, _ = esm_layer.self_attn(\n",
        "                query=x,\n",
        "                key=x,\n",
        "                value=x,\n",
        "                key_padding_mask=~attention_mask,\n",
        "                need_weights=False\n",
        "            )\n",
        "            x = residual + x\n",
        "\n",
        "            # Apply feed-forward network\n",
        "            residual = x\n",
        "            x = esm_layer.final_layer_norm(x)\n",
        "            x = esm_layer.fc1(x)\n",
        "            x = F.gelu(x)\n",
        "            x = esm_layer.fc2(x)\n",
        "            x = residual + x\n",
        "\n",
        "            # Transpose x back to (batch_size, seq_length, embed_dim)\n",
        "            x = x.transpose(0, 1)\n",
        "\n",
        "        return x\n",
        "\n",
        "class CrossAttentionModule(nn.Module):\n",
        "    def __init__(self, esm_layers):\n",
        "        super().__init__()\n",
        "        self.esm_attention_layers = esm_layers\n",
        "\n",
        "    def forward(self, ab_latent, epitope_latent):\n",
        "        # Transpose to match ESM's expected format: (seq_length, batch_size, embed_dim)\n",
        "        ab_latent = ab_latent.transpose(0, 1)\n",
        "        epitope_latent = epitope_latent.transpose(0, 1)\n",
        "\n",
        "        for esm_layer in self.esm_attention_layers:\n",
        "            # Cross-attention of ab to epitope\n",
        "            ab_residual = ab_latent\n",
        "            ab_latent = esm_layer.self_attn_layer_norm(ab_latent)\n",
        "            ab_latent, _ = esm_layer.self_attn(\n",
        "                query=ab_latent,\n",
        "                key=epitope_latent,\n",
        "                value=epitope_latent,\n",
        "                need_weights=False\n",
        "            )\n",
        "            ab_latent = ab_residual + ab_latent\n",
        "\n",
        "            # Cross-attention of epitope to ab\n",
        "            epitope_residual = epitope_latent\n",
        "            epitope_latent = esm_layer.self_attn_layer_norm(epitope_latent)\n",
        "            epitope_latent, _ = esm_layer.self_attn(\n",
        "                query=epitope_latent,\n",
        "                key=ab_latent,\n",
        "                value=ab_latent,\n",
        "                need_weights=False\n",
        "            )\n",
        "            epitope_latent = epitope_residual + epitope_latent\n",
        "\n",
        "            # Apply feed-forward networks\n",
        "            ab_latent = self._apply_feed_forward(esm_layer, ab_latent)\n",
        "            epitope_latent = self._apply_feed_forward(esm_layer, epitope_latent)\n",
        "\n",
        "        # Transpose back to (batch_size, seq_length, embed_dim)\n",
        "        ab_latent = ab_latent.transpose(0, 1)\n",
        "        epitope_latent = epitope_latent.transpose(0, 1)\n",
        "        return ab_latent, epitope_latent\n",
        "\n",
        "    def _apply_feed_forward(self, esm_layer, x):\n",
        "        residual = x\n",
        "        x = esm_layer.final_layer_norm(x)\n",
        "        x = esm_layer.fc1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = esm_layer.fc2(x)\n",
        "        x = residual + x\n",
        "        return x\n",
        "\n",
        "class CLIPModel(nn.Module):\n",
        "    def __init__(self, embed_dim, projection_dim):\n",
        "        super().__init__()\n",
        "        self.ab_encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=8),\n",
        "            num_layers=3\n",
        "        )\n",
        "        self.ag_encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=8),\n",
        "            num_layers=3\n",
        "        )\n",
        "        self.project_ab = nn.Linear(embed_dim, projection_dim)\n",
        "        self.project_ag = nn.Linear(embed_dim, projection_dim)\n",
        "\n",
        "    def forward(self, ab_emb, ag_emb):\n",
        "        ab_vec = self.ab_encoder(ab_emb)\n",
        "        ag_vec = self.ag_encoder(ag_emb)\n",
        "\n",
        "        ab_embed = F.normalize(self.project_ab(ab_vec[:, 0]), dim=-1)\n",
        "        ag_embed = F.normalize(self.project_ag(ag_vec[:, 0]), dim=-1)\n",
        "\n",
        "        # Symmetrical CLIP loss\n",
        "        similarity = torch.matmul(ab_embed, ag_embed.t())\n",
        "        labels = torch.arange(similarity.size(0)).to(similarity.device)\n",
        "        loss_i = F.cross_entropy(similarity, labels)\n",
        "        loss_t = F.cross_entropy(similarity.t(), labels)\n",
        "        clip_loss = (loss_i + loss_t) / 2\n",
        "\n",
        "        return ab_embed, ag_embed, clip_loss\n",
        "\n",
        "class RefinedRepresentation(nn.Module):\n",
        "    def __init__(self, seq_len):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def forward(self, tokens, energy_scores):\n",
        "        # One-hot encoding\n",
        "        one_hot = F.one_hot(tokens, num_classes=len(esm_model.alphabet))\n",
        "        # Binary motif channel\n",
        "        motif_channel = (energy_scores <= -1).float().unsqueeze(-1)\n",
        "        # Combine representations\n",
        "        combined = torch.cat([one_hot, motif_channel], dim=-1)\n",
        "        return combined\n",
        "\n",
        "\n",
        "def pad_or_truncate(tensor, target_length, pad_value=0):\n",
        "    current_length = tensor.size(1)\n",
        "    if current_length < target_length:\n",
        "        padding = torch.full((tensor.size(0), target_length - current_length, *tensor.size()[2:]), pad_value, device=tensor.device)\n",
        "        return torch.cat([tensor, padding], dim=1)\n",
        "    else:\n",
        "        return tensor[:, :target_length]\n",
        "\n",
        "def train_clip(model, esm_model, train_loader, val_loader, optimizer, num_epochs, device):\n",
        "    wandb.init(project=\"protein_binding_clip\", entity=\"vskavi2003\")\n",
        "    wandb.config.update({\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "        \"epochs\": num_epochs,\n",
        "        \"batch_size\": train_loader.batch_size\n",
        "    })\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        for batch in tqdm(train_loader, desc=f\"CLIP Epoch {epoch+1}/{num_epochs}\"):\n",
        "            energy_scores, protein_seq, peptide_seq = batch\n",
        "            energy_scores = energy_scores.to(device)\n",
        "            protein_tokens = protein_seq.to(device)\n",
        "            peptide_tokens = peptide_seq.to(device)\n",
        "            protein_onehot = F.one_hot(protein_tokens, num_classes=len(esm_model.alphabet)).float()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                protein_embedding = esm_model(protein_tokens, repr_layers=[33], return_contacts=False)[\"representations\"][33]\n",
        "                peptide_embedding = esm_model(peptide_tokens, repr_layers=[33], return_contacts=False)[\"representations\"][33]\n",
        "\n",
        "            _, _, clip_loss = model(peptide_embedding, protein_embedding)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            clip_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += clip_loss.item()\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                energy_scores, protein_seq, peptide_seq = batch\n",
        "                energy_scores = energy_scores.to(device)\n",
        "                protein_tokens = protein_seq.to(device)\n",
        "                peptide_tokens = peptide_seq.to(device)\n",
        "                protein_onehot = F.one_hot(protein_tokens, num_classes=len(esm_model.alphabet)).float()\n",
        "\n",
        "                protein_embedding = esm_model(protein_tokens, repr_layers=[33], return_contacts=False)[\"representations\"][33]\n",
        "                peptide_embedding = esm_model(peptide_tokens, repr_layers=[33], return_contacts=False)[\"representations\"][33]\n",
        "\n",
        "                _, _, val_clip_loss = model(peptide_embedding, protein_embedding)\n",
        "                total_val_loss += val_clip_loss.item()\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch+1,\n",
        "            \"clip_train_loss\": avg_train_loss,\n",
        "            \"clip_val_loss\": avg_val_loss\n",
        "        })\n",
        "\n",
        "        print(f\"CLIP Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "def validate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_diff_loss = 0\n",
        "    total_clip_loss = 0\n",
        "    total_ce_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            energy_scores, protein_seq, peptide_seq = batch\n",
        "            energy_scores = energy_scores.to(device)\n",
        "            protein_tokens = protein_seq.to(device)\n",
        "            peptide_tokens = peptide_seq.to(device)\n",
        "            protein_onehot = F.one_hot(protein_tokens, num_classes=len(model.esm_model.alphabet)).float()\n",
        "\n",
        "            protein_embedding = esm_model(protein_tokens, repr_layers=[33], return_contacts=False)[\"representations\"][33]\n",
        "            peptide_embedding = esm_model(peptide_tokens, repr_layers=[33], return_contacts=False)[\"representations\"][33]\n",
        "\n",
        "            epitope_latent = model.refined_representation(protein_tokens, (energy_scores <= -1).float())\n",
        "\n",
        "            t = torch.randint(0, model.num_steps, (protein_embedding.shape[0],), device=device).long()\n",
        "            loss, clip_loss, ce_loss, diff_loss = model.p_losses(peptide_embedding, protein_embedding, epitope_latent, t, peptide_tokens)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_clip_loss += clip_loss.item()\n",
        "            total_ce_loss += ce_loss.item()\n",
        "            total_diff_loss += (loss - clip_loss - ce_loss).item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    avg_diff_loss = total_diff_loss / len(dataloader)\n",
        "    avg_clip_loss = total_clip_loss / len(dataloader)\n",
        "    avg_ce_loss = total_ce_loss / len(dataloader)\n",
        "\n",
        "    return avg_loss, avg_diff_loss, avg_clip_loss, avg_ce_loss\n",
        "\n",
        "def train(model, train_loader, val_loader, optimizer, num_epochs, device):\n",
        "    wandb.init(project=\"protein_binding_diffusion\", entity=\"vskavi2003\")\n",
        "    wandb.config.update({\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "        \"epochs\": num_epochs,\n",
        "        \"batch_size\": train_loader.batch_size\n",
        "    })\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        total_train_diff_loss = 0\n",
        "        total_train_clip_loss = 0\n",
        "        total_train_ce_loss = 0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            energy_scores, protein_seq, peptide_seq = batch\n",
        "            energy_scores = energy_scores.to(device)\n",
        "            protein_tokens = protein_seq.to(device)\n",
        "            peptide_tokens = peptide_seq.to(device)\n",
        "\n",
        "            protein_onehot = F.one_hot(protein_tokens, num_classes=len(model.esm_model.alphabet)).float()\n",
        "\n",
        "            protein_embedding = esm_model(protein_tokens, repr_layers=[33], return_contacts=False)[\"representations\"][33]\n",
        "            peptide_embedding = esm_model(peptide_tokens, repr_layers=[33], return_contacts=False)[\"representations\"][33]\n",
        "\n",
        "            epitope_latent = model.refined_representation(protein_tokens, (energy_scores <= -1).float())\n",
        "\n",
        "            # Implement classifier-free guidance\n",
        "            if random.random() < 0.1:  # 10% of the time, remove antigen conditioning\n",
        "                protein_embedding = torch.zeros_like(protein_embedding)\n",
        "                epitope_latent = torch.zeros_like(epitope_latent)\n",
        "\n",
        "            t = torch.randint(0, model.num_steps, (protein_embedding.shape[0],), device=device).long()\n",
        "            loss, clip_loss, ce_loss, diff_loss = model.p_losses(peptide_embedding, protein_embedding, epitope_latent, t, peptide_tokens)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "            total_train_clip_loss += clip_loss.item()\n",
        "            total_train_ce_loss += ce_loss.item()\n",
        "            total_train_diff_loss += (loss - clip_loss - ce_loss).item()\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        avg_train_diff_loss = total_train_diff_loss / len(train_loader)\n",
        "        avg_train_clip_loss = total_train_clip_loss / len(train_loader)\n",
        "        avg_train_ce_loss = total_train_ce_loss / len(train_loader)\n",
        "\n",
        "        val_loss, val_diff_loss, val_clip_loss, val_ce_loss = validate(model, val_loader, device)\n",
        "\n",
        "        train_losses.append(avg_train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch+1,\n",
        "            \"train_loss\": avg_train_loss,\n",
        "            \"train_diff_loss\": avg_train_diff_loss,\n",
        "            \"train_clip_loss\": avg_train_clip_loss,\n",
        "            \"train_ce_loss\": avg_train_ce_loss,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_diff_loss\": val_diff_loss,\n",
        "            \"val_clip_loss\": val_clip_loss,\n",
        "            \"val_ce_loss\": val_ce_loss\n",
        "        })\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "def plot_losses(train_losses, val_losses):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
        "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Losses')\n",
        "    plt.legend()\n",
        "    plt.savefig('loss_plot.png')\n",
        "    wandb.log({\"loss_plot\": wandb.Image('loss_plot.png')})\n",
        "\n",
        "def generate_random_protein_binders(model, num_samples=5, seq_length=100):\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Generate random protein sequence\n",
        "    protein_seq = ''.join(random.choice('ACDEFGHIKLMNPQRSTVWY') for _ in range(seq_length))\n",
        "\n",
        "    # Generate random epitope (motif)\n",
        "    epitope_start = random.randint(0, seq_length - 10)\n",
        "    epitope_end = epitope_start + random.randint(5, 10)\n",
        "    epitope_seq = protein_seq[epitope_start:epitope_end]\n",
        "\n",
        "    # Generate binders\n",
        "    generated_binders = model.sample(protein_seq, epitope_seq, num_samples=num_samples)\n",
        "\n",
        "    return protein_seq, epitope_seq, generated_binders\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    energy_scores, protein_seqs, peptide_seqs = zip(*batch)\n",
        "    batch_converter = esm_model.alphabet.get_batch_converter()\n",
        "    _, _, protein_tokens = batch_converter([(i, seq) for i, seq in enumerate(protein_seqs)])\n",
        "    _, _, peptide_tokens = batch_converter([(i, seq) for i, seq in enumerate(peptide_seqs)])\n",
        "\n",
        "    padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
        "\n",
        "    max_seq_length = max(protein_tokens.size(1), peptide_tokens.size(1))\n",
        "\n",
        "    padded_energy_scores = torch.stack([\n",
        "        pad_or_truncate(score.unsqueeze(0), max_seq_length, pad_value=0).squeeze(0)\n",
        "        for score in padded_energy_scores\n",
        "    ])\n",
        "\n",
        "    padded_protein_tokens = pad_or_truncate(protein_tokens, max_seq_length, pad_value=esm_model.alphabet.padding_idx)\n",
        "\n",
        "    padded_peptide_tokens = pad_or_truncate(peptide_tokens, max_seq_length, pad_value=esm_model.alphabet.padding_idx)\n",
        "\n",
        "    return padded_energy_scores, padded_protein_tokens, padded_peptide_tokens\n",
        "\n",
        "def main():\n",
        "    # Load and preprocess data\n",
        "    train_snp = preprocess_snp_data('training_dataset.csv')\n",
        "    val_snp = preprocess_snp_data('validation_dataset.csv')\n",
        "    test_snp = preprocess_snp_data('testing_dataset.csv')\n",
        "\n",
        "    train_snp = filter_datasets(train_snp)\n",
        "    val_snp = filter_datasets(val_snp)\n",
        "    test_snp = filter_datasets(test_snp)\n",
        "\n",
        "    train_snp, val_snp, test_snp = train_snp[:32], val_snp[:16], test_snp[:16] # subset code\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = ProteinInteractionDataset(train_snp)\n",
        "    val_dataset = ProteinInteractionDataset(val_snp)\n",
        "    test_dataset = ProteinInteractionDataset(test_snp)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=custom_collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=4, collate_fn=custom_collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, num_workers=4, collate_fn=custom_collate_fn)\n",
        "\n",
        "    # Initialize model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    num_steps = 1000\n",
        "    model = RefinedLatentDiffusion(esm_model, num_steps, device).to(device)\n",
        "\n",
        "    # Train CLIP model\n",
        "    clip_optimizer = torch.optim.Adam(model.clip_model.parameters(), lr=1e-5)\n",
        "    train_clip(model.clip_model, esm_model, train_loader, val_loader, clip_optimizer, num_epochs=2, device=device)\n",
        "\n",
        "    # Train Latent Diffusion model\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "    train_losses, val_losses = train(model, train_loader, val_loader, optimizer, num_epochs=2, device=device)\n",
        "\n",
        "    # Plot losses\n",
        "    plot_losses(train_losses, val_losses)\n",
        "\n",
        "    # Save the trained model\n",
        "    torch.save(model.state_dict(), 'protein_binder_model.pth')\n",
        "\n",
        "    # # Generate examples\n",
        "    # print(\"Generating protein binders for random cases:\")\n",
        "    # for i in range(3):\n",
        "    #     protein_seq, epitope_seq, generated_binders = generate_random_protein_binders(model)\n",
        "    #     print(f\"\\nCase {i+1}:\")\n",
        "    #     print(f\"Protein sequence: {protein_seq}\")\n",
        "    #     print(f\"Epitope sequence: {epitope_seq}\")\n",
        "    #     print(\"Generated binders:\")\n",
        "    #     for j, binder in enumerate(generated_binders):\n",
        "    #         print(f\"Binder {j+1}: {binder}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "58699ca984314969992c99c558e3ba89",
            "4b1c8171307641c39fabd376dcce6a00",
            "2125d4b25c9e4ec7911bf8c999977f84",
            "8bc6416469d146bba30f025be339064d",
            "13c584d4116e4d4091ad24639346a407",
            "208ffca44d284f209021a10a015c1d18",
            "24508b676bc9494bb3ffc54cdb189c60",
            "b2d5f10f1c834380bbbfca7c8e1c43f2",
            "8c14e54a8ca94835a986347ca36c0852",
            "a35c41f085c74ca7878fda73c7b71a12",
            "87a1657b1fa24959a9365c892b31d4ea",
            "62901a4c10f341f986ad769299d9d2ff",
            "3c39c30618834e938fde0ce6f435aafe",
            "c7b0fab9806a414c97cd71741edd7fa7",
            "e92aaf5c8b664f86b736d9ea8fe1f0f2",
            "491ba1f556ef42898dd7638b1423812e"
          ]
        },
        "id": "HbV8-2KMz-CL",
        "outputId": "d2c5d1e4-11b5-406c-97e2-ea3ebc78a632"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 32\n",
            "Mismatched lengths: 0\n",
            "Total samples: 16\n",
            "Mismatched lengths: 0\n",
            "Total samples: 16\n",
            "Mismatched lengths: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:134bdhez) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.029 MB of 0.029 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58699ca984314969992c99c558e3ba89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁█</td></tr><tr><td>train_ce_loss</td><td>▁█</td></tr><tr><td>train_clip_loss</td><td>█▁</td></tr><tr><td>train_diff_loss</td><td>▁█</td></tr><tr><td>train_loss</td><td>▁█</td></tr><tr><td>val_ce_loss</td><td>█▁</td></tr><tr><td>val_clip_loss</td><td>█▁</td></tr><tr><td>val_diff_loss</td><td>█▁</td></tr><tr><td>val_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>train_ce_loss</td><td>4.61357</td></tr><tr><td>train_clip_loss</td><td>0.69274</td></tr><tr><td>train_diff_loss</td><td>0.94575</td></tr><tr><td>train_loss</td><td>6.25206</td></tr><tr><td>val_ce_loss</td><td>4.91685</td></tr><tr><td>val_clip_loss</td><td>0.69324</td></tr><tr><td>val_diff_loss</td><td>0.9898</td></tr><tr><td>val_loss</td><td>6.59989</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">clean-darkness-23</strong> at: <a href='https://wandb.ai/vskavi2003/protein_binding_diffusion/runs/134bdhez' target=\"_blank\">https://wandb.ai/vskavi2003/protein_binding_diffusion/runs/134bdhez</a><br/> View project at: <a href='https://wandb.ai/vskavi2003/protein_binding_diffusion' target=\"_blank\">https://wandb.ai/vskavi2003/protein_binding_diffusion</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240827_180812-134bdhez/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:134bdhez). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1EBYzKC5cdf8cu4kkYeHgWcmUZAPc6Fli/Programmable Biology Group/Srikar/flamingo-diffusion/data_dump/old_dat/wandb/run-20240827_183631-mcagxgoo</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vskavi2003/protein_binding_clip/runs/mcagxgoo' target=\"_blank\">ethereal-gorge-37</a></strong> to <a href='https://wandb.ai/vskavi2003/protein_binding_clip' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vskavi2003/protein_binding_clip' target=\"_blank\">https://wandb.ai/vskavi2003/protein_binding_clip</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vskavi2003/protein_binding_clip/runs/mcagxgoo' target=\"_blank\">https://wandb.ai/vskavi2003/protein_binding_clip/runs/mcagxgoo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCLIP Epoch 1/2:   0%|          | 0/16 [00:00<?, ?it/s]<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "CLIP Epoch 1/2: 100%|██████████| 16/16 [00:12<00:00,  1.27it/s]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLIP Epoch 1, Train Loss: 0.6929, Val Loss: 0.6932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCLIP Epoch 2/2:   0%|          | 0/16 [00:00<?, ?it/s]<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "CLIP Epoch 2/2: 100%|██████████| 16/16 [00:13<00:00,  1.18it/s]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLIP Epoch 2, Train Loss: 0.6929, Val Loss: 0.6931\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:mcagxgoo) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c14e54a8ca94835a986347ca36c0852"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>clip_train_loss</td><td>█▁</td></tr><tr><td>clip_val_loss</td><td>█▁</td></tr><tr><td>epoch</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>clip_train_loss</td><td>0.69292</td></tr><tr><td>clip_val_loss</td><td>0.69314</td></tr><tr><td>epoch</td><td>2</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ethereal-gorge-37</strong> at: <a href='https://wandb.ai/vskavi2003/protein_binding_clip/runs/mcagxgoo' target=\"_blank\">https://wandb.ai/vskavi2003/protein_binding_clip/runs/mcagxgoo</a><br/> View project at: <a href='https://wandb.ai/vskavi2003/protein_binding_clip' target=\"_blank\">https://wandb.ai/vskavi2003/protein_binding_clip</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240827_183631-mcagxgoo/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:mcagxgoo). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1EBYzKC5cdf8cu4kkYeHgWcmUZAPc6Fli/Programmable Biology Group/Srikar/flamingo-diffusion/data_dump/old_dat/wandb/run-20240827_183718-irw0aetc</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vskavi2003/protein_binding_diffusion/runs/irw0aetc' target=\"_blank\">restful-jazz-24</a></strong> to <a href='https://wandb.ai/vskavi2003/protein_binding_diffusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vskavi2003/protein_binding_diffusion' target=\"_blank\">https://wandb.ai/vskavi2003/protein_binding_diffusion</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vskavi2003/protein_binding_diffusion/runs/irw0aetc' target=\"_blank\">https://wandb.ai/vskavi2003/protein_binding_diffusion/runs/irw0aetc</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:   0%|          | 0/16 [00:00<?, ?it/s]<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise tensor([[[ 0.0732, -0.2021,  1.0232,  ...,  0.2652, -0.1121, -0.3209],\n",
            "         [ 0.1720, -0.7881,  0.3673,  ...,  1.6525,  0.9268, -0.4953],\n",
            "         [-0.1673,  1.9410,  1.8666,  ...,  1.3755,  1.3214,  0.7574],\n",
            "         ...,\n",
            "         [ 0.4280, -0.3974, -0.6015,  ...,  0.4538, -0.1635,  0.1952],\n",
            "         [ 0.5458, -0.4649, -0.0464,  ...,  1.2896, -1.0493,  0.0263],\n",
            "         [ 0.4132, -1.8092, -0.7840,  ..., -0.6751,  0.7916,  0.2907]],\n",
            "\n",
            "        [[ 1.4178, -0.8159,  1.4735,  ..., -0.9894,  0.2139, -0.2662],\n",
            "         [-0.5440, -0.2995, -0.5789,  ...,  0.6645,  0.2801,  0.2502],\n",
            "         [-0.0889,  0.1477, -0.5135,  ..., -0.3772, -0.8773,  1.3404],\n",
            "         ...,\n",
            "         [ 0.9553, -0.8378, -1.4707,  ..., -0.2191,  2.5326,  0.3141],\n",
            "         [-0.5247,  0.2365, -0.5531,  ...,  0.3488,  0.9311,  0.1401],\n",
            "         [ 2.2106,  1.0692,  1.6998,  ...,  0.0434,  0.1194,  1.3308]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[-0.1177, -0.5207,  0.4638,  ..., -0.2440,  0.2285,  0.7269],\n",
            "         [-0.1455, -0.5061,  0.6570,  ..., -0.3127,  0.3141,  0.7636],\n",
            "         [-0.0349, -0.5836,  0.6380,  ..., -0.3465,  0.1977,  0.6792],\n",
            "         ...,\n",
            "         [ 0.2887, -0.5594,  0.4488,  ..., -0.1432,  0.1238,  0.8826],\n",
            "         [ 0.1602, -0.5150,  0.5751,  ..., -0.1213,  0.0222,  0.5832],\n",
            "         [ 0.1556, -0.4807,  0.6519,  ..., -0.2967,  0.1702,  0.5021]],\n",
            "\n",
            "        [[ 0.6971, -0.6704,  0.9726,  ..., -0.3074, -0.1862, -0.7116],\n",
            "         [ 0.7396, -0.5678,  1.0523,  ..., -0.2057, -0.1016, -0.7150],\n",
            "         [ 0.9424, -0.5629,  0.9349,  ..., -0.1183, -0.1675, -0.6518],\n",
            "         ...,\n",
            "         [ 0.7716, -0.6669,  0.8448,  ...,  0.0490, -0.1555, -0.6185],\n",
            "         [ 0.6607, -0.7138,  0.9616,  ..., -0.0119, -0.1354, -0.6004],\n",
            "         [ 0.7274, -0.6886,  0.9336,  ..., -0.0331, -0.1290, -0.6233]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.3190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.3190, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:   6%|▋         | 1/16 [00:01<00:22,  1.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise tensor([[[-0.9617,  0.1894,  0.9788,  ..., -0.5152,  1.1937, -0.7792],\n",
            "         [ 1.7520,  1.6443, -1.7601,  ..., -0.4550, -0.4607, -0.2752],\n",
            "         [ 1.7549, -1.2186, -0.4896,  ..., -0.3643,  1.1238, -0.1725],\n",
            "         ...,\n",
            "         [-1.6297, -0.6906,  0.0675,  ..., -1.2601,  0.1830, -0.9362],\n",
            "         [ 1.8196,  0.7820,  0.4635,  ..., -2.0538, -1.2017, -0.6054],\n",
            "         [ 2.7779, -0.7843,  1.1315,  ...,  1.4378,  0.3681, -0.0411]],\n",
            "\n",
            "        [[ 0.7082, -0.8803, -0.2283,  ...,  0.8879, -0.5346,  0.3824],\n",
            "         [ 0.7596, -0.5101, -0.3611,  ...,  0.4532, -0.0966,  0.6514],\n",
            "         [-1.4053,  0.4568,  0.0571,  ..., -0.2204,  0.6253,  0.8026],\n",
            "         ...,\n",
            "         [ 1.8053, -0.4346, -0.5448,  ..., -0.3703,  0.6908,  1.4224],\n",
            "         [-0.1119,  0.1105, -1.5531,  ...,  0.3609,  0.6242, -0.2818],\n",
            "         [ 1.5076,  0.2723,  0.2131,  ...,  0.3240, -0.3077,  0.4216]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[-3.2047e-01, -4.6178e-01, -1.5107e-02,  ..., -2.4790e-01,\n",
            "           7.3816e-01,  1.5342e+00],\n",
            "         [-1.9598e-01, -5.5487e-01, -9.4091e-02,  ..., -1.2705e-01,\n",
            "           1.9967e-01,  1.5461e+00],\n",
            "         [-2.4380e-01, -4.3445e-01,  1.4166e-02,  ..., -1.5222e-01,\n",
            "           1.3952e-01,  1.4441e+00],\n",
            "         ...,\n",
            "         [-6.7346e-01, -2.5804e-01, -2.5062e-01,  ..., -3.9395e-02,\n",
            "           2.1098e-01,  2.1007e+00],\n",
            "         [-5.7733e-01, -5.4167e-01,  2.0063e-03,  ...,  1.0633e-01,\n",
            "           5.7594e-01,  1.7326e+00],\n",
            "         [-1.1234e+00, -3.4831e-01, -2.9219e-01,  ..., -2.6543e-01,\n",
            "           4.0696e-01,  2.2051e+00]],\n",
            "\n",
            "        [[ 6.5356e-01, -6.1427e-01,  7.4798e-01,  ..., -2.9487e-01,\n",
            "           8.1286e-03, -4.2722e-01],\n",
            "         [ 4.8958e-01, -7.7795e-01,  5.9116e-01,  ..., -2.5713e-01,\n",
            "           2.9323e-02, -3.5375e-01],\n",
            "         [ 5.0354e-01, -7.3817e-01,  6.7846e-01,  ..., -8.8766e-02,\n",
            "          -1.6047e-01, -1.4762e-01],\n",
            "         ...,\n",
            "         [ 6.1808e-01, -5.5220e-01,  7.7735e-01,  ..., -1.4602e-01,\n",
            "          -3.7489e-02, -2.5865e-01],\n",
            "         [ 7.5267e-01, -6.6277e-01,  8.6868e-01,  ..., -2.4329e-01,\n",
            "           5.4770e-02, -4.6953e-01],\n",
            "         [ 5.5187e-01, -6.8135e-01,  7.4169e-01,  ..., -2.2111e-01,\n",
            "           6.5612e-02, -1.6477e-01]]], device='cuda:0',\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.1522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.1522, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:  12%|█▎        | 2/16 [00:02<00:16,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:  19%|█▉        | 3/16 [00:03<00:12,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.1312e+00, -5.4775e-01,  1.2492e+00,  ..., -3.5457e-01,\n",
            "           3.1230e-01,  4.4374e-01],\n",
            "         [ 1.0557e+00, -1.7312e+00,  1.8027e+00,  ..., -6.9280e-01,\n",
            "          -9.5155e-01,  2.9963e-01],\n",
            "         [-6.9859e-02, -4.4744e-01,  5.0655e-01,  ..., -1.2629e+00,\n",
            "           9.9074e-01, -8.5257e-01],\n",
            "         ...,\n",
            "         [ 7.9792e-01,  7.0007e-01, -1.0463e+00,  ...,  1.5066e+00,\n",
            "           6.4399e-03,  6.0046e-01],\n",
            "         [ 2.1412e-01,  4.6378e-01, -4.4900e-01,  ...,  8.5698e-01,\n",
            "           2.3526e-01,  2.3941e-01],\n",
            "         [-9.8105e-01, -1.4752e+00,  7.4469e-01,  ..., -3.9451e-01,\n",
            "           9.5521e-01, -1.8571e+00]],\n",
            "\n",
            "        [[-5.8362e-01, -3.8479e-01, -1.0553e+00,  ..., -8.8975e-01,\n",
            "           6.8993e-01,  7.3780e-01],\n",
            "         [-9.8805e-01, -1.4208e-01, -1.0232e+00,  ..., -1.1278e+00,\n",
            "           1.1555e+00, -7.3783e-01],\n",
            "         [-8.0556e-01,  7.1352e-01, -1.9353e-01,  ..., -1.0521e-01,\n",
            "          -5.8193e-01, -1.1199e+00],\n",
            "         ...,\n",
            "         [-5.5116e-01,  1.7614e+00,  2.0191e+00,  ...,  9.2501e-02,\n",
            "           7.3410e-01,  5.2328e-01],\n",
            "         [-6.6728e-02,  4.4863e-01,  7.2639e-01,  ..., -2.5525e-03,\n",
            "          -3.4374e-01,  1.3085e+00],\n",
            "         [ 2.3526e+00,  2.9425e+00,  1.1840e+00,  ..., -4.9944e-02,\n",
            "          -3.8772e-01, -2.3280e+00]]], device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.7457, -0.4313,  0.9070,  ..., -0.1826, -0.0405, -0.6338],\n",
            "         [ 0.6649, -0.5203,  0.8579,  ..., -0.1466, -0.0533, -0.5651],\n",
            "         [ 0.6078, -0.5054,  0.7995,  ..., -0.1964, -0.0385, -0.5246],\n",
            "         ...,\n",
            "         [ 0.5351, -0.4436,  0.8923,  ...,  0.0182, -0.3203, -0.4059],\n",
            "         [ 0.5959, -0.4117,  0.9393,  ..., -0.1581, -0.2606, -0.5165],\n",
            "         [ 0.5662, -0.5077,  0.9086,  ..., -0.0597, -0.2294, -0.6369]],\n",
            "\n",
            "        [[ 0.5043, -0.7101,  0.6095,  ..., -0.0813, -0.1099, -0.4001],\n",
            "         [ 0.6367, -0.5848,  0.8874,  ..., -0.3034, -0.1855, -0.3339],\n",
            "         [ 0.6353, -0.6440,  0.8722,  ..., -0.2423, -0.0800, -0.2707],\n",
            "         ...,\n",
            "         [ 0.5253, -0.5707,  0.6072,  ..., -0.0508, -0.1128, -0.2325],\n",
            "         [ 0.5305, -0.6000,  0.5315,  ..., -0.1248, -0.0426, -0.2355],\n",
            "         [ 0.4222, -0.4309,  0.5850,  ..., -0.2566,  0.0570, -0.3584]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.2938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.2938, device='cuda:0', grad_fn=<ClampBackward1>)\n",
            "diff losses noise tensor([[[ 0.2475,  0.3670,  1.3169,  ..., -0.0368, -1.0905, -0.7116],\n",
            "         [ 1.9099, -0.9924,  1.2802,  ...,  0.6097, -1.5758, -0.2162],\n",
            "         [-1.3201,  0.7898,  0.1368,  ..., -1.8402,  2.0661,  0.6583],\n",
            "         ...,\n",
            "         [ 0.1451,  0.5055,  0.5280,  ...,  1.6381,  1.3841,  0.6273],\n",
            "         [-1.2074,  0.6573, -0.0754,  ...,  2.0998, -1.2433,  1.2982],\n",
            "         [ 0.8221,  0.5574, -0.8504,  ...,  1.4659,  0.3138,  0.7624]],\n",
            "\n",
            "        [[ 0.2990,  0.1942,  0.7683,  ...,  1.0093,  0.0393, -0.1702],\n",
            "         [ 1.1894, -0.2315,  1.4239,  ...,  0.7374,  0.2580, -0.6112],\n",
            "         [ 0.5572, -1.4786,  0.4422,  ..., -0.7066, -0.1963, -0.1112],\n",
            "         ...,\n",
            "         [ 0.8220,  0.6151,  0.6830,  ..., -0.8374,  0.8196, -1.6300],\n",
            "         [-1.4611, -0.1142,  0.3609,  ..., -0.8503, -0.5293, -0.3651],\n",
            "         [ 0.4800,  0.1312, -0.2764,  ...,  1.4458,  1.0318, -0.3172]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.6129, -0.5499,  0.8396,  ..., -0.1142, -0.3013, -0.4000],\n",
            "         [ 0.6571, -0.6335,  0.8805,  ..., -0.2221, -0.0938, -0.5021],\n",
            "         [ 0.6993, -0.7917,  0.7779,  ..., -0.2265, -0.1371, -0.5789],\n",
            "         ...,\n",
            "         [ 0.9297, -0.4604,  0.7865,  ..., -0.1000, -0.2828, -0.3409],\n",
            "         [ 1.0334, -0.4332,  0.9367,  ..., -0.1902, -0.1669, -0.4640],\n",
            "         [ 0.7002, -0.5079,  0.6681,  ..., -0.1362, -0.1338, -0.2477]],\n",
            "\n",
            "        [[ 0.6108, -0.4408,  0.6045,  ..., -0.4816,  0.2546, -0.3370],\n",
            "         [ 0.5983, -0.4814,  0.7265,  ..., -0.4070,  0.1138, -0.4362],\n",
            "         [ 0.5274, -0.5428,  0.6843,  ..., -0.5075,  0.1250, -0.3295],\n",
            "         ...,\n",
            "         [ 0.4032, -0.6840,  0.6197,  ..., -0.3101,  0.2114, -0.2245],\n",
            "         [ 0.3575, -0.6349,  0.5647,  ..., -0.3300,  0.2434, -0.0758],\n",
            "         [ 0.4553, -0.6029,  0.5618,  ..., -0.1286,  0.0027, -0.0047]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.9929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.9929, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:  25%|██▌       | 4/16 [00:04<00:11,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise tensor([[[ 0.0773, -0.6819, -0.0090,  ..., -0.3491,  0.1009,  0.7724],\n",
            "         [ 0.2199,  0.2998,  1.3403,  ..., -0.2251,  0.9847,  1.5589],\n",
            "         [ 1.2741, -0.2020, -1.5466,  ...,  1.0793,  0.3211,  0.1929],\n",
            "         ...,\n",
            "         [ 0.8301, -1.3770, -0.4269,  ..., -0.8953,  0.7762, -0.4363],\n",
            "         [-0.1214, -0.7418, -0.5604,  ..., -0.9035,  0.8098,  0.2325],\n",
            "         [-0.8546, -0.7461,  0.0395,  ...,  0.1096, -0.7162,  0.4272]],\n",
            "\n",
            "        [[-0.0082,  1.4355, -0.7875,  ...,  0.4134,  0.6936,  0.8042],\n",
            "         [-1.7088,  0.8903,  0.1037,  ..., -0.0867,  0.5686,  0.7002],\n",
            "         [ 0.6508,  2.1177, -0.3854,  ...,  0.1004, -0.2381,  1.5892],\n",
            "         ...,\n",
            "         [-1.9296, -0.9132,  1.5045,  ...,  0.1321,  1.8953, -0.8686],\n",
            "         [-0.9251,  1.2130,  0.0933,  ..., -0.3759, -2.9999, -0.7747],\n",
            "         [-1.8301, -0.1076, -0.1086,  ...,  2.0988,  1.8576,  0.8616]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 1.1706, -0.4647,  1.0369,  ...,  0.0846, -0.6046, -1.1569],\n",
            "         [ 1.2455, -0.4857,  1.1999,  ...,  0.1193, -0.3927, -1.2673],\n",
            "         [ 1.1369, -0.5372,  1.0977,  ..., -0.0975, -0.4510, -1.1633],\n",
            "         ...,\n",
            "         [ 1.2631, -0.3440,  1.1516,  ...,  0.0851, -0.5423, -1.2528],\n",
            "         [ 1.2172, -0.4953,  1.0059,  ...,  0.0641, -0.6512, -1.2294],\n",
            "         [ 1.0489, -0.5925,  0.9365,  ...,  0.0064, -0.6471, -1.0927]],\n",
            "\n",
            "        [[ 0.6713, -0.6582,  0.7905,  ..., -0.3151, -0.3230, -0.4801],\n",
            "         [ 0.5254, -0.7878,  0.7751,  ..., -0.2876, -0.3013, -0.4311],\n",
            "         [ 0.5405, -0.6446,  0.8165,  ..., -0.0958, -0.3321, -0.4864],\n",
            "         ...,\n",
            "         [ 0.6808, -0.5813,  0.7670,  ..., -0.0347, -0.3316, -0.3826],\n",
            "         [ 0.6426, -0.4480,  0.7667,  ...,  0.0132, -0.2428, -0.3524],\n",
            "         [ 0.5463, -0.4207,  0.7653,  ...,  0.1011, -0.2185, -0.3630]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.9047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.9047, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:  31%|███▏      | 5/16 [00:05<00:10,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise tensor([[[ 0.3793, -0.7284, -0.7347,  ...,  0.1815,  2.1521,  0.0962],\n",
            "         [-1.3766,  0.7418, -0.8266,  ..., -0.5365,  2.0860,  0.0850],\n",
            "         [-1.8954, -0.9957,  1.1361,  ...,  0.2895, -0.1526,  1.1812],\n",
            "         ...,\n",
            "         [-0.9193,  0.9376,  1.6172,  ...,  0.5652,  1.3195,  0.5665],\n",
            "         [-0.9986,  0.4382, -1.7421,  ..., -0.5875,  1.1265, -0.3770],\n",
            "         [-0.0214,  0.4420,  0.2893,  ...,  0.4140,  0.0426, -0.8705]],\n",
            "\n",
            "        [[ 0.0037,  0.4730,  0.3917,  ...,  2.3269,  0.1652,  0.6786],\n",
            "         [-0.4752, -0.6908,  0.2826,  ..., -0.2117, -0.6270, -1.4486],\n",
            "         [ 1.4396, -0.6823,  0.4272,  ...,  1.7040,  0.1452,  0.1937],\n",
            "         ...,\n",
            "         [ 1.2394, -1.2028, -0.3851,  ...,  0.7494, -1.7759, -1.1985],\n",
            "         [ 0.5742,  0.2562, -2.0120,  ..., -0.0379,  1.2831,  0.3470],\n",
            "         [ 0.2577, -0.1392,  0.0275,  ..., -0.1993, -0.6312,  0.4099]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.9076, -0.2965,  1.2945,  ..., -0.2096, -0.0882, -0.8653],\n",
            "         [ 0.7533, -0.1964,  1.2522,  ..., -0.1203, -0.1646, -0.8681],\n",
            "         [ 0.8346, -0.1869,  1.2096,  ..., -0.1083, -0.2128, -0.8982],\n",
            "         ...,\n",
            "         [ 0.9181, -0.1241,  1.3206,  ..., -0.1900, -0.4291, -0.8563],\n",
            "         [ 0.9002, -0.1005,  1.3459,  ..., -0.2595, -0.2436, -0.9074],\n",
            "         [ 0.9452, -0.0801,  1.3295,  ..., -0.2013, -0.3364, -0.9698]],\n",
            "\n",
            "        [[ 0.9087, -0.4648,  1.2003,  ..., -0.0669, -0.4475, -0.9095],\n",
            "         [ 0.8950, -0.2037,  1.1660,  ..., -0.1843, -0.3613, -0.9294],\n",
            "         [ 0.9118, -0.2812,  1.1492,  ..., -0.2543, -0.3302, -1.0544],\n",
            "         ...,\n",
            "         [ 0.7992, -0.4065,  1.2286,  ...,  0.0609, -0.5551, -0.8447],\n",
            "         [ 0.9364, -0.1459,  1.1829,  ...,  0.1001, -0.5197, -0.8797],\n",
            "         [ 0.8860, -0.1187,  1.2307,  ...,  0.1111, -0.5307, -0.8977]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.7038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.7038, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:  38%|███▊      | 6/16 [00:06<00:10,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise tensor([[[ 2.1170, -1.2664,  0.2866,  ...,  1.1253,  1.3840,  0.6536],\n",
            "         [ 0.0623, -0.1840, -0.4744,  ..., -0.3082, -0.2150, -0.2127],\n",
            "         [-0.4370, -0.6190, -0.3069,  ...,  1.3274, -0.3420, -0.1062],\n",
            "         ...,\n",
            "         [ 1.5951,  0.3080, -0.6914,  ..., -0.8238,  0.0380, -0.4682],\n",
            "         [ 1.4362,  1.4588, -1.1773,  ...,  0.6046, -0.6016,  1.8846],\n",
            "         [-0.0323,  1.5328,  0.2178,  ...,  0.6852, -1.3530, -0.2352]],\n",
            "\n",
            "        [[ 1.3037,  1.3117, -0.0384,  ...,  1.3304, -0.5175, -0.0477],\n",
            "         [ 1.1235, -0.8398, -0.2928,  ..., -0.8170,  0.2564, -1.3061],\n",
            "         [-2.1878, -1.1049, -1.5171,  ..., -1.4191, -0.2324,  0.7879],\n",
            "         ...,\n",
            "         [ 1.3546, -1.4800, -0.2362,  ...,  0.2037,  3.5497,  0.2887],\n",
            "         [-1.4815, -1.1414, -1.5578,  ..., -1.0953,  0.1885, -0.4094],\n",
            "         [ 1.3932, -0.5857,  1.4673,  ..., -0.5772,  0.5247, -0.7843]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.6449, -0.4884,  0.8139,  ..., -0.4702, -0.2134, -0.4110],\n",
            "         [ 0.7064, -0.3959,  0.7892,  ..., -0.3218, -0.0586, -0.4898],\n",
            "         [ 0.5035, -0.4095,  0.8025,  ..., -0.2349, -0.1878, -0.3900],\n",
            "         ...,\n",
            "         [ 0.6745, -0.4887,  0.5965,  ..., -0.2192, -0.1496, -0.2703],\n",
            "         [ 0.5117, -0.3362,  0.5960,  ...,  0.0273, -0.1072, -0.2004],\n",
            "         [ 0.6090, -0.2937,  0.8734,  ..., -0.2223, -0.1210, -0.5043]],\n",
            "\n",
            "        [[ 1.3736, -0.6024,  1.2102,  ...,  0.0387, -0.7084, -1.4052],\n",
            "         [ 1.3464, -0.6720,  1.1278,  ...,  0.0314, -0.7006, -1.3674],\n",
            "         [ 1.3937, -0.5442,  1.1052,  ...,  0.0906, -0.6935, -1.2976],\n",
            "         ...,\n",
            "         [ 1.2238, -0.4926,  1.2268,  ...,  0.0197, -0.7158, -1.0177],\n",
            "         [ 1.2469, -0.5028,  1.0544,  ...,  0.0333, -0.8018, -1.0285],\n",
            "         [ 1.0455, -0.6709,  0.9571,  ...,  0.1523, -0.8374, -1.1482]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.6875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.6875, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:  44%|████▍     | 7/16 [00:07<00:09,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise tensor([[[-1.4499, -2.4071,  0.2123,  ..., -0.2135, -0.1374, -0.1209],\n",
            "         [-0.5442,  0.0742, -1.0001,  ..., -0.4006,  0.2279, -2.0636],\n",
            "         [ 0.1900,  0.3787, -1.1652,  ..., -0.5696,  2.0029,  1.7233],\n",
            "         ...,\n",
            "         [ 0.4962,  2.0594,  2.0920,  ...,  1.1544,  0.2345,  0.1054],\n",
            "         [-0.3694,  0.3499, -0.7310,  ...,  0.4875, -1.4030, -0.6749],\n",
            "         [ 1.5916, -0.9684,  0.8044,  ..., -0.4778,  0.3371,  0.1291]],\n",
            "\n",
            "        [[ 1.0718, -0.7166,  0.4004,  ...,  0.2143, -0.7187,  1.6102],\n",
            "         [ 1.0891, -0.2393,  2.8786,  ...,  0.0596, -0.2715, -0.5696],\n",
            "         [ 1.6194, -0.3156,  0.0322,  ..., -1.3549,  0.0458, -0.0557],\n",
            "         ...,\n",
            "         [-0.1924, -1.4347,  0.2085,  ..., -0.7869, -1.2879,  0.1765],\n",
            "         [-0.5936,  0.1930,  1.5952,  ..., -1.8955, -0.8511,  0.0656],\n",
            "         [-0.0167, -0.0857,  0.1031,  ...,  0.7077, -0.7899,  1.0475]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.7765, -0.5716,  0.8383,  ..., -0.1119, -0.3973, -0.9380],\n",
            "         [ 0.7049, -0.5895,  1.0051,  ..., -0.1366, -0.5481, -0.8763],\n",
            "         [ 0.7850, -0.6258,  0.9274,  ..., -0.1385, -0.2282, -0.8712],\n",
            "         ...,\n",
            "         [ 0.9323, -0.4753,  0.9651,  ...,  0.1384, -0.6519, -0.6819],\n",
            "         [ 0.8428, -0.5858,  0.8337,  ..., -0.0222, -0.6834, -0.6595],\n",
            "         [ 0.7568, -0.5766,  0.9247,  ..., -0.1503, -0.6049, -0.7285]],\n",
            "\n",
            "        [[ 1.4947, -0.5051,  1.1647,  ..., -0.0474, -0.5679, -1.4707],\n",
            "         [ 1.3318, -0.6279,  1.2743,  ..., -0.0241, -0.5119, -1.3309],\n",
            "         [ 1.4943, -0.5513,  1.2370,  ..., -0.1019, -0.4718, -1.4725],\n",
            "         ...,\n",
            "         [ 1.3124, -0.3858,  1.2255,  ..., -0.0188, -0.7835, -1.2510],\n",
            "         [ 1.4126, -0.3928,  1.2386,  ..., -0.1142, -0.6363, -1.2986],\n",
            "         [ 1.3587, -0.5189,  1.1918,  ..., -0.1364, -0.6634, -1.3050]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.6709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.6709, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:  50%|█████     | 8/16 [00:08<00:09,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:  56%|█████▋    | 9/16 [00:09<00:07,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1.5909e+00,  3.7890e-01, -1.0446e+00,  ...,  7.2050e-01,\n",
            "          -2.2739e-02,  1.3206e+00],\n",
            "         [-1.0425e+00,  8.6197e-01, -9.1807e-01,  ...,  1.5203e+00,\n",
            "           8.3523e-01, -3.5985e-01],\n",
            "         [-2.3669e+00,  6.6233e-01, -3.4664e-01,  ..., -1.5554e+00,\n",
            "          -6.2188e-02, -3.4949e-01],\n",
            "         ...,\n",
            "         [-5.5414e-01,  6.9356e-01, -2.5339e+00,  ...,  1.3413e+00,\n",
            "           2.2266e-01, -7.2856e-02],\n",
            "         [ 1.7908e-01,  3.2036e+00, -1.4303e+00,  ..., -3.9421e-01,\n",
            "          -1.1792e+00, -6.9070e-02],\n",
            "         [-6.1539e-01, -1.1607e+00,  4.3757e-01,  ..., -2.5715e-01,\n",
            "          -1.3840e+00, -1.6126e+00]],\n",
            "\n",
            "        [[-7.8780e-01,  8.0636e-01, -7.7415e-01,  ...,  8.8090e-01,\n",
            "           9.2976e-01,  3.4487e-01],\n",
            "         [ 3.7930e-01, -8.6625e-01, -2.9679e-01,  ...,  6.8406e-01,\n",
            "           4.3653e-01,  4.0260e-01],\n",
            "         [-6.7690e-01, -1.3008e-01, -3.5919e-04,  ..., -1.1568e+00,\n",
            "           7.0394e-01,  2.0929e-01],\n",
            "         ...,\n",
            "         [ 2.1868e-01, -1.5648e+00, -1.4738e-01,  ..., -1.7712e+00,\n",
            "           5.4670e-01, -3.6276e-01],\n",
            "         [-1.4504e+00,  1.9538e+00,  6.5280e-01,  ..., -2.6540e-01,\n",
            "          -1.1676e+00,  1.8711e-01],\n",
            "         [ 8.2455e-01,  2.1296e-01,  7.4811e-01,  ..., -1.0963e-01,\n",
            "          -5.8706e-01,  3.4818e+00]]], device='cuda:0')\n",
            "diff losses pred noise tensor([[[-0.2224, -0.4557,  0.3367,  ..., -0.3694,  0.1442,  1.0079],\n",
            "         [-0.2132, -0.4372,  0.2528,  ..., -0.3511,  0.2845,  0.9735],\n",
            "         [-0.2063, -0.4451,  0.2638,  ..., -0.2190,  0.3487,  1.0272],\n",
            "         ...,\n",
            "         [-0.5595, -0.3390,  0.3951,  ..., -0.0788,  0.0635,  1.1286],\n",
            "         [-0.4729, -0.4322,  0.3827,  ..., -0.1226,  0.2405,  1.1879],\n",
            "         [-0.3310, -0.3456,  0.3414,  ..., -0.0551,  0.2337,  1.0867]],\n",
            "\n",
            "        [[ 0.8848, -0.2846,  1.1774,  ..., -0.3296, -0.4627, -0.8773],\n",
            "         [ 0.8151, -0.2126,  1.1952,  ..., -0.2668, -0.4853, -0.8471],\n",
            "         [ 0.9372, -0.3090,  1.1260,  ..., -0.3984, -0.4990, -0.9852],\n",
            "         ...,\n",
            "         [ 1.0113, -0.1753,  1.1137,  ..., -0.1567, -0.4774, -1.0848],\n",
            "         [ 0.8584, -0.1755,  1.0458,  ..., -0.0886, -0.6874, -1.0722],\n",
            "         [ 0.9472, -0.3075,  1.0655,  ..., -0.2110, -0.5978, -1.1398]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.2404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.2404, device='cuda:0', grad_fn=<ClampBackward1>)\n",
            "diff losses noise "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:  62%|██████▎   | 10/16 [00:10<00:05,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1.5510,  0.0211, -0.8153,  ...,  1.3542, -0.1889,  1.1765],\n",
            "         [-0.9619, -0.0456,  1.2585,  ..., -0.5876, -0.8954, -1.4473],\n",
            "         [ 1.0856,  0.5799,  1.6939,  ..., -0.2450, -0.1352,  1.0329],\n",
            "         ...,\n",
            "         [ 0.5492, -1.1217,  0.5455,  ...,  0.7368,  0.2405, -1.2201],\n",
            "         [-0.3791,  0.8606, -1.1420,  ..., -1.1321,  0.1516, -0.0168],\n",
            "         [ 0.3946,  0.1799, -1.6184,  ...,  0.1959, -0.1833,  3.1949]],\n",
            "\n",
            "        [[-0.3944,  1.5434, -0.2689,  ..., -0.0851,  0.3729,  0.7511],\n",
            "         [-1.3514,  1.1760, -1.9298,  ..., -0.9314, -0.1175, -0.6155],\n",
            "         [ 0.2700, -2.1133,  0.1119,  ..., -0.0496, -1.2443,  0.7569],\n",
            "         ...,\n",
            "         [ 0.5651, -0.7134, -0.3155,  ..., -0.0889,  0.8549,  0.5976],\n",
            "         [-0.1249, -0.8682,  0.8773,  ..., -0.5341,  0.2749, -1.3617],\n",
            "         [-0.9345,  0.6710,  0.3124,  ..., -0.1466, -0.4451, -0.0643]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.4642, -0.4577,  0.7415,  ..., -0.0145, -0.2235, -0.1010],\n",
            "         [ 0.4718, -0.4410,  0.7900,  ..., -0.2524, -0.2843, -0.1506],\n",
            "         [ 0.4083, -0.4963,  0.7973,  ..., -0.4366, -0.2009, -0.1251],\n",
            "         ...,\n",
            "         [ 0.3587, -0.2459,  0.8482,  ..., -0.3463,  0.0618, -0.2150],\n",
            "         [ 0.3341, -0.2667,  0.9410,  ..., -0.3143,  0.1066, -0.1999],\n",
            "         [ 0.3279, -0.2915,  0.9021,  ..., -0.3191,  0.0523, -0.1661]],\n",
            "\n",
            "        [[ 0.3228, -0.5050,  0.3887,  ..., -0.2166,  0.2321,  0.5061],\n",
            "         [ 0.2308, -0.4593,  0.4248,  ..., -0.2744,  0.1563,  0.5831],\n",
            "         [ 0.2099, -0.4987,  0.5335,  ..., -0.2182,  0.2076,  0.4074],\n",
            "         ...,\n",
            "         [ 0.2214, -0.3869,  0.5478,  ..., -0.2286,  0.1931,  0.4667],\n",
            "         [ 0.3297, -0.4261,  0.5708,  ..., -0.2836,  0.1897,  0.3658],\n",
            "         [ 0.3815, -0.4640,  0.4978,  ..., -0.3835,  0.0757,  0.3076]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.4839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.4839, device='cuda:0', grad_fn=<ClampBackward1>)\n",
            "diff losses noise tensor([[[-1.8426,  1.7414, -1.0394,  ...,  0.9416, -1.3543, -0.5178],\n",
            "         [-0.1744,  0.5567,  0.1238,  ..., -0.1553, -0.2825,  1.2256],\n",
            "         [-0.4740, -0.0689, -0.9642,  ...,  0.5345, -2.2909,  2.4084],\n",
            "         ...,\n",
            "         [-1.8346,  1.0657,  1.0355,  ..., -0.7503,  0.1871,  1.8283],\n",
            "         [ 1.7829,  2.1524,  0.3459,  ..., -0.9468, -1.2605,  1.4984],\n",
            "         [-0.4715, -0.3403, -0.5787,  ..., -0.0263, -1.0713, -1.0470]],\n",
            "\n",
            "        [[ 1.8841,  0.5598, -0.5012,  ..., -1.3827, -0.3497,  0.3472],\n",
            "         [-0.4916, -1.2779,  0.1626,  ..., -0.4828, -0.8911, -0.7275],\n",
            "         [-0.1075, -0.4143,  0.7172,  ..., -0.8253,  0.5769,  1.9579],\n",
            "         ...,\n",
            "         [ 0.3977, -0.3971,  1.6301,  ..., -0.5800, -0.7117,  1.4837],\n",
            "         [-0.0332, -0.1762,  0.3561,  ...,  0.2010,  0.7214, -1.1299],\n",
            "         [ 0.5284, -0.6293,  0.3398,  ...,  0.0873, -0.4954, -0.6288]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.4890, -0.4323,  1.0142,  ..., -0.1109, -0.4130, -0.5574],\n",
            "         [ 0.4685, -0.3965,  1.0883,  ..., -0.0795, -0.4647, -0.4880],\n",
            "         [ 0.7372, -0.3194,  0.9042,  ..., -0.1196, -0.3488, -0.5312],\n",
            "         ...,\n",
            "         [ 0.5154, -0.2681,  0.8399,  ..., -0.1194, -0.4671, -0.5645],\n",
            "         [ 0.5106, -0.2322,  0.9024,  ..., -0.1795, -0.4022, -0.5538],\n",
            "         [ 0.5873, -0.2133,  0.8401,  ..., -0.1016, -0.3843, -0.6139]],\n",
            "\n",
            "        [[ 0.6737, -0.3005,  1.0954,  ..., -0.2023, -0.4300, -0.8465],\n",
            "         [ 0.8457, -0.1745,  1.2232,  ..., -0.1704, -0.3764, -0.8161],\n",
            "         [ 0.8126, -0.2660,  1.1264,  ..., -0.2720, -0.5089, -0.6906],\n",
            "         ...,\n",
            "         [ 0.7418, -0.2187,  1.1558,  ..., -0.0589, -0.3607, -0.8426],\n",
            "         [ 0.7424, -0.2728,  1.0456,  ...,  0.1103, -0.5333, -0.8644],\n",
            "         [ 0.6325, -0.3119,  1.1579,  ...,  0.0660, -0.4526, -0.7146]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.1654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.1654, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:  69%|██████▉   | 11/16 [00:11<00:05,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise tensor([[[ 0.3187, -1.4668,  1.1875,  ...,  2.7515, -0.5587,  0.9300],\n",
            "         [-2.1512, -1.2385,  0.3095,  ...,  0.6390, -0.2413,  0.4261],\n",
            "         [-0.4438, -1.3110,  0.3211,  ...,  0.6703,  1.4199,  0.1224],\n",
            "         ...,\n",
            "         [-1.1901,  0.0444,  0.6535,  ..., -0.2674,  0.8107,  0.9169],\n",
            "         [-0.6913,  0.6795,  1.0565,  ..., -2.4169,  0.9182, -0.5767],\n",
            "         [ 1.0700,  0.6060, -0.2179,  ...,  3.2635, -0.1309, -0.6610]],\n",
            "\n",
            "        [[-0.4437,  0.7151,  0.0773,  ...,  0.5465, -0.2925, -0.8010],\n",
            "         [-0.9042, -0.6987, -0.1297,  ..., -1.1596, -0.5910,  0.1208],\n",
            "         [-2.4442,  0.5480,  0.3359,  ..., -0.8361,  1.4133,  0.2649],\n",
            "         ...,\n",
            "         [ 0.5906, -0.7118, -0.7483,  ..., -1.1464, -0.5247,  0.6380],\n",
            "         [ 1.4598, -0.8921,  2.7691,  ..., -0.6879,  0.2355, -1.6032],\n",
            "         [-1.6549,  1.1789,  0.2145,  ..., -0.3455,  0.8847,  1.0235]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[-0.3058, -0.2764,  0.4491,  ..., -0.1478, -0.0873,  0.9873],\n",
            "         [-0.3511, -0.2389,  0.4947,  ..., -0.2374, -0.0912,  0.9255],\n",
            "         [-0.3274, -0.1797,  0.4606,  ..., -0.2134, -0.0753,  0.9723],\n",
            "         ...,\n",
            "         [-0.2700, -0.4089,  0.3760,  ..., -0.1321,  0.0161,  1.0697],\n",
            "         [-0.2288, -0.2932,  0.4200,  ..., -0.0458,  0.0438,  0.9697],\n",
            "         [-0.2399, -0.1889,  0.2889,  ..., -0.0999,  0.0788,  1.1245]],\n",
            "\n",
            "        [[ 0.8230, -0.4989,  1.0401,  ..., -0.0370, -0.1594, -0.8977],\n",
            "         [ 1.1055, -0.3948,  1.0978,  ..., -0.0050, -0.3004, -0.9836],\n",
            "         [ 1.0959, -0.2886,  1.0615,  ...,  0.1271, -0.3820, -0.9819],\n",
            "         ...,\n",
            "         [ 0.9914, -0.2597,  1.0440,  ..., -0.2689, -0.2631, -0.8850],\n",
            "         [ 0.9678, -0.2410,  0.9027,  ..., -0.1174, -0.1188, -0.7460],\n",
            "         [ 0.9341, -0.2496,  0.9490,  ..., -0.1814, -0.1212, -0.8099]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.0141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.0141, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:  75%|███████▌  | 12/16 [00:12<00:03,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise tensor([[[-0.9183, -1.5954,  0.3130,  ...,  0.2978, -1.2637, -0.8767],\n",
            "         [-0.4048,  0.7796,  0.4652,  ..., -0.5226, -0.4700,  0.6244],\n",
            "         [ 0.3483,  1.3067,  0.1948,  ..., -0.3868, -0.8209,  0.0661],\n",
            "         ...,\n",
            "         [ 0.8655, -1.2729, -0.2150,  ..., -0.1913,  0.8943,  0.6664],\n",
            "         [-0.6280,  0.2801, -0.5274,  ...,  0.9253,  2.0564,  0.9922],\n",
            "         [-1.8957, -0.8451,  1.5372,  ...,  0.9571,  1.3052,  0.5705]],\n",
            "\n",
            "        [[-0.0403,  1.3268, -0.0675,  ..., -0.2024,  0.2464,  0.0397],\n",
            "         [-0.5631, -0.4675,  0.0687,  ...,  0.5517,  0.5907, -0.9469],\n",
            "         [ 0.5750, -0.6090, -0.4896,  ..., -2.0821, -0.2317,  0.9030],\n",
            "         ...,\n",
            "         [-1.4135,  0.7318,  0.2415,  ...,  0.5092,  0.0262, -0.4958],\n",
            "         [ 0.9335, -0.4103,  0.1507,  ...,  0.3791, -0.5448,  1.4236],\n",
            "         [-0.2579,  0.0964,  1.0522,  ...,  0.0974,  0.3610,  1.1080]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 1.0730, -0.2394,  1.1579,  ..., -0.1276, -0.4330, -1.1182],\n",
            "         [ 1.0363, -0.2614,  1.0810,  ..., -0.1402, -0.5228, -1.1101],\n",
            "         [ 1.0418, -0.1626,  1.1546,  ..., -0.1198, -0.4429, -1.1571],\n",
            "         ...,\n",
            "         [ 0.8872, -0.1871,  1.1050,  ..., -0.0602, -0.6355, -0.8321],\n",
            "         [ 0.8647, -0.3382,  1.0714,  ..., -0.0565, -0.6842, -0.9372],\n",
            "         [ 0.9455, -0.2813,  1.0391,  ..., -0.0941, -0.5456, -1.0360]],\n",
            "\n",
            "        [[ 1.2331, -0.1279,  1.3433,  ..., -0.0751, -0.5412, -1.2344],\n",
            "         [ 1.2494, -0.2591,  1.2117,  ..., -0.0092, -0.5462, -1.2433],\n",
            "         [ 1.2046, -0.1627,  1.2668,  ...,  0.0089, -0.4923, -1.2809],\n",
            "         ...,\n",
            "         [ 1.0137, -0.3267,  1.3025,  ...,  0.0044, -0.5758, -0.9897],\n",
            "         [ 0.9735, -0.2850,  1.1817,  ..., -0.0633, -0.6645, -0.9049],\n",
            "         [ 0.9343, -0.4662,  1.0779,  ..., -0.1179, -0.6956, -1.0103]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.9957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.9957, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:  81%|████████▏ | 13/16 [00:14<00:04,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:  88%|████████▊ | 14/16 [00:15<00:02,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0866, -1.1497, -1.9467,  ..., -0.2004, -0.3996, -1.5285],\n",
            "         [-1.0205, -0.9408,  0.7097,  ..., -2.0968,  1.4921,  0.6615],\n",
            "         [ 0.0281, -0.8575, -0.1201,  ...,  2.5750, -0.6611,  0.0137],\n",
            "         ...,\n",
            "         [ 0.0228,  2.8383, -1.0350,  ...,  1.4055,  0.5478, -0.7141],\n",
            "         [ 0.7285, -1.1925,  1.5308,  ..., -0.6306,  0.0252, -0.1895],\n",
            "         [-1.5917, -0.1190,  1.2865,  ..., -0.1156, -0.4083, -0.2243]],\n",
            "\n",
            "        [[-1.3548,  0.4578, -0.0308,  ..., -0.2954,  1.1052,  0.9431],\n",
            "         [ 0.8436, -0.8872,  0.7553,  ..., -0.3175,  1.1516,  0.4741],\n",
            "         [-1.5490, -0.5166,  1.2491,  ..., -1.9863,  0.8660,  0.5503],\n",
            "         ...,\n",
            "         [ 1.0818, -0.6983,  1.6763,  ..., -1.2191, -1.9062, -0.0544],\n",
            "         [-1.6464, -0.9092,  0.2294,  ...,  0.4895, -0.8471,  0.1294],\n",
            "         [-0.4986, -0.3234,  1.8191,  ...,  1.6041,  0.2919, -0.5323]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[-0.0443, -0.6065,  0.6265,  ..., -0.3038,  0.2302,  0.4060],\n",
            "         [-0.0495, -0.5389,  0.6881,  ...,  0.0078,  0.1021,  0.5294],\n",
            "         [-0.0716, -0.6216,  0.4617,  ..., -0.2425,  0.3063,  0.2718],\n",
            "         ...,\n",
            "         [ 0.1424, -0.6359,  0.3926,  ...,  0.0107,  0.1000,  0.5617],\n",
            "         [ 0.2399, -0.6002,  0.2160,  ..., -0.0253,  0.1868,  0.5052],\n",
            "         [ 0.2816, -0.5972,  0.2521,  ..., -0.1170,  0.1819,  0.5582]],\n",
            "\n",
            "        [[-0.0732, -0.6981,  0.5319,  ..., -0.2673, -0.0086,  0.2477],\n",
            "         [-0.0838, -0.6823,  0.4895,  ..., -0.3468,  0.1047,  0.4607],\n",
            "         [ 0.0865, -0.5283,  0.4516,  ..., -0.3020,  0.1938,  0.4369],\n",
            "         ...,\n",
            "         [ 0.0697, -0.8798,  0.6748,  ..., -0.3393,  0.3959,  0.4677],\n",
            "         [-0.0080, -0.7436,  0.8039,  ..., -0.1109,  0.1300,  0.4664],\n",
            "         [ 0.1151, -0.6159,  0.4627,  ..., -0.2573,  0.2541,  0.2976]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.5976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.5976, device='cuda:0', grad_fn=<ClampBackward1>)\n",
            "diff losses noise tensor([[[ 0.0057, -1.5387, -1.1226,  ..., -1.0905,  1.9052, -0.0715],\n",
            "         [-0.2579, -0.2369,  0.9466,  ...,  0.1426,  0.5042, -1.1557],\n",
            "         [ 0.2585, -2.3672, -0.0659,  ..., -0.2774,  0.2874,  1.9617],\n",
            "         ...,\n",
            "         [-0.4358, -0.8723, -0.3742,  ...,  1.0584,  1.0853, -0.2584],\n",
            "         [-0.9165,  1.5457, -0.2990,  ...,  0.9160, -0.5398,  0.0271],\n",
            "         [ 0.8365,  1.2736, -1.4692,  ..., -0.2707, -0.8888, -1.0039]],\n",
            "\n",
            "        [[-0.7415,  0.7569,  3.1559,  ...,  2.0551, -0.6297, -0.7117],\n",
            "         [ 1.3551,  0.7788, -1.9563,  ...,  0.2140,  0.1396,  1.2315],\n",
            "         [-0.7224,  1.4934,  0.3523,  ..., -0.7009, -0.5948,  0.1539],\n",
            "         ...,\n",
            "         [-1.3601, -0.4004,  0.6681,  ...,  0.3098, -0.9985,  0.2844],\n",
            "         [-1.6501,  0.5790, -0.9200,  ...,  1.3619,  2.7198,  1.6015],\n",
            "         [ 0.1817, -0.7117, -0.4180,  ..., -1.1887, -0.9722, -0.9080]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.3939, -0.5129,  0.9545,  ..., -0.1225, -0.3561, -0.2505],\n",
            "         [ 0.2747, -0.7501,  0.8765,  ..., -0.0878, -0.3457, -0.2087],\n",
            "         [ 0.2622, -0.5891,  0.9593,  ..., -0.2595, -0.3409, -0.2789],\n",
            "         ...,\n",
            "         [ 0.2315, -0.3573,  1.0050,  ..., -0.2169, -0.1995, -0.0253],\n",
            "         [ 0.2958, -0.3664,  1.0365,  ..., -0.2628, -0.1896, -0.1266],\n",
            "         [ 0.2293, -0.2441,  0.9620,  ..., -0.2552, -0.0608,  0.0268]],\n",
            "\n",
            "        [[ 0.4660, -0.4452,  0.7589,  ..., -0.1047, -0.4443, -0.3631],\n",
            "         [ 0.4999, -0.3339,  0.7470,  ..., -0.0904, -0.4567, -0.1961],\n",
            "         [ 0.4882, -0.3841,  0.8641,  ..., -0.1727, -0.3882, -0.2399],\n",
            "         ...,\n",
            "         [ 0.6133, -0.5107,  0.7296,  ..., -0.2137, -0.4024, -0.5000],\n",
            "         [ 0.5257, -0.5212,  0.7213,  ..., -0.2190, -0.3698, -0.4815],\n",
            "         [ 0.4905, -0.4177,  0.8241,  ..., -0.0662, -0.4990, -0.5472]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(0.9840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(0.9840, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:  94%|█████████▍| 15/16 [00:16<00:01,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise tensor([[[ 0.5095, -1.9787, -1.1941,  ..., -0.0843, -1.1899, -0.0637],\n",
            "         [ 0.6278,  0.3430, -0.3370,  ...,  0.2257, -0.1606,  1.6388],\n",
            "         [-0.3852, -1.6411,  1.1113,  ...,  0.5207, -0.5039, -0.7304],\n",
            "         ...,\n",
            "         [-0.8228, -1.0730, -0.0664,  ...,  0.7574, -0.7449,  0.4701],\n",
            "         [-0.7368,  0.1790,  0.8997,  ...,  0.4002, -1.7245,  0.6692],\n",
            "         [ 0.4433,  0.7936,  0.5391,  ...,  0.7707,  0.5904,  0.4369]],\n",
            "\n",
            "        [[ 1.1012,  0.5553, -1.3164,  ...,  0.8391, -0.1321,  0.5925],\n",
            "         [ 0.7778, -1.4524, -1.0277,  ..., -0.4474, -1.4276, -2.3788],\n",
            "         [ 0.0157, -0.9739, -0.1765,  ...,  0.0126,  0.9128,  0.5947],\n",
            "         ...,\n",
            "         [-0.1552, -0.1689, -0.9897,  ...,  0.5634,  2.1202, -0.4149],\n",
            "         [-0.3900, -0.2462, -0.9022,  ...,  0.5664, -1.0123, -0.8375],\n",
            "         [-0.0597,  1.8203,  2.3155,  ...,  1.3286,  0.5609,  0.3460]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 1.1237, -0.1795,  1.3923,  ..., -0.0973, -0.7977, -1.2245],\n",
            "         [ 1.1323, -0.0898,  1.4093,  ..., -0.1075, -0.7033, -1.2635],\n",
            "         [ 1.0526, -0.3360,  1.2442,  ..., -0.1109, -0.7879, -1.2624],\n",
            "         ...,\n",
            "         [ 1.0629, -0.2647,  1.2172,  ..., -0.2410, -0.7557, -1.1791],\n",
            "         [ 1.0517, -0.1785,  1.1507,  ..., -0.1495, -0.6955, -1.1382],\n",
            "         [ 0.9956, -0.1359,  1.1887,  ..., -0.1051, -0.6861, -1.1385]],\n",
            "\n",
            "        [[ 0.6064, -0.3617,  0.9544,  ..., -0.0022, -0.4909, -0.8612],\n",
            "         [ 0.5293, -0.4435,  1.1211,  ..., -0.0237, -0.6047, -0.8754],\n",
            "         [ 0.5847, -0.3041,  1.1759,  ..., -0.0082, -0.5888, -0.8502],\n",
            "         ...,\n",
            "         [ 0.7493, -0.0876,  1.1339,  ..., -0.0706, -0.4130, -0.8628],\n",
            "         [ 0.7001, -0.2580,  1.1036,  ...,  0.0491, -0.4126, -0.8650],\n",
            "         [ 0.8664, -0.3040,  1.1352,  ..., -0.0629, -0.4380, -0.9392]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.9431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.9431, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 16/16 [00:17<00:00,  1.11s/it]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise tensor([[[ 2.3526,  0.1770,  0.9003,  ...,  0.3956, -0.5676, -0.9833],\n",
            "         [-0.1325, -0.2998, -0.0283,  ..., -1.4187,  0.2027,  0.6592],\n",
            "         [ 0.3677, -0.0096, -1.8341,  ..., -0.7006, -1.4607,  0.6320],\n",
            "         ...,\n",
            "         [ 0.3864,  0.7195,  0.6013,  ...,  0.4879,  0.6473, -0.1976],\n",
            "         [ 1.2960, -0.4093, -1.1549,  ...,  2.1640,  0.1839,  0.4597],\n",
            "         [-0.5057, -1.3066,  0.2101,  ..., -0.9084, -2.6864, -0.3045]],\n",
            "\n",
            "        [[ 0.4520,  0.3621,  2.5601,  ..., -0.6881,  0.2054, -1.8583],\n",
            "         [ 0.4742,  0.6623, -0.1499,  ...,  0.5925,  1.4402, -0.5643],\n",
            "         [-1.8258, -0.1037, -0.0610,  ...,  0.6927,  0.1113,  0.1782],\n",
            "         ...,\n",
            "         [-0.7524,  0.8802, -0.3477,  ...,  0.5988, -0.8411,  0.0870],\n",
            "         [ 2.5388, -1.1571, -1.2970,  ...,  0.0222, -0.8297,  0.9040],\n",
            "         [ 1.0119, -0.3134, -0.4792,  ..., -1.7029,  0.6845,  0.5370]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.6523, -0.4934,  0.8803,  ..., -0.5743, -0.2780, -0.7148],\n",
            "         [ 0.6471, -0.5345,  0.8008,  ..., -0.4935, -0.4086, -0.6987],\n",
            "         [ 0.6300, -0.4608,  0.8469,  ..., -0.3162, -0.4344, -0.7090],\n",
            "         ...,\n",
            "         [ 0.7571, -0.2328,  0.7601,  ..., -0.1275, -0.6328, -0.6037],\n",
            "         [ 0.5607, -0.4509,  0.6677,  ..., -0.1568, -0.6242, -0.5144],\n",
            "         [ 0.6549, -0.3148,  0.8160,  ..., -0.1127, -0.6640, -0.6811]],\n",
            "\n",
            "        [[ 1.1638, -0.2520,  1.2270,  ..., -0.0986, -0.5789, -1.0620],\n",
            "         [ 1.1473, -0.4800,  1.3054,  ..., -0.0098, -0.6209, -1.0669],\n",
            "         [ 1.1707, -0.4330,  1.3492,  ..., -0.0029, -0.6078, -1.0732],\n",
            "         ...,\n",
            "         [ 1.1303, -0.3375,  1.3852,  ...,  0.0040, -0.6296, -1.1719],\n",
            "         [ 1.1334, -0.2710,  1.4198,  ..., -0.0035, -0.7226, -1.0781],\n",
            "         [ 1.0253, -0.2123,  1.3842,  ..., -0.0062, -0.7646, -1.0113]]],\n",
            "       device='cuda:0')\n",
            "diff loss tensor(1.4753, device='cuda:0')\n",
            "diff loss clipped tensor(1.4753, device='cuda:0')\n",
            "diff losses noise tensor([[[-1.2078e+00, -9.9875e-01, -9.2167e-01,  ..., -5.4543e-02,\n",
            "          -2.6308e-01, -2.8522e-03],\n",
            "         [-1.2597e+00,  2.8968e-01,  6.0231e-01,  ..., -1.3219e+00,\n",
            "           1.7583e+00,  1.5107e+00],\n",
            "         [ 1.9279e-01,  1.3204e+00,  3.5971e-01,  ...,  1.0571e+00,\n",
            "           2.7362e+00,  1.2776e+00],\n",
            "         ...,\n",
            "         [ 1.5569e+00,  1.0155e+00, -4.3346e-01,  ..., -4.7014e-01,\n",
            "           2.4599e-01, -7.3120e-01],\n",
            "         [-1.7507e+00,  8.3079e-01, -9.8163e-01,  ..., -1.7335e+00,\n",
            "           7.7546e-01, -1.5799e+00],\n",
            "         [-2.2373e-01, -7.0024e-01, -4.6936e-01,  ..., -2.8764e+00,\n",
            "           1.8503e+00,  1.3243e+00]],\n",
            "\n",
            "        [[ 2.4112e+00, -2.6533e+00,  6.5923e-01,  ..., -9.5385e-01,\n",
            "          -1.5956e-01,  5.9689e-01],\n",
            "         [ 7.8936e-01,  6.1819e-01,  1.4637e+00,  ...,  4.6005e-01,\n",
            "          -1.9314e-01,  1.2862e+00],\n",
            "         [ 7.4629e-01,  1.8480e+00,  6.4830e-01,  ..., -1.2275e+00,\n",
            "           7.0650e-01,  1.2476e+00],\n",
            "         ...,\n",
            "         [ 6.8553e-01,  1.0666e+00, -7.7665e-02,  ...,  6.8936e-01,\n",
            "           1.2508e+00, -3.3036e-01],\n",
            "         [ 2.4434e+00, -4.9432e-01, -4.8412e-01,  ..., -1.4359e+00,\n",
            "          -1.9905e+00,  1.0064e+00],\n",
            "         [ 1.1230e+00,  3.2182e-01, -5.4427e-01,  ..., -3.5752e-01,\n",
            "           2.0065e-01,  2.6018e-01]]], device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.1264, -0.4873,  0.8180,  ..., -0.1802, -0.2096, -0.1130],\n",
            "         [ 0.1469, -0.4348,  0.9132,  ..., -0.0631, -0.2155, -0.2095],\n",
            "         [ 0.0802, -0.4946,  1.0609,  ..., -0.0582, -0.3520, -0.2740],\n",
            "         ...,\n",
            "         [ 0.2583, -0.3794,  0.8602,  ..., -0.0599, -0.3275, -0.0043],\n",
            "         [ 0.2135, -0.3604,  0.8252,  ...,  0.0471, -0.3913, -0.1009],\n",
            "         [ 0.2702, -0.4349,  0.8387,  ..., -0.1449, -0.4859, -0.1641]],\n",
            "\n",
            "        [[ 0.6023, -0.4405,  0.9367,  ..., -0.0276, -0.4782, -0.5812],\n",
            "         [ 0.6630, -0.5506,  0.8166,  ..., -0.0575, -0.4216, -0.6494],\n",
            "         [ 0.5778, -0.4126,  0.9423,  ...,  0.0236, -0.4379, -0.5623],\n",
            "         ...,\n",
            "         [ 0.7535, -0.3220,  1.1256,  ..., -0.0171, -0.5262, -0.7134],\n",
            "         [ 0.6150, -0.3324,  1.0626,  ..., -0.1263, -0.6880, -0.6878],\n",
            "         [ 0.7243, -0.3818,  1.0008,  ..., -0.0903, -0.6638, -0.7036]]],\n",
            "       device='cuda:0')\n",
            "diff loss tensor(1.2951, device='cuda:0')\n",
            "diff loss clipped tensor(1.2951, device='cuda:0')\n",
            "diff losses noise tensor([[[ 6.8276e-01,  6.1432e-01,  8.6236e-01,  ...,  5.3300e-01,\n",
            "           1.7848e+00, -8.9315e-01],\n",
            "         [ 2.5622e-01, -2.5478e-01, -9.4002e-01,  ..., -3.3177e-01,\n",
            "           3.2345e-01, -3.9272e-01],\n",
            "         [ 1.6528e+00,  8.0648e-01,  4.9729e-01,  ...,  8.0955e-01,\n",
            "          -9.6027e-02, -3.6799e-01],\n",
            "         ...,\n",
            "         [ 8.4047e-01, -1.1335e+00, -2.1309e+00,  ...,  3.6270e-02,\n",
            "           6.5567e-01, -9.0023e-01],\n",
            "         [ 7.0669e-02, -6.4549e-02, -2.1176e-01,  ..., -3.0266e-01,\n",
            "          -1.7389e+00,  1.5627e+00],\n",
            "         [ 9.5180e-01,  1.1907e+00, -1.3236e+00,  ..., -5.5194e-02,\n",
            "          -1.9893e-01, -2.3074e+00]],\n",
            "\n",
            "        [[-1.8528e-01, -6.1948e-04,  2.4028e-01,  ...,  6.6095e-01,\n",
            "          -1.9557e+00, -1.1621e+00],\n",
            "         [-4.5129e-01, -4.9941e-01,  1.4212e+00,  ..., -5.1114e-01,\n",
            "           8.7548e-01,  4.0165e-01],\n",
            "         [-7.8007e-02, -7.7136e-01,  1.2578e-01,  ..., -2.0698e+00,\n",
            "          -3.9571e-01, -1.1076e+00],\n",
            "         ...,\n",
            "         [-2.4597e-01,  1.4616e+00, -9.7284e-01,  ...,  4.4760e-01,\n",
            "          -1.3513e-01, -1.3567e+00],\n",
            "         [-3.4795e-01, -2.4413e-01, -1.5485e-01,  ..., -2.3971e+00,\n",
            "          -9.4130e-01, -7.6911e-01],\n",
            "         [ 4.8272e-01, -6.2983e-01, -9.2941e-01,  ...,  6.7838e-01,\n",
            "          -8.4935e-03,  2.3846e+00]]], device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.5618, -0.4117,  1.0706,  ..., -0.3279, -0.2300, -0.6079],\n",
            "         [ 0.4881, -0.3681,  1.1091,  ..., -0.3329, -0.1742, -0.4548],\n",
            "         [ 0.4522, -0.4242,  1.1016,  ..., -0.4075, -0.1926, -0.3006],\n",
            "         ...,\n",
            "         [ 0.4836, -0.4251,  1.0746,  ..., -0.1221, -0.4040, -0.5518],\n",
            "         [ 0.4856, -0.4042,  1.1014,  ..., -0.1581, -0.3052, -0.3834],\n",
            "         [ 0.5556, -0.3777,  1.0625,  ..., -0.0590, -0.2281, -0.3245]],\n",
            "\n",
            "        [[ 0.1132, -0.4599,  0.5233,  ..., -0.1399,  0.0516,  0.4178],\n",
            "         [ 0.0722, -0.5396,  0.6446,  ..., -0.0778, -0.0086,  0.3160],\n",
            "         [-0.0406, -0.4817,  0.7928,  ..., -0.0320,  0.0221,  0.3810],\n",
            "         ...,\n",
            "         [-0.0019, -0.4343,  0.6520,  ..., -0.0461, -0.0043,  0.2788],\n",
            "         [-0.0532, -0.4961,  0.6500,  ...,  0.0495,  0.0455,  0.3241],\n",
            "         [ 0.0825, -0.4750,  0.6981,  ..., -0.0186, -0.0593,  0.3043]]],\n",
            "       device='cuda:0')\n",
            "diff loss tensor(1.3113, device='cuda:0')\n",
            "diff loss clipped tensor(1.3113, device='cuda:0')\n",
            "diff losses noise tensor([[[ 0.4557,  0.1604, -0.8855,  ..., -0.4542, -0.0841, -0.2699],\n",
            "         [ 0.5613, -1.2800, -0.0959,  ..., -1.2199,  0.8667, -0.7797],\n",
            "         [ 0.1745,  0.2443,  0.2253,  ..., -0.7659, -1.1065, -0.4684],\n",
            "         ...,\n",
            "         [ 0.9352, -0.4014,  0.4746,  ...,  0.1252,  0.6000, -0.6019],\n",
            "         [-1.4770,  0.7042, -0.7304,  ..., -0.7051,  0.1356,  0.8296],\n",
            "         [-0.7440, -1.3403, -2.0598,  ...,  0.3497,  0.1614,  0.4592]],\n",
            "\n",
            "        [[-1.3336,  1.2762,  0.6602,  ...,  0.4306,  0.5304, -1.3386],\n",
            "         [ 0.1742, -0.1358, -1.2186,  ...,  0.8178, -1.3163,  0.5978],\n",
            "         [-1.9498,  0.5325, -1.7517,  ..., -0.5058, -1.2526, -0.8784],\n",
            "         ...,\n",
            "         [-1.2678,  1.1328, -0.6711,  ..., -0.4375, -0.7864, -0.6894],\n",
            "         [ 1.0006, -0.1646,  0.3773,  ...,  0.1870,  0.3070, -0.9343],\n",
            "         [-0.0242, -0.6333, -0.2110,  ..., -1.2742,  1.1032,  1.1394]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.6347, -0.4433,  0.7523,  ..., -0.4700, -0.2395, -0.5717],\n",
            "         [ 0.4350, -0.4957,  0.7306,  ..., -0.4086, -0.3906, -0.4402],\n",
            "         [ 0.5606, -0.5055,  0.7713,  ..., -0.4740, -0.3884, -0.5876],\n",
            "         ...,\n",
            "         [ 0.4250, -0.4514,  0.9793,  ..., -0.2669, -0.4491, -0.4825],\n",
            "         [ 0.5988, -0.4086,  1.0112,  ..., -0.2888, -0.5879, -0.5696],\n",
            "         [ 0.5367, -0.5462,  0.8805,  ..., -0.3986, -0.3748, -0.4960]],\n",
            "\n",
            "        [[ 0.5427, -0.0587,  0.7850,  ..., -0.0610, -0.4464, -0.3586],\n",
            "         [ 0.5765, -0.0365,  0.7293,  ..., -0.0529, -0.4510, -0.4015],\n",
            "         [ 0.5651, -0.0606,  0.7715,  ..., -0.1701, -0.4664, -0.3983],\n",
            "         ...,\n",
            "         [ 0.4433, -0.1780,  0.8087,  ..., -0.2103, -0.5668, -0.3359],\n",
            "         [ 0.5274, -0.0895,  0.7748,  ..., -0.1473, -0.5298, -0.4865],\n",
            "         [ 0.4871, -0.1501,  0.7778,  ..., -0.1236, -0.5994, -0.4645]]],\n",
            "       device='cuda:0')\n",
            "diff loss tensor(0.9174, device='cuda:0')\n",
            "diff loss clipped tensor(0.9174, device='cuda:0')\n",
            "diff losses noise tensor([[[-0.7063,  0.8189, -0.2937,  ..., -1.0256,  2.6513,  0.4286],\n",
            "         [ 0.6762,  1.0623, -0.4551,  ...,  0.3774,  0.7919,  0.1075],\n",
            "         [-0.5073,  0.7962,  1.0964,  ...,  0.5333, -0.6315,  0.1984],\n",
            "         ...,\n",
            "         [-0.2750, -0.5597,  0.0490,  ...,  1.0609, -1.5480, -0.4210],\n",
            "         [ 1.8116, -0.5935, -0.6222,  ..., -0.5425,  0.8556,  0.8280],\n",
            "         [ 0.5097,  1.4791, -0.9896,  ..., -0.6728, -0.6911, -2.0028]],\n",
            "\n",
            "        [[-0.4848, -0.4336,  0.4360,  ..., -0.6571,  0.3914,  0.0438],\n",
            "         [-0.9805, -0.0447, -0.7198,  ...,  0.4231,  0.2061, -0.6852],\n",
            "         [-1.1021, -2.3848, -0.1518,  ...,  1.6031, -0.4228, -1.0893],\n",
            "         ...,\n",
            "         [-0.5550, -1.7005,  0.5791,  ..., -0.0230,  0.7819, -0.3953],\n",
            "         [ 1.2923,  0.1905, -0.0102,  ..., -0.2367, -2.4325, -0.7252],\n",
            "         [ 1.2304, -0.2696,  0.5085,  ..., -0.3788,  2.1321, -0.1115]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.1531, -0.4372,  0.8267,  ..., -0.3499, -0.1000,  0.1003],\n",
            "         [ 0.2445, -0.5222,  0.6913,  ..., -0.3800,  0.1597,  0.1095],\n",
            "         [ 0.3168, -0.5140,  0.6802,  ..., -0.3318,  0.1393,  0.1705],\n",
            "         ...,\n",
            "         [ 0.2731, -0.4901,  0.6267,  ..., -0.2226, -0.0638,  0.0400],\n",
            "         [ 0.2472, -0.4900,  0.6764,  ..., -0.2375,  0.0033,  0.2514],\n",
            "         [ 0.2879, -0.5136,  0.6143,  ..., -0.2413, -0.0161,  0.0457]],\n",
            "\n",
            "        [[ 0.6427, -0.4773,  0.8935,  ..., -0.0847, -0.4672, -0.6714],\n",
            "         [ 0.6618, -0.5232,  0.9213,  ..., -0.1297, -0.4340, -0.7774],\n",
            "         [ 0.7421, -0.3932,  0.9842,  ..., -0.1241, -0.4588, -0.7479],\n",
            "         ...,\n",
            "         [ 0.7038, -0.3046,  1.0829,  ..., -0.0288, -0.2050, -0.6523],\n",
            "         [ 0.5775, -0.3878,  1.3863,  ..., -0.0476, -0.4989, -0.7474],\n",
            "         [ 0.5751, -0.5226,  1.2803,  ..., -0.0333, -0.3828, -0.7270]]],\n",
            "       device='cuda:0')\n",
            "diff loss tensor(1.4577, device='cuda:0')\n",
            "diff loss clipped tensor(1.4577, device='cuda:0')\n",
            "diff losses noise tensor([[[ 0.2190,  0.2856,  0.8954,  ..., -2.2033, -0.8953, -0.0915],\n",
            "         [ 0.5970, -1.3351,  0.7299,  ..., -0.4488, -0.5514, -0.0496],\n",
            "         [-1.0795, -0.6061, -0.2635,  ..., -2.1611,  0.3748,  0.0317],\n",
            "         ...,\n",
            "         [ 1.1380,  1.0598, -0.6130,  ...,  0.7996, -0.7690,  0.4166],\n",
            "         [-0.3374, -1.2564,  1.6502,  ...,  0.2831, -1.0839, -0.9968],\n",
            "         [ 0.7791,  1.1723, -0.5764,  ...,  1.1198,  1.0137,  1.6081]],\n",
            "\n",
            "        [[-0.9724,  0.6218,  0.2571,  ..., -0.5148, -1.5119, -0.1789],\n",
            "         [ 1.0219, -1.2040, -1.9571,  ...,  0.8310,  0.9518, -1.2869],\n",
            "         [-0.7151, -0.5960, -0.7323,  ..., -1.6854,  0.9329, -0.1271],\n",
            "         ...,\n",
            "         [-0.2636, -1.0890,  0.5670,  ..., -0.3498, -0.5431,  0.9303],\n",
            "         [ 0.1021,  1.2854, -0.4140,  ...,  0.0252,  1.0235,  0.8934],\n",
            "         [-0.3595, -0.2400,  0.4570,  ..., -2.1551, -0.1679, -0.7677]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.3655, -0.2510,  0.7722,  ..., -0.1374, -0.5605, -0.3707],\n",
            "         [ 0.4087, -0.0404,  0.8459,  ..., -0.0131, -0.6099, -0.3462],\n",
            "         [ 0.5478, -0.1395,  0.9008,  ..., -0.0224, -0.6775, -0.5051],\n",
            "         ...,\n",
            "         [ 0.7228, -0.2733,  1.0526,  ..., -0.2592, -0.4349, -0.7547],\n",
            "         [ 0.6696, -0.2604,  0.9280,  ..., -0.1348, -0.5433, -0.6761],\n",
            "         [ 0.8069, -0.3735,  0.8575,  ..., -0.1643, -0.6287, -0.7998]],\n",
            "\n",
            "        [[ 0.6523, -0.2590,  0.9967,  ..., -0.0533, -0.5551, -0.5492],\n",
            "         [ 0.5884, -0.2723,  1.0742,  ..., -0.0398, -0.5478, -0.5508],\n",
            "         [ 0.6325, -0.2066,  0.8971,  ..., -0.1164, -0.5682, -0.5711],\n",
            "         ...,\n",
            "         [ 0.6308, -0.3048,  1.0148,  ..., -0.1478, -0.5607, -0.6375],\n",
            "         [ 0.5807, -0.3237,  0.9724,  ..., -0.1316, -0.5180, -0.5415],\n",
            "         [ 0.5139, -0.3016,  1.0816,  ..., -0.1053, -0.5338, -0.5036]]],\n",
            "       device='cuda:0')\n",
            "diff loss tensor(1.0048, device='cuda:0')\n",
            "diff loss clipped tensor(1.0048, device='cuda:0')\n",
            "diff losses noise tensor([[[ 2.5966e-01, -9.2461e-02,  9.5650e-01,  ...,  2.2837e+00,\n",
            "          -1.2531e+00,  4.0330e-01],\n",
            "         [ 1.7219e-01,  8.6859e-01, -1.2661e+00,  ..., -8.0370e-01,\n",
            "          -5.8186e-01, -6.7484e-02],\n",
            "         [-1.1045e+00,  1.6045e+00, -9.7580e-01,  ..., -7.5093e-01,\n",
            "          -1.5336e+00, -2.3254e+00],\n",
            "         ...,\n",
            "         [ 2.3132e-01, -9.9002e-01, -2.8495e-01,  ..., -6.0111e-02,\n",
            "          -2.3691e+00, -4.4068e-01],\n",
            "         [-3.2590e-01,  5.4245e-01, -7.8645e-01,  ...,  3.2543e-01,\n",
            "          -9.8527e-01,  2.0575e+00],\n",
            "         [ 7.5311e-01, -9.5893e-01,  5.6602e-01,  ..., -1.1547e+00,\n",
            "           1.1726e-01,  4.8369e-01]],\n",
            "\n",
            "        [[ 3.0024e-01, -9.5052e-02,  8.5031e-01,  ..., -7.5581e-01,\n",
            "           1.0668e+00, -3.5938e-01],\n",
            "         [ 7.5370e-01, -1.3163e-01,  2.4084e-01,  ..., -1.7770e-01,\n",
            "           9.2601e-01, -2.0772e-01],\n",
            "         [ 3.3873e-01, -6.0224e-01,  1.6551e+00,  ..., -9.7724e-03,\n",
            "          -2.7421e-01, -1.7690e+00],\n",
            "         ...,\n",
            "         [-2.7911e+00,  1.4422e-03,  6.3695e-01,  ..., -6.8745e-01,\n",
            "           1.0966e+00,  1.9652e+00],\n",
            "         [-1.9172e+00, -1.7773e+00, -3.0128e-01,  ..., -2.5710e-01,\n",
            "          -3.2472e-01,  2.4409e+00],\n",
            "         [ 2.9748e+00,  3.3975e-01,  2.7533e-01,  ...,  1.4753e+00,\n",
            "           8.5382e-01, -3.5743e-01]]], device='cuda:0')\n",
            "diff losses pred noise tensor([[[-0.4405, -0.4489,  0.1938,  ..., -0.4005, -0.0871,  1.1183],\n",
            "         [-0.5996, -0.4340,  0.2776,  ..., -0.4550, -0.1748,  1.1653],\n",
            "         [-0.4108, -0.3053,  0.1934,  ..., -0.4364, -0.0583,  1.2367],\n",
            "         ...,\n",
            "         [-0.4824, -0.5255,  0.2772,  ..., -0.3214,  0.1091,  1.0422],\n",
            "         [-0.4667, -0.4258,  0.3280,  ..., -0.2919, -0.0532,  0.9929],\n",
            "         [-0.4536, -0.4400,  0.2806,  ..., -0.3383, -0.0068,  0.9992]],\n",
            "\n",
            "        [[ 0.8224, -0.3496,  0.9876,  ...,  0.0671, -0.6239, -0.9040],\n",
            "         [ 0.8184, -0.2267,  1.1253,  ..., -0.0673, -0.7142, -0.9518],\n",
            "         [ 0.8067, -0.3318,  1.0566,  ...,  0.0146, -0.5503, -0.8758],\n",
            "         ...,\n",
            "         [ 1.0643, -0.3464,  1.2353,  ...,  0.0545, -0.4105, -1.0923],\n",
            "         [ 0.9220, -0.2560,  1.2889,  ...,  0.1812, -0.4442, -1.0586],\n",
            "         [ 0.9003, -0.2576,  1.1879,  ...,  0.1485, -0.5138, -1.0181]]],\n",
            "       device='cuda:0')\n",
            "diff loss tensor(1.0166, device='cuda:0')\n",
            "diff loss clipped tensor(1.0166, device='cuda:0')\n",
            "diff losses noise tensor([[[ 1.0954e+00,  1.2216e+00,  8.5865e-01,  ...,  7.1070e-02,\n",
            "           2.4321e+00, -1.2837e-03],\n",
            "         [-5.6813e-01, -1.1280e+00, -1.7099e+00,  ..., -1.9629e+00,\n",
            "           1.0491e-01, -5.3822e-01],\n",
            "         [-1.1251e+00,  7.1623e-01,  8.2588e-02,  ...,  7.6343e-01,\n",
            "          -1.1558e+00,  1.1531e+00],\n",
            "         ...,\n",
            "         [ 1.8945e+00,  7.8457e-01,  6.1531e-01,  ...,  8.7200e-01,\n",
            "           8.6159e-01,  5.4672e-01],\n",
            "         [ 1.6058e+00, -9.5037e-01,  7.6674e-01,  ..., -3.0215e-01,\n",
            "           1.1126e+00, -5.7200e-01],\n",
            "         [-7.5155e-01, -2.2703e-01, -2.3025e-01,  ..., -2.6772e-01,\n",
            "          -8.7895e-01, -3.7530e-01]],\n",
            "\n",
            "        [[-5.9974e-02,  2.7860e-01,  1.2260e+00,  ...,  1.6165e+00,\n",
            "           8.1661e-01, -1.0678e-01],\n",
            "         [-7.8709e-02, -3.7899e-01,  1.8183e+00,  ...,  3.0074e-01,\n",
            "          -4.6532e-01, -7.4420e-01],\n",
            "         [-1.8738e-01, -2.0625e-01, -2.4881e-01,  ...,  2.1322e+00,\n",
            "           7.1125e-01, -8.5748e-01],\n",
            "         ...,\n",
            "         [ 3.0529e-01, -4.5490e-01, -1.0381e+00,  ...,  8.4777e-02,\n",
            "           4.7272e-01, -1.2173e-01],\n",
            "         [ 7.0362e-01,  3.2074e-01,  1.7787e-01,  ..., -6.1409e-01,\n",
            "           5.9019e-02,  1.1787e+00],\n",
            "         [ 2.7455e-01,  4.1887e-01, -7.0170e-01,  ..., -6.5690e-01,\n",
            "           1.0133e+00, -4.6356e-01]]], device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.6474, -0.0617,  1.0161,  ..., -0.3818, -0.4377, -0.6732],\n",
            "         [ 0.6412, -0.0545,  1.1785,  ..., -0.3276, -0.2896, -0.5799],\n",
            "         [ 0.7585, -0.1534,  1.1427,  ..., -0.4454, -0.3713, -0.8589],\n",
            "         ...,\n",
            "         [ 0.4352, -0.3924,  1.0593,  ..., -0.2973, -0.2488, -0.7041],\n",
            "         [ 0.6900, -0.2394,  0.9336,  ..., -0.4211, -0.2234, -0.7385],\n",
            "         [ 0.6278, -0.2000,  1.1360,  ..., -0.2306, -0.3944, -0.5403]],\n",
            "\n",
            "        [[-0.2252, -0.4740,  0.4666,  ..., -0.3045,  0.0085,  0.8657],\n",
            "         [-0.0773, -0.4721,  0.4408,  ..., -0.3555,  0.1078,  0.8881],\n",
            "         [-0.1269, -0.4459,  0.4205,  ..., -0.2465,  0.1102,  0.7433],\n",
            "         ...,\n",
            "         [-0.1353, -0.3086,  0.4649,  ..., -0.2396,  0.0489,  0.9684],\n",
            "         [-0.2193, -0.2804,  0.4925,  ..., -0.2274,  0.0639,  1.0323],\n",
            "         [-0.1599, -0.4475,  0.4711,  ..., -0.1474,  0.0624,  0.8794]]],\n",
            "       device='cuda:0')\n",
            "diff loss tensor(0.1360, device='cuda:0')\n",
            "diff loss clipped tensor(0.1360, device='cuda:0')\n",
            "Epoch 1, Train Loss: 7.9207, Val Loss: 8.3882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/2:   0%|          | 0/16 [00:00<?, ?it/s]<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/2:   6%|▋         | 1/16 [00:01<00:15,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.3821,  0.8817,  0.1539,  ...,  0.9003,  0.9768,  0.9396],\n",
            "         [-1.3366,  0.1920,  1.4416,  ..., -1.6486, -1.5726,  0.8740],\n",
            "         [-0.5263,  0.5445,  0.6224,  ..., -1.6161,  1.4830, -0.1544],\n",
            "         ...,\n",
            "         [ 0.4698, -0.4183, -0.7562,  ...,  0.4389, -0.4965,  0.2410],\n",
            "         [ 0.4212,  0.5840, -1.8616,  ...,  0.1761,  1.3326, -1.3349],\n",
            "         [-1.0075,  0.1248, -0.5753,  ..., -0.3747, -1.4291,  0.5955]],\n",
            "\n",
            "        [[-1.2877, -0.7869,  1.8368,  ...,  1.1521, -1.4277, -1.1303],\n",
            "         [-1.4666,  1.6456,  1.3689,  ...,  1.4646, -0.3484, -0.5707],\n",
            "         [-1.0107,  0.1681,  2.4322,  ..., -0.9044,  0.1149,  0.3093],\n",
            "         ...,\n",
            "         [ 1.6553, -1.1163,  0.7396,  ...,  0.0612, -0.6016, -1.3332],\n",
            "         [ 0.4710, -0.6345,  2.2056,  ...,  0.8025,  0.0092, -0.5473],\n",
            "         [ 0.5605,  0.4413,  0.3586,  ...,  0.3977, -2.1490, -0.1481]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[-0.7529, -0.3280, -0.0984,  ..., -0.3277,  0.1642,  1.4530],\n",
            "         [-0.8362, -0.3376, -0.1521,  ..., -0.3951,  0.2384,  1.5074],\n",
            "         [-0.7741, -0.2576, -0.1592,  ..., -0.2641,  0.1545,  1.5597],\n",
            "         ...,\n",
            "         [-0.7231, -0.3532, -0.1811,  ..., -0.2847,  0.4081,  1.6543],\n",
            "         [-0.6745, -0.5668,  0.1110,  ..., -0.4232,  0.2906,  1.2935],\n",
            "         [-0.7321, -0.5133, -0.0094,  ..., -0.5067,  0.4023,  1.4660]],\n",
            "\n",
            "        [[ 0.4724, -0.3659,  0.9392,  ..., -0.0616, -0.6335, -0.5861],\n",
            "         [ 0.4897, -0.3947,  0.8452,  ..., -0.0322, -0.5822, -0.5392],\n",
            "         [ 0.5003, -0.3656,  0.9207,  ..., -0.1112, -0.5219, -0.4461],\n",
            "         ...,\n",
            "         [ 0.5873, -0.4618,  0.9116,  ..., -0.1759, -0.5359, -0.6736],\n",
            "         [ 0.5371, -0.3956,  0.9782,  ..., -0.1154, -0.5075, -0.5579],\n",
            "         [ 0.6033, -0.4143,  1.0313,  ..., -0.1772, -0.4851, -0.5254]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.0043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.0043, device='cuda:0', grad_fn=<ClampBackward1>)\n",
            "diff losses noise tensor([[[-1.4439, -0.3771,  0.3524,  ..., -0.7299, -2.4230,  0.2890],\n",
            "         [-1.0204,  0.5029,  0.6626,  ..., -0.1526,  0.3917, -1.6930],\n",
            "         [ 1.2820, -1.2782,  0.5081,  ...,  1.6537, -0.0558,  0.8303],\n",
            "         ...,\n",
            "         [-1.4728,  1.0936,  0.3418,  ...,  0.0123,  0.3729,  0.2899],\n",
            "         [ 0.5687, -1.1784,  1.4719,  ..., -0.1352, -0.7206, -1.4591],\n",
            "         [-1.3116, -0.0488,  0.2833,  ...,  0.1214,  1.0261, -0.2071]],\n",
            "\n",
            "        [[ 0.2797, -0.0113, -0.4974,  ...,  0.7772, -1.7213,  0.7587],\n",
            "         [ 0.5930,  1.0271, -0.7956,  ...,  1.0552, -1.5625, -0.7928],\n",
            "         [ 1.1528,  2.1199,  0.0098,  ..., -0.6064, -0.0913,  0.4616],\n",
            "         ...,\n",
            "         [-0.5824, -1.3609, -0.0591,  ..., -0.5074, -0.6564, -0.6324],\n",
            "         [ 1.0067,  1.5868,  0.3899,  ...,  1.1972,  0.0241, -1.4172],\n",
            "         [ 0.5081,  0.7779, -0.5677,  ...,  0.6900, -0.0297, -1.0987]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[-0.0903, -0.5345,  0.1552,  ..., -0.0993,  0.2795,  0.9695],\n",
            "         [-0.2855, -0.5493,  0.1508,  ..., -0.0997,  0.2610,  1.1716],\n",
            "         [-0.4528, -0.5799,  0.1672,  ..., -0.1063,  0.3328,  1.0306],\n",
            "         ...,\n",
            "         [-0.3275, -0.5797,  0.0966,  ..., -0.2763,  0.3727,  1.3307],\n",
            "         [-0.3364, -0.6080,  0.1173,  ..., -0.2222,  0.4329,  1.4042],\n",
            "         [-0.4565, -0.4401,  0.0927,  ..., -0.1282,  0.4804,  1.4486]],\n",
            "\n",
            "        [[ 0.6862, -0.4950,  0.8077,  ..., -0.3755, -0.4170, -0.5100],\n",
            "         [ 0.6629, -0.4936,  0.9196,  ..., -0.2931, -0.4487, -0.5144],\n",
            "         [ 0.6578, -0.5256,  0.9316,  ..., -0.3283, -0.4680, -0.6213],\n",
            "         ...,\n",
            "         [ 0.6954, -0.5075,  1.0289,  ..., -0.2460, -0.5055, -0.5556],\n",
            "         [ 0.5044, -0.3668,  1.0341,  ..., -0.3690, -0.2982, -0.6148],\n",
            "         [ 0.6034, -0.4704,  1.0124,  ..., -0.3943, -0.3178, -0.5652]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.0682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.0682, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/2:  12%|█▎        | 2/16 [00:01<00:09,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise tensor([[[ 2.5359e+00,  2.0166e-01,  9.7098e-01,  ..., -6.1722e-01,\n",
            "           7.5738e-02, -1.1445e+00],\n",
            "         [ 2.8516e-01,  1.9159e+00,  3.6009e-01,  ..., -1.7681e+00,\n",
            "           5.0792e-01, -7.8175e-01],\n",
            "         [-2.1085e-02, -6.9240e-01,  2.6470e+00,  ..., -9.9460e-01,\n",
            "           3.9611e-01, -1.2402e+00],\n",
            "         ...,\n",
            "         [-2.0018e-04, -5.0264e-01, -8.4094e-01,  ...,  5.7085e-01,\n",
            "          -1.2388e+00,  1.0785e+00],\n",
            "         [-7.7838e-01,  1.5246e+00, -2.8887e-01,  ...,  4.8821e-01,\n",
            "          -4.4781e-02,  5.9562e-01],\n",
            "         [ 6.5318e-01,  1.1601e+00, -6.4696e-01,  ..., -2.1194e+00,\n",
            "           1.6491e+00,  1.7950e+00]],\n",
            "\n",
            "        [[ 1.0527e+00,  2.5398e-01, -8.0457e-02,  ..., -2.8291e+00,\n",
            "           2.2120e+00, -1.2719e+00],\n",
            "         [-1.0629e+00,  3.8110e-01,  1.6553e-01,  ...,  3.5783e-01,\n",
            "          -1.3447e+00, -2.7622e-01],\n",
            "         [ 9.9803e-01,  9.5535e-01,  2.0289e+00,  ...,  7.0876e-01,\n",
            "          -1.1216e+00,  8.2968e-01],\n",
            "         ...,\n",
            "         [-2.0456e+00, -3.3767e-01, -2.2167e-01,  ...,  3.2140e-02,\n",
            "          -6.6123e-01, -4.6336e-01],\n",
            "         [-1.2883e+00,  1.9218e+00, -9.7069e-01,  ...,  5.4683e-01,\n",
            "           6.6823e-01, -1.4032e-01],\n",
            "         [-3.3694e-01, -1.1325e+00,  1.6728e+00,  ..., -3.8544e-01,\n",
            "           6.9494e-01,  1.0422e+00]]], device='cuda:0')\n",
            "diff losses pred noise tensor([[[-0.3208, -0.5917,  0.2371,  ..., -0.7095, -0.0661,  0.8189],\n",
            "         [-0.1243, -0.5823,  0.2903,  ..., -0.6308,  0.0191,  0.7726],\n",
            "         [-0.1539, -0.3224,  0.2549,  ..., -0.4845,  0.1752,  0.5538],\n",
            "         ...,\n",
            "         [-0.2964, -0.5375,  0.3546,  ..., -0.1437,  0.5721,  0.8636],\n",
            "         [-0.5177, -0.7586,  0.3671,  ..., -0.3065,  0.3211,  0.8847],\n",
            "         [-0.4994, -0.7181,  0.2389,  ..., -0.3864,  0.2400,  0.8424]],\n",
            "\n",
            "        [[ 0.7251, -0.2829,  1.2604,  ...,  0.0365, -0.3391, -1.0055],\n",
            "         [ 0.6586, -0.2569,  1.1690,  ...,  0.0847, -0.5422, -0.9517],\n",
            "         [ 0.7255, -0.3958,  1.1369,  ..., -0.0330, -0.4505, -1.0295],\n",
            "         ...,\n",
            "         [ 0.7983, -0.3070,  1.2505,  ...,  0.1547, -0.4013, -0.9349],\n",
            "         [ 0.6493, -0.3648,  1.1892,  ...,  0.1648, -0.4767, -0.9040],\n",
            "         [ 0.7709, -0.3036,  1.2301,  ...,  0.1786, -0.2392, -0.9946]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.0531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.0531, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/2:  19%|█▉        | 3/16 [00:02<00:12,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise tensor([[[ 0.3717,  0.4857,  1.4267,  ...,  1.3464,  1.4458,  1.1155],\n",
            "         [-0.2656, -0.1764, -0.6085,  ..., -1.2139, -0.1080,  0.1275],\n",
            "         [-2.4643,  0.7759, -0.7267,  ..., -1.7775, -0.6742,  0.2061],\n",
            "         ...,\n",
            "         [ 0.0780, -0.2413,  0.4900,  ..., -0.9178, -0.0318, -1.6439],\n",
            "         [ 1.0193,  1.9512, -0.4873,  ..., -0.6585,  0.2128, -0.3047],\n",
            "         [-1.0484,  1.2851, -0.7814,  ...,  1.1599,  1.2244, -0.8363]],\n",
            "\n",
            "        [[-0.7599,  0.7550,  1.1408,  ...,  1.2183,  0.7411,  1.8628],\n",
            "         [ 1.2425,  0.2062, -1.8313,  ..., -0.2526, -0.3072,  1.6040],\n",
            "         [ 2.7177, -0.1087, -1.4595,  ..., -0.5655,  0.5694, -0.1062],\n",
            "         ...,\n",
            "         [-0.6348,  0.2096, -1.1494,  ..., -1.1309,  0.8578, -0.0325],\n",
            "         [ 2.2009,  0.1647, -0.5689,  ..., -0.3905,  0.1274, -1.4001],\n",
            "         [-0.5740, -0.5253, -0.2902,  ..., -0.8955,  0.0791,  0.3016]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.5314, -0.3289,  1.1635,  ..., -0.1599, -0.4744, -0.7496],\n",
            "         [ 0.3237, -0.3388,  1.1068,  ..., -0.0990, -0.3638, -0.6719],\n",
            "         [ 0.4572, -0.4343,  0.8760,  ..., -0.3239, -0.4479, -0.8247],\n",
            "         ...,\n",
            "         [ 0.5658, -0.3712,  1.0404,  ..., -0.2536, -0.3675, -0.4808],\n",
            "         [ 0.5327, -0.3299,  1.0754,  ..., -0.2150, -0.3818, -0.5377],\n",
            "         [ 0.5598, -0.2139,  1.2269,  ..., -0.3124, -0.3917, -0.3817]],\n",
            "\n",
            "        [[ 0.4110, -0.3617,  0.8551,  ..., -0.4527, -0.2456, -0.2768],\n",
            "         [ 0.4212, -0.3744,  0.7932,  ..., -0.3085, -0.1264, -0.3095],\n",
            "         [ 0.2785, -0.6358,  0.6660,  ..., -0.3114, -0.1890, -0.4395],\n",
            "         ...,\n",
            "         [-0.0705, -0.5448,  0.5697,  ..., -0.3327, -0.3259, -0.3021],\n",
            "         [ 0.3795, -0.4488,  0.7398,  ..., -0.5044, -0.3714, -0.6298],\n",
            "         [ 0.1106, -0.3505,  0.6354,  ..., -0.2856, -0.2389, -0.1274]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.9900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.9900, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/2:  25%|██▌       | 4/16 [00:03<00:09,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise tensor([[[ 6.6478e-01, -5.2244e-01, -1.5295e-01,  ..., -2.0473e-01,\n",
            "          -1.3900e-01,  7.9576e-01],\n",
            "         [-1.1570e+00,  1.1560e-01, -4.1718e-01,  ..., -1.0515e+00,\n",
            "           4.6063e-01,  2.0161e+00],\n",
            "         [-1.1803e+00,  3.8866e-02,  6.3250e-01,  ...,  1.5842e+00,\n",
            "          -8.1596e-01, -4.5839e-01],\n",
            "         ...,\n",
            "         [-3.8114e-01, -5.1100e-01,  4.8862e-01,  ..., -5.5679e-01,\n",
            "           4.9914e-01, -1.3565e+00],\n",
            "         [-1.8631e-01,  1.3542e-02, -6.9676e-01,  ...,  1.2140e+00,\n",
            "          -5.9348e-01, -1.8737e-01],\n",
            "         [ 4.9493e-01, -6.3279e-01,  5.4615e-01,  ..., -4.7924e-03,\n",
            "           1.0585e-01, -1.1415e+00]],\n",
            "\n",
            "        [[ 3.8332e-01,  2.5140e+00, -1.6230e+00,  ...,  3.5783e-01,\n",
            "          -1.2784e-01,  8.8104e-01],\n",
            "         [-3.3696e-02,  8.9940e-01,  6.1028e-01,  ..., -1.5905e+00,\n",
            "           2.2821e+00, -1.7418e+00],\n",
            "         [ 1.4981e+00, -1.1268e+00, -9.4858e-01,  ..., -9.2141e-01,\n",
            "          -4.7516e-01, -3.8965e-01],\n",
            "         ...,\n",
            "         [-4.7118e-01, -1.5550e+00, -7.2610e-01,  ..., -7.7437e-01,\n",
            "           7.2242e-01, -1.0382e+00],\n",
            "         [-9.4212e-01,  5.4251e-01,  1.0506e+00,  ...,  6.6915e-04,\n",
            "           4.3908e-01, -1.0311e+00],\n",
            "         [-8.8611e-01, -2.5711e-01,  1.0040e+00,  ..., -1.3544e+00,\n",
            "          -3.2797e-01, -3.8406e-01]]], device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.4765, -0.3715,  1.1351,  ..., -0.4369, -0.5175, -0.9754],\n",
            "         [ 0.4481, -0.3708,  1.0375,  ..., -0.3885, -0.4657, -0.8050],\n",
            "         [ 0.3929, -0.3424,  0.8734,  ..., -0.4088, -0.2990, -0.7865],\n",
            "         ...,\n",
            "         [ 1.0210,  0.0229,  1.2661,  ..., -0.2570, -0.5815, -0.8995],\n",
            "         [ 0.9113, -0.0888,  1.1680,  ..., -0.0961, -0.7595, -0.9021],\n",
            "         [ 0.8985, -0.0671,  1.0590,  ..., -0.2257, -0.5379, -1.0166]],\n",
            "\n",
            "        [[ 0.5002, -0.3962,  0.8962,  ..., -0.2099, -0.4431, -0.6924],\n",
            "         [ 0.5554, -0.4521,  0.8908,  ..., -0.2537, -0.4510, -0.8238],\n",
            "         [ 0.4616, -0.4783,  1.0173,  ..., -0.3211, -0.4073, -0.7438],\n",
            "         ...,\n",
            "         [ 0.5550, -0.3418,  0.8929,  ..., -0.1098, -0.4560, -0.6211],\n",
            "         [ 0.4708, -0.4854,  0.9805,  ..., -0.1018, -0.5771, -0.7060],\n",
            "         [ 0.4409, -0.3918,  0.7097,  ...,  0.1386, -0.6754, -0.6437]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.3882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.3882, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/2:  31%|███▏      | 5/16 [00:04<00:10,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise tensor([[[ 0.0591, -0.1298,  0.7044,  ..., -1.6036, -0.2811,  1.4716],\n",
            "         [-0.8548,  0.9432, -1.3156,  ..., -0.3218, -0.8020, -1.7151],\n",
            "         [-0.7034,  0.8377, -0.5642,  ...,  0.9583,  1.3939,  0.0270],\n",
            "         ...,\n",
            "         [ 0.3377,  0.0546, -0.7185,  ..., -0.9845, -2.8696,  0.8124],\n",
            "         [ 1.0671, -0.1728,  0.3730,  ..., -0.2580,  0.2983, -2.1777],\n",
            "         [ 1.2875,  1.1065, -0.1472,  ..., -1.1040,  0.1952,  0.3261]],\n",
            "\n",
            "        [[-0.4556, -1.0568,  1.0139,  ...,  1.0636,  0.7770, -1.0516],\n",
            "         [ 1.0300,  0.4158,  1.1818,  ..., -1.4558, -0.5815,  0.4330],\n",
            "         [ 1.2281, -1.2368,  0.2305,  ..., -0.9166, -0.6928,  1.4312],\n",
            "         ...,\n",
            "         [-2.3788,  0.5724, -0.5170,  ...,  1.2259,  0.8386, -0.0175],\n",
            "         [-0.8409,  0.1718, -1.2092,  ..., -0.3797, -1.4207, -1.3194],\n",
            "         [-1.5895,  0.0620,  0.4149,  ..., -0.4992, -0.3170,  0.8756]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.5409, -0.2127,  0.8432,  ...,  0.0371, -0.6903, -0.7659],\n",
            "         [ 0.6067, -0.2198,  0.9570,  ..., -0.1262, -0.6543, -0.8334],\n",
            "         [ 0.5689, -0.0498,  0.9688,  ..., -0.0083, -0.6762, -0.7703],\n",
            "         ...,\n",
            "         [ 0.5718, -0.2793,  0.9654,  ..., -0.1495, -0.7403, -0.7994],\n",
            "         [ 0.5364, -0.2010,  0.9130,  ..., -0.0755, -0.6202, -0.8246],\n",
            "         [ 0.6149, -0.0592,  0.8832,  ..., -0.1249, -0.5219, -0.8987]],\n",
            "\n",
            "        [[ 0.6524, -0.3056,  1.1106,  ..., -0.2030, -0.5790, -0.9258],\n",
            "         [ 0.5305, -0.1430,  1.0465,  ..., -0.0321, -0.6635, -0.6973],\n",
            "         [ 0.5545, -0.2878,  1.0859,  ..., -0.0945, -0.6759, -0.6924],\n",
            "         ...,\n",
            "         [ 0.6483, -0.2844,  1.0884,  ..., -0.1190, -0.5936, -0.9373],\n",
            "         [ 0.6316, -0.2056,  1.1494,  ..., -0.0740, -0.6867, -0.9255],\n",
            "         [ 0.6312, -0.1776,  1.1474,  ..., -0.1389, -0.6937, -0.9395]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.8198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.8198, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/2:  38%|███▊      | 6/16 [00:05<00:09,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise tensor([[[ 1.5697,  0.5498,  0.7316,  ..., -0.1697, -0.5567,  0.4840],\n",
            "         [ 0.6392, -0.9335, -0.8470,  ..., -1.3609,  0.8486,  0.2678],\n",
            "         [ 0.0334, -0.8946,  0.4166,  ...,  0.1547,  1.7327,  0.0336],\n",
            "         ...,\n",
            "         [ 1.3874,  1.9229,  0.1925,  ...,  0.9724,  0.5604, -0.9580],\n",
            "         [-0.9727,  0.9589, -0.5915,  ...,  1.6453, -0.5461,  1.1033],\n",
            "         [-0.5654,  0.3578, -0.2954,  ..., -0.0048,  0.1341, -0.9589]],\n",
            "\n",
            "        [[-0.3087, -0.2174,  0.7173,  ..., -0.5178, -0.2685, -0.1521],\n",
            "         [-1.1606, -0.8316, -1.1280,  ...,  0.0590,  0.2645, -0.1820],\n",
            "         [ 0.8097,  0.6434,  0.0517,  ..., -0.7555, -1.4706,  0.7924],\n",
            "         ...,\n",
            "         [-1.6919,  0.7080,  1.3542,  ...,  1.6986, -1.6678, -0.4181],\n",
            "         [ 2.2563,  0.2707,  1.2261,  ...,  1.3976, -0.5849,  0.4229],\n",
            "         [-0.4722,  0.6008,  0.4871,  ..., -0.0851,  0.2104,  1.4147]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.6522, -0.1007,  1.1203,  ..., -0.1547, -0.3273, -0.6213],\n",
            "         [ 0.7372, -0.1181,  1.0276,  ..., -0.1951, -0.3960, -0.6526],\n",
            "         [ 0.4690, -0.3092,  0.8606,  ..., -0.0393, -0.5035, -0.6687],\n",
            "         ...,\n",
            "         [ 0.5987, -0.1365,  1.0205,  ..., -0.1902, -0.4984, -0.5707],\n",
            "         [ 0.6161, -0.2475,  0.9235,  ..., -0.3095, -0.5629, -0.6355],\n",
            "         [ 0.5658, -0.1464,  0.9923,  ..., -0.1720, -0.6822, -0.5173]],\n",
            "\n",
            "        [[ 0.8811, -0.0899,  1.3920,  ..., -0.0907, -0.5447, -1.1832],\n",
            "         [ 0.8449, -0.0866,  1.3492,  ...,  0.0023, -0.6552, -1.1267],\n",
            "         [ 0.7809,  0.0476,  1.2699,  ..., -0.1498, -0.5059, -1.0944],\n",
            "         ...,\n",
            "         [ 0.9100, -0.0301,  1.4373,  ...,  0.0535, -0.7707, -1.0324],\n",
            "         [ 0.8163, -0.2227,  1.5186,  ...,  0.0069, -0.7011, -0.9022],\n",
            "         [ 0.7935, -0.2186,  1.3066,  ...,  0.1813, -0.6732, -0.8831]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(0.9961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(0.9961, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/2:  44%|████▍     | 7/16 [00:08<00:13,  1.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise tensor([[[ 2.1117, -1.4384,  0.1211,  ..., -2.2285,  1.1697,  0.6106],\n",
            "         [ 0.9197, -1.3406, -0.1112,  ..., -1.5097,  1.1070, -0.2379],\n",
            "         [-0.3557,  0.5102,  0.4331,  ..., -1.8347,  0.6130,  1.4325],\n",
            "         ...,\n",
            "         [ 1.0930, -0.4229, -0.0327,  ...,  1.4033, -0.3058, -0.7585],\n",
            "         [ 0.6479, -0.2907,  1.1541,  ...,  1.3627, -0.1988,  0.6174],\n",
            "         [ 0.6945, -0.3294,  1.2138,  ...,  1.2068, -0.9395,  1.7711]],\n",
            "\n",
            "        [[ 1.0864,  1.0709, -1.2189,  ...,  0.1185, -0.4019,  1.3401],\n",
            "         [-0.0571,  0.2395,  0.0733,  ...,  0.5801,  0.6165, -0.3642],\n",
            "         [-1.5041,  1.3168,  0.0319,  ...,  1.4035,  0.8719,  0.3612],\n",
            "         ...,\n",
            "         [-2.2927,  0.4803,  0.1457,  ...,  0.4928,  0.1735, -0.6156],\n",
            "         [ 1.4627, -0.6796,  0.2957,  ...,  1.4099, -0.8445,  0.3261],\n",
            "         [ 0.3348,  1.2233, -1.0656,  ...,  0.2969, -1.3419, -0.0806]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.5232, -0.3256,  1.2295,  ..., -0.3079, -0.2297, -0.8874],\n",
            "         [ 0.4214, -0.3204,  1.3550,  ..., -0.3723, -0.2785, -0.8831],\n",
            "         [ 0.4373, -0.3183,  1.1742,  ..., -0.1064, -0.3052, -0.8761],\n",
            "         ...,\n",
            "         [ 0.5535, -0.2211,  1.2988,  ..., -0.4624, -0.3254, -0.7802],\n",
            "         [ 0.5705, -0.1729,  1.1809,  ..., -0.4216, -0.2076, -0.8031],\n",
            "         [ 0.6214, -0.1925,  1.1291,  ..., -0.3442, -0.2356, -0.8138]],\n",
            "\n",
            "        [[ 0.9502, -0.0391,  1.4255,  ..., -0.0804, -0.5193, -1.1533],\n",
            "         [ 0.9582, -0.0841,  1.2702,  ..., -0.1246, -0.6010, -1.1222],\n",
            "         [ 0.9859, -0.0509,  1.2645,  ..., -0.1947, -0.5333, -1.1047],\n",
            "         ...,\n",
            "         [ 1.0439, -0.0735,  1.3263,  ..., -0.0280, -0.8700, -1.0764],\n",
            "         [ 0.9438, -0.2080,  1.4220,  ...,  0.0338, -0.7131, -1.1792],\n",
            "         [ 0.9176, -0.1137,  1.5492,  ...,  0.0804, -0.5684, -1.1064]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.3572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.3572, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/2:  50%|█████     | 8/16 [00:09<00:10,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/2:  56%|█████▋    | 9/16 [00:09<00:08,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-6.5851e-01,  8.6938e-02,  6.5485e-01,  ...,  1.7307e+00,\n",
            "          -1.0328e+00,  2.0915e+00],\n",
            "         [-5.3142e-01,  6.5801e-01,  6.5770e-01,  ...,  3.6711e-01,\n",
            "          -8.3967e-01,  1.2414e+00],\n",
            "         [-1.6119e+00, -9.7821e-01,  2.9320e+00,  ..., -1.4974e+00,\n",
            "          -2.2897e+00, -7.0702e-01],\n",
            "         ...,\n",
            "         [ 4.3068e-01, -9.8371e-01,  2.3280e-01,  ..., -1.4632e+00,\n",
            "           4.4197e-01, -1.4141e+00],\n",
            "         [-5.2931e-01,  5.5782e-01,  3.9609e-01,  ...,  1.2207e+00,\n",
            "          -8.5539e-01,  1.2787e+00],\n",
            "         [ 2.7056e-01,  6.6592e-01,  8.5356e-01,  ...,  1.2092e+00,\n",
            "          -6.6081e-01, -6.6839e-01]],\n",
            "\n",
            "        [[-4.6050e-01, -5.7550e-01,  3.2103e-01,  ..., -1.6363e+00,\n",
            "          -8.3806e-01, -7.8097e-01],\n",
            "         [ 9.3146e-01, -6.4871e-01, -2.0855e-04,  ..., -3.3733e-02,\n",
            "          -9.2460e-01,  1.6275e+00],\n",
            "         [ 4.7652e-01, -2.1246e+00,  3.6561e-02,  ...,  4.7460e-01,\n",
            "          -5.2909e-01, -5.5881e-01],\n",
            "         ...,\n",
            "         [-2.6185e+00, -2.0588e+00, -1.2664e+00,  ...,  2.1103e-01,\n",
            "           1.1628e+00,  6.9182e-01],\n",
            "         [ 1.2168e-01,  7.0527e-02, -1.4393e+00,  ...,  8.6042e-03,\n",
            "          -3.3413e-01,  2.8392e-03],\n",
            "         [-9.2928e-01,  5.5976e-01,  2.5556e-01,  ...,  1.4176e+00,\n",
            "          -9.7293e-01,  1.6542e+00]]], device='cuda:0')\n",
            "diff losses pred noise tensor([[[-0.0345, -0.2734,  0.6045,  ..., -0.1916, -0.1438,  0.4448],\n",
            "         [-0.0971, -0.3956,  0.5779,  ..., -0.1981, -0.0231,  0.5156],\n",
            "         [-0.1641, -0.3347,  0.5064,  ..., -0.2626, -0.0104,  0.6243],\n",
            "         ...,\n",
            "         [-0.2882, -0.3684,  0.5810,  ..., -0.2243,  0.0257,  0.7249],\n",
            "         [-0.3544, -0.2914,  0.5799,  ..., -0.1787,  0.0606,  0.6699],\n",
            "         [-0.1233, -0.2833,  0.6191,  ..., -0.3494,  0.0554,  0.6023]],\n",
            "\n",
            "        [[ 0.6024, -0.2356,  1.1643,  ...,  0.0033, -0.5307, -0.9202],\n",
            "         [ 0.6385, -0.2950,  1.1408,  ...,  0.0167, -0.5644, -0.9170],\n",
            "         [ 0.6271, -0.3048,  1.1653,  ...,  0.0040, -0.5639, -0.9172],\n",
            "         ...,\n",
            "         [ 0.4763, -0.3475,  1.1518,  ..., -0.2581, -0.5899, -0.9267],\n",
            "         [ 0.5826, -0.1945,  1.1974,  ...,  0.0102, -0.5164, -0.9831],\n",
            "         [ 0.5713, -0.2933,  1.2168,  ..., -0.1662, -0.7179, -1.0149]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.0411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.0411, device='cuda:0', grad_fn=<ClampBackward1>)\n",
            "diff losses noise tensor([[[-2.4545,  2.1200, -3.1711,  ...,  0.0471,  0.0093, -0.3952],\n",
            "         [ 2.8661, -0.1860,  0.0212,  ...,  2.8279, -1.1492,  0.6064],\n",
            "         [ 1.0952, -0.5065,  0.8820,  ..., -0.6419, -0.3925,  1.3073],\n",
            "         ...,\n",
            "         [-1.2063, -1.7439, -1.8422,  ..., -2.3047, -1.4155, -0.7834],\n",
            "         [ 1.3300,  0.5133,  0.4322,  ...,  0.7607, -0.3900,  0.5709],\n",
            "         [ 0.7712, -2.0568,  0.0476,  ..., -0.3265, -0.8638, -1.3477]],\n",
            "\n",
            "        [[-0.0355,  0.0609, -0.2583,  ..., -0.4472, -1.5155, -0.8136],\n",
            "         [ 0.6765,  1.4568,  1.1743,  ..., -0.2355,  0.2503,  0.2342],\n",
            "         [ 1.3806, -0.3660, -1.2926,  ..., -2.9910,  0.1554, -1.6720],\n",
            "         ...,\n",
            "         [ 0.0816,  0.3277, -1.5158,  ...,  0.8938, -1.0432,  0.1193],\n",
            "         [ 1.5853,  0.8948,  0.5896,  ..., -0.1175,  0.8755,  0.2505],\n",
            "         [ 1.8273,  0.2100, -1.6076,  ..., -1.6167, -0.1409,  0.1934]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.3394, -0.5205,  0.9461,  ..., -0.2458, -0.4025, -0.4902],\n",
            "         [ 0.1426, -0.6049,  1.0614,  ..., -0.1846, -0.3448, -0.3157],\n",
            "         [ 0.2831, -0.4378,  1.1237,  ..., -0.2012, -0.3798, -0.4214],\n",
            "         ...,\n",
            "         [ 0.2848, -0.2176,  0.9770,  ...,  0.0203, -0.5402, -0.4175],\n",
            "         [ 0.4794, -0.4212,  0.9788,  ..., -0.1771, -0.5156, -0.4600],\n",
            "         [ 0.4568, -0.2609,  1.0563,  ...,  0.1451, -0.6970, -0.5186]],\n",
            "\n",
            "        [[-0.4315, -0.6541,  0.2801,  ..., -0.4196,  0.1457,  0.9008],\n",
            "         [-0.5028, -0.6522,  0.2703,  ..., -0.3117,  0.0586,  0.8544],\n",
            "         [-0.5232, -0.8710,  0.2220,  ..., -0.5576,  0.3250,  0.8386],\n",
            "         ...,\n",
            "         [-0.1654, -0.8076, -0.0674,  ..., -0.7363,  0.1242,  0.7950],\n",
            "         [-0.1307, -0.6219,  0.0777,  ..., -0.5271,  0.1113,  0.9632],\n",
            "         [-0.1657, -0.7284,  0.0963,  ..., -0.4963,  0.1269,  0.9906]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.3765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.3765, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/2:  62%|██████▎   | 10/16 [00:10<00:06,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/2:  69%|██████▉   | 11/16 [00:11<00:04,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0539,  0.7175, -1.8488,  ..., -0.1367,  0.2762, -0.9402],\n",
            "         [ 0.4404,  0.6517,  0.5258,  ..., -0.5169, -0.7994, -0.9097],\n",
            "         [-0.1808,  0.7725,  1.2945,  ..., -1.3495,  0.8362, -0.3448],\n",
            "         ...,\n",
            "         [ 1.0710,  1.0433, -2.2317,  ..., -1.9804,  0.6214,  0.0926],\n",
            "         [-0.6258, -0.1983, -0.0540,  ..., -1.1930, -0.4970,  0.3238],\n",
            "         [ 0.2620, -0.2336,  0.5943,  ...,  0.5095,  0.1268, -0.7894]],\n",
            "\n",
            "        [[ 0.4339, -0.7534, -1.5148,  ...,  0.3775,  0.8937, -0.9689],\n",
            "         [ 0.6221, -0.8938, -0.0534,  ..., -1.7793,  1.0566,  2.0104],\n",
            "         [ 0.3458,  1.8050,  0.3405,  ..., -2.0209, -0.1209,  0.1063],\n",
            "         ...,\n",
            "         [ 0.1286,  0.1942, -0.4821,  ..., -0.8799,  0.8634, -1.4567],\n",
            "         [-0.1530,  0.5625, -0.2434,  ...,  0.6592, -0.4215, -0.7820],\n",
            "         [ 1.5194,  0.6235,  0.0233,  ..., -0.5911, -1.7365, -0.7700]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.2084, -0.2785,  1.0350,  ..., -0.1453, -0.4764, -0.3532],\n",
            "         [ 0.2319, -0.4124,  0.9915,  ..., -0.2114, -0.3830, -0.1917],\n",
            "         [ 0.2580, -0.3592,  1.1166,  ..., -0.2554, -0.3257, -0.2316],\n",
            "         ...,\n",
            "         [ 0.4873, -0.5021,  0.7849,  ..., -0.2414, -0.3785, -0.6293],\n",
            "         [ 0.3667, -0.4645,  0.8341,  ..., -0.2752, -0.3001, -0.4787],\n",
            "         [ 0.3825, -0.4840,  0.7899,  ..., -0.3667, -0.4511, -0.4303]],\n",
            "\n",
            "        [[-0.3121, -0.4640,  0.4391,  ..., -0.1703,  0.1983,  0.6869],\n",
            "         [-0.2083, -0.5788,  0.4829,  ..., -0.1210,  0.2796,  0.5675],\n",
            "         [-0.3210, -0.4941,  0.4755,  ..., -0.2790,  0.0947,  0.6278],\n",
            "         ...,\n",
            "         [-0.0190, -0.5429,  0.4105,  ..., -0.2974,  0.4216,  0.7021],\n",
            "         [ 0.1331, -0.5382,  0.2130,  ..., -0.2239,  0.3149,  0.6146],\n",
            "         [ 0.0362, -0.5321,  0.3256,  ..., -0.2506,  0.3699,  0.6504]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.9711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.9711, device='cuda:0', grad_fn=<ClampBackward1>)\n",
            "diff losses noise tensor([[[ 1.5643, -0.6475,  0.3966,  ..., -0.1019, -0.1924,  0.0302],\n",
            "         [ 0.0532, -1.6533,  0.5972,  ...,  0.2918, -0.3217, -0.2903],\n",
            "         [ 0.2830,  0.7828,  0.5930,  ..., -0.0521,  1.4838, -0.5295],\n",
            "         ...,\n",
            "         [-1.5103, -0.7426, -2.2209,  ..., -0.3040, -0.0244, -0.6628],\n",
            "         [ 1.4502, -0.3858, -1.3886,  ...,  0.9299,  1.5715, -0.7068],\n",
            "         [-2.8288, -0.3082,  0.4924,  ..., -0.7426, -0.4381, -0.3629]],\n",
            "\n",
            "        [[-0.2778,  0.1958, -0.2565,  ..., -0.0753, -0.5122, -0.2258],\n",
            "         [-0.1529,  0.2746, -0.4683,  ...,  0.4463, -1.6320, -0.1734],\n",
            "         [-0.9243,  0.2646,  0.1142,  ..., -1.5981, -0.6531, -0.4246],\n",
            "         ...,\n",
            "         [ 0.0564,  1.0260, -0.2946,  ..., -0.5392,  1.0781, -1.7253],\n",
            "         [-0.6062, -1.8899, -2.0740,  ...,  1.8575,  0.6040,  1.3822],\n",
            "         [-1.1315, -1.1456,  1.4467,  ..., -0.3952,  1.1160,  0.3957]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.7343, -0.1285,  1.0769,  ..., -0.1268, -0.4814, -0.9893],\n",
            "         [ 0.7008, -0.1487,  1.1070,  ..., -0.1424, -0.3725, -0.9464],\n",
            "         [ 0.7187, -0.1001,  1.2830,  ..., -0.1145, -0.5703, -1.1704],\n",
            "         ...,\n",
            "         [ 0.4664, -0.4360,  1.1431,  ..., -0.1099, -0.6847, -0.9629],\n",
            "         [ 0.4753, -0.3220,  1.1415,  ..., -0.1640, -0.5441, -0.8353],\n",
            "         [ 0.4540, -0.2526,  1.1634,  ..., -0.1644, -0.5212, -0.7667]],\n",
            "\n",
            "        [[ 0.5994, -0.3544,  1.0251,  ..., -0.3393, -0.3717, -0.9140],\n",
            "         [ 0.5097, -0.2517,  0.9770,  ..., -0.0992, -0.3714, -0.7162],\n",
            "         [ 0.4724, -0.3864,  0.9765,  ..., -0.2086, -0.5026, -0.7834],\n",
            "         ...,\n",
            "         [ 0.5353, -0.4197,  0.8415,  ..., -0.0423, -0.6915, -0.6723],\n",
            "         [ 0.5331, -0.5260,  0.8244,  ..., -0.0376, -0.6838, -0.6678],\n",
            "         [ 0.5206, -0.7290,  0.9169,  ..., -0.2045, -0.8208, -0.7758]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.8859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.8859, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/2:  75%|███████▌  | 12/16 [00:12<00:04,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/2:  81%|████████▏ | 13/16 [00:13<00:02,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.0904e+00, -2.2006e+00,  1.2265e+00,  ...,  3.2486e-01,\n",
            "          -1.5321e+00,  1.3794e+00],\n",
            "         [-6.8281e-01, -6.9396e-02,  6.1698e-01,  ..., -3.8423e-01,\n",
            "           3.7870e-01, -3.0049e-01],\n",
            "         [ 3.7481e-01,  1.0666e+00, -1.7876e+00,  ..., -1.5945e-01,\n",
            "           1.3836e+00, -1.3171e+00],\n",
            "         ...,\n",
            "         [-1.5451e+00,  6.8987e-02,  1.1091e-01,  ...,  2.2000e-02,\n",
            "          -1.2992e-01,  5.9116e-01],\n",
            "         [-1.4562e+00, -2.8234e+00,  1.0318e+00,  ..., -1.2918e+00,\n",
            "          -1.9345e+00, -8.3830e-01],\n",
            "         [ 6.0387e-01, -5.8506e-01, -2.2793e+00,  ..., -1.2041e+00,\n",
            "          -1.1869e-04, -7.0956e-01]],\n",
            "\n",
            "        [[ 7.0987e-01, -5.0845e-01, -7.1503e-01,  ..., -9.6498e-01,\n",
            "           5.6068e-02,  5.0500e-02],\n",
            "         [ 2.4888e-01, -3.7374e-01, -1.8811e-01,  ...,  1.5514e+00,\n",
            "           7.2540e-01,  1.4024e+00],\n",
            "         [ 6.4393e-01, -4.7311e+00, -4.7937e-01,  ..., -1.0608e+00,\n",
            "          -5.6139e-01, -4.2563e-02],\n",
            "         ...,\n",
            "         [-7.1274e-01,  3.3757e-01,  7.7341e-01,  ...,  1.7670e-01,\n",
            "          -1.1968e-01,  1.1646e+00],\n",
            "         [ 6.3226e-01,  5.6974e-02,  9.3362e-01,  ...,  5.4815e-01,\n",
            "          -1.2810e-01, -1.2849e+00],\n",
            "         [ 1.5205e+00, -3.2408e-01,  9.1536e-02,  ..., -1.8719e+00,\n",
            "           5.9760e-01,  2.1006e-02]]], device='cuda:0')\n",
            "diff losses pred noise tensor([[[-0.0199, -0.5442,  0.7957,  ..., -0.2056, -0.0932, -0.0521],\n",
            "         [ 0.0054, -0.4399,  0.6556,  ..., -0.2399, -0.0589, -0.0163],\n",
            "         [ 0.1122, -0.4907,  0.6080,  ..., -0.2436, -0.0830, -0.0497],\n",
            "         ...,\n",
            "         [ 0.1181, -0.5143,  1.0071,  ..., -0.1156, -0.2060, -0.1052],\n",
            "         [ 0.0756, -0.5166,  0.9248,  ..., -0.0439, -0.1911, -0.1118],\n",
            "         [ 0.0048, -0.4737,  0.8043,  ...,  0.0445, -0.3538, -0.0666]],\n",
            "\n",
            "        [[ 0.4787, -0.4835,  1.2035,  ..., -0.4135, -0.1389, -0.5672],\n",
            "         [ 0.4815, -0.3942,  1.1952,  ..., -0.5603, -0.3504, -0.6885],\n",
            "         [ 0.4873, -0.2236,  1.2431,  ..., -0.3400, -0.2955, -0.4167],\n",
            "         ...,\n",
            "         [ 0.4943, -0.1060,  1.1219,  ..., -0.2221, -0.5470, -0.6397],\n",
            "         [ 0.5558, -0.4066,  1.1305,  ..., -0.3845, -0.5728, -0.7187],\n",
            "         [ 0.4604, -0.4855,  1.1198,  ..., -0.2965, -0.5591, -0.5936]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.9296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.9296, device='cuda:0', grad_fn=<ClampBackward1>)\n",
            "diff losses noise tensor([[[-2.2577e-01, -3.8502e-02,  1.6704e+00,  ..., -7.7590e-01,\n",
            "           1.1701e+00,  1.2331e+00],\n",
            "         [ 1.4604e+00,  1.0562e+00,  1.6721e+00,  ...,  5.4960e-03,\n",
            "          -7.1783e-01, -9.8205e-02],\n",
            "         [-2.7345e-01,  1.8245e+00, -1.1022e+00,  ...,  1.3183e+00,\n",
            "          -5.1813e-01, -4.1863e-01],\n",
            "         ...,\n",
            "         [-4.1899e-01,  1.6266e+00, -1.1039e+00,  ..., -1.4233e-01,\n",
            "          -4.4069e-02, -1.9555e+00],\n",
            "         [ 5.1057e-01,  1.8384e+00, -1.1232e-01,  ..., -1.4474e-03,\n",
            "           6.2917e-01,  1.6210e+00],\n",
            "         [-8.2073e-01, -1.8399e+00,  5.5124e-01,  ..., -9.2869e-01,\n",
            "          -3.5767e-01,  2.4200e+00]],\n",
            "\n",
            "        [[ 1.1058e-01, -2.3857e-01,  1.3845e+00,  ..., -4.3078e-01,\n",
            "           1.5208e+00, -6.0205e-02],\n",
            "         [ 1.9991e+00,  3.8095e-01, -9.3946e-01,  ..., -1.3075e+00,\n",
            "          -7.3693e-01,  3.9525e-01],\n",
            "         [ 8.2682e-01,  1.5291e+00,  1.7182e+00,  ...,  2.3638e+00,\n",
            "          -1.0474e+00,  1.9722e+00],\n",
            "         ...,\n",
            "         [ 6.3871e-01, -1.3196e+00,  2.3226e-01,  ...,  1.0032e-01,\n",
            "           1.1544e+00,  8.8562e-01],\n",
            "         [ 1.9196e-01,  6.2915e-01, -1.9375e-01,  ...,  1.7235e+00,\n",
            "          -6.7821e-02, -3.2150e-01],\n",
            "         [ 8.5805e-01,  2.7172e-03,  5.7740e-01,  ..., -4.8991e-01,\n",
            "          -9.9247e-01,  1.0460e+00]]], device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.2791, -0.4547,  0.8405,  ..., -0.2364, -0.0447, -0.6444],\n",
            "         [ 0.2428, -0.3329,  0.6881,  ..., -0.1678, -0.1593, -0.5298],\n",
            "         [ 0.1424, -0.4606,  0.8321,  ..., -0.1273, -0.2163, -0.4133],\n",
            "         ...,\n",
            "         [ 0.1928, -0.4494,  0.7901,  ..., -0.2902, -0.1597, -0.5017],\n",
            "         [ 0.2501, -0.3556,  0.7911,  ..., -0.1910, -0.2545, -0.6233],\n",
            "         [ 0.2820, -0.2990,  0.7903,  ..., -0.1814, -0.1989, -0.4705]],\n",
            "\n",
            "        [[ 0.3846, -0.2239,  1.2267,  ..., -0.1445, -0.7385, -0.9336],\n",
            "         [ 0.4066, -0.3292,  1.1729,  ..., -0.1132, -0.7323, -0.9546],\n",
            "         [ 0.4209, -0.2207,  1.0629,  ...,  0.0219, -0.6707, -0.8751],\n",
            "         ...,\n",
            "         [ 0.5580, -0.0508,  1.0236,  ...,  0.0536, -0.6451, -0.8491],\n",
            "         [ 0.4957, -0.0292,  0.8994,  ...,  0.0254, -0.6811, -0.7144],\n",
            "         [ 0.5585, -0.1176,  1.0131,  ...,  0.0112, -0.6308, -0.7560]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.2779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.2779, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/2:  88%|████████▊ | 14/16 [00:14<00:02,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/2:  94%|█████████▍| 15/16 [00:15<00:01,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.2389, -0.3420, -0.6245,  ..., -0.4474,  0.5128,  0.3112],\n",
            "         [-0.8060, -1.8258,  0.4261,  ..., -0.9274, -0.4002, -0.5020],\n",
            "         [ 0.1801, -0.0800,  1.0731,  ..., -0.7691, -0.0191, -0.2088],\n",
            "         ...,\n",
            "         [ 0.8758, -0.4802,  0.3087,  ..., -1.9987, -1.7520,  0.9752],\n",
            "         [ 0.1470, -0.8850, -0.3446,  ..., -2.2561,  0.7832, -0.5034],\n",
            "         [-2.0061,  1.0381,  1.0687,  ...,  0.3202,  0.0490, -0.6701]],\n",
            "\n",
            "        [[ 2.1394, -0.7484,  0.3038,  ...,  0.4629, -0.5528,  0.1858],\n",
            "         [-1.3045, -0.5608,  0.8945,  ...,  1.6529,  0.4555, -0.1916],\n",
            "         [ 0.9894, -1.3652,  1.9205,  ..., -0.8837,  0.6285, -0.0197],\n",
            "         ...,\n",
            "         [ 0.2187,  0.9586, -1.9156,  ..., -0.0427, -0.1313,  0.6492],\n",
            "         [-0.0428,  1.3496, -2.1602,  ..., -0.9164, -0.0452, -0.0182],\n",
            "         [-0.6043, -0.4762,  0.3986,  ...,  0.7256,  1.4938, -2.1189]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.1789, -0.5748,  0.8634,  ..., -0.0240, -0.3241, -0.3293],\n",
            "         [ 0.2022, -0.5324,  0.7870,  ...,  0.0444, -0.3438, -0.3605],\n",
            "         [ 0.2556, -0.4992,  0.8020,  ...,  0.0050, -0.3510, -0.4233],\n",
            "         ...,\n",
            "         [ 0.2402, -0.5205,  0.8300,  ...,  0.1085, -0.1583, -0.1164],\n",
            "         [ 0.2256, -0.5945,  0.9138,  ...,  0.0589, -0.2448, -0.1815],\n",
            "         [ 0.3556, -0.5227,  0.8709,  ..., -0.0110, -0.1353, -0.1468]],\n",
            "\n",
            "        [[ 0.1251, -0.6832,  0.5603,  ..., -0.3341, -0.1291, -0.0424],\n",
            "         [ 0.1667, -0.7164,  0.6644,  ..., -0.3583, -0.0902, -0.0291],\n",
            "         [ 0.1405, -0.6450,  0.6703,  ..., -0.3759, -0.0852, -0.0407],\n",
            "         ...,\n",
            "         [ 0.1196, -0.4410,  0.8203,  ..., -0.0236, -0.2699, -0.1254],\n",
            "         [ 0.2045, -0.4920,  0.5932,  ..., -0.0808, -0.2818, -0.2590],\n",
            "         [ 0.1755, -0.5457,  0.6810,  ..., -0.0849, -0.1432, -0.0545]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.7637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.7637, device='cuda:0', grad_fn=<ClampBackward1>)\n",
            "diff losses noise "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/2: 100%|██████████| 16/16 [00:16<00:00,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.5150,  1.0293, -1.8218,  ..., -0.2439,  0.7389,  0.3740],\n",
            "         [-0.0599,  0.4119,  0.8739,  ..., -2.1799, -1.5756,  0.3463],\n",
            "         [ 2.0096,  1.0529,  0.5451,  ..., -1.0400,  0.7469, -0.9038],\n",
            "         ...,\n",
            "         [ 0.4041,  0.2758,  0.7674,  ...,  0.4657, -0.4734, -0.5934],\n",
            "         [ 0.4420,  0.2515, -0.5207,  ..., -2.1626, -0.4189,  0.1420],\n",
            "         [ 0.5660, -0.5856,  0.3038,  ...,  1.3634, -0.0044,  1.9755]],\n",
            "\n",
            "        [[ 0.9384,  1.0113,  1.1931,  ..., -0.6985,  1.2484, -0.0796],\n",
            "         [ 0.3112, -0.6439,  0.0767,  ...,  0.0420,  0.6787,  0.2718],\n",
            "         [ 0.3703,  0.5169,  0.7055,  ...,  1.3179,  0.3560, -0.8310],\n",
            "         ...,\n",
            "         [ 0.4113, -0.4258, -0.4188,  ..., -0.5458, -0.0935,  0.2932],\n",
            "         [-0.8956,  0.6307,  1.8964,  ..., -0.3029, -0.7920,  0.0426],\n",
            "         [ 0.1058, -1.4020, -1.4159,  ..., -2.1034, -0.9799, -1.1936]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.2266, -0.5904,  0.8743,  ..., -0.0790, -0.6164, -0.4120],\n",
            "         [ 0.3412, -0.5454,  0.8171,  ..., -0.1200, -0.6176, -0.4543],\n",
            "         [ 0.2151, -0.4749,  0.9070,  ..., -0.0014, -0.5445, -0.4862],\n",
            "         ...,\n",
            "         [ 0.3516, -0.3921,  0.9647,  ..., -0.1675, -0.4468, -0.7434],\n",
            "         [ 0.2851, -0.3782,  1.0048,  ..., -0.1113, -0.4721, -0.6767],\n",
            "         [ 0.2519, -0.4042,  0.9314,  ..., -0.1497, -0.4404, -0.6614]],\n",
            "\n",
            "        [[ 0.7200, -0.2809,  1.0730,  ..., -0.2685, -0.5430, -0.8580],\n",
            "         [ 0.6651, -0.0669,  0.9070,  ..., -0.0937, -0.5225, -0.8491],\n",
            "         [ 0.6508, -0.0439,  1.0341,  ..., -0.1098, -0.5257, -0.8231],\n",
            "         ...,\n",
            "         [ 0.6891, -0.3549,  1.1846,  ..., -0.1925, -0.7572, -0.9560],\n",
            "         [ 0.7254, -0.2478,  1.1095,  ..., -0.1090, -0.7679, -0.9282],\n",
            "         [ 0.8387, -0.2841,  1.0505,  ..., -0.3669, -0.7457, -1.0139]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
            "diff loss tensor(1.8925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "diff loss clipped tensor(1.8925, device='cuda:0', grad_fn=<ClampBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/2: 100%|██████████| 16/16 [00:16<00:00,  1.03s/it]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n",
            "<ipython-input-10-2979545277c5>:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  padded_energy_scores = [F.pad(torch.tensor(score, dtype=torch.float32), (1, 1), value=0) for score in energy_scores]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff losses noise tensor([[[-0.1219,  0.8643,  1.0280,  ...,  1.1698, -0.3747, -1.3045],\n",
            "         [-0.8010, -0.2555,  0.9117,  ...,  2.4482, -0.1058,  1.2987],\n",
            "         [-2.4554,  0.6692,  0.9251,  ..., -0.6640,  0.9014, -1.5944],\n",
            "         ...,\n",
            "         [-0.2241, -0.4696,  0.7909,  ..., -0.4993, -0.7266,  1.5716],\n",
            "         [-0.1769, -0.0088,  1.1582,  ..., -1.2264,  0.4212, -0.0602],\n",
            "         [ 0.2948, -2.2917, -0.7478,  ...,  0.9979,  0.3334,  0.5495]],\n",
            "\n",
            "        [[ 2.1881, -1.4908, -1.1211,  ...,  0.7571, -0.1989,  1.1085],\n",
            "         [-0.3789,  0.9627, -0.1982,  ...,  0.1978, -1.0389, -1.5679],\n",
            "         [-0.6167, -0.4168, -0.7497,  ..., -0.2893, -2.2037,  1.4004],\n",
            "         ...,\n",
            "         [-0.5978, -0.5242, -0.5017,  ...,  1.1490,  1.1187, -0.3626],\n",
            "         [ 1.7591, -1.6692, -0.6609,  ...,  1.2131,  0.5113, -2.1193],\n",
            "         [-0.4416,  0.5621,  1.3332,  ...,  0.4102,  0.1856,  0.8003]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.6597, -0.2333,  1.0314,  ..., -0.1484, -0.6372, -0.8583],\n",
            "         [ 0.5414, -0.3012,  1.0781,  ..., -0.2000, -0.6138, -0.9392],\n",
            "         [ 0.3933, -0.3855,  1.0333,  ..., -0.2077, -0.5922, -0.7841],\n",
            "         ...,\n",
            "         [ 0.4835, -0.3473,  1.0133,  ..., -0.1328, -0.6375, -0.7315],\n",
            "         [ 0.5045, -0.3657,  0.9370,  ..., -0.0143, -0.6289, -0.7613],\n",
            "         [ 0.5213, -0.3840,  0.9321,  ..., -0.0504, -0.6852, -0.7592]],\n",
            "\n",
            "        [[-0.0460, -0.4815,  0.7548,  ...,  0.0452, -0.0222,  0.2072],\n",
            "         [-0.1207, -0.3701,  0.7414,  ...,  0.0432, -0.0766,  0.3036],\n",
            "         [-0.1133, -0.4014,  0.7117,  ...,  0.0234, -0.0783,  0.3544],\n",
            "         ...,\n",
            "         [-0.0673, -0.4500,  0.6600,  ..., -0.0078, -0.0128,  0.3639],\n",
            "         [-0.1360, -0.4984,  0.7232,  ...,  0.0499, -0.1112,  0.3073],\n",
            "         [ 0.0603, -0.4946,  0.7085,  ...,  0.0250, -0.1222,  0.2981]]],\n",
            "       device='cuda:0')\n",
            "diff loss tensor(1.5107, device='cuda:0')\n",
            "diff loss clipped tensor(1.5107, device='cuda:0')\n",
            "diff losses noise tensor([[[ 0.4141, -0.1297,  0.3956,  ...,  1.0352, -0.8637,  0.9453],\n",
            "         [ 0.1764,  0.5976,  0.2803,  ...,  1.1509,  1.7564,  0.4293],\n",
            "         [-0.8783, -1.0744,  0.7287,  ..., -0.2396,  2.9407,  1.7978],\n",
            "         ...,\n",
            "         [ 1.3605,  0.9269,  2.0573,  ..., -2.0816, -0.2709, -0.0347],\n",
            "         [-0.6647,  0.0070,  0.7107,  ...,  0.2025,  0.7596,  0.8044],\n",
            "         [-0.3956, -1.6004,  0.8982,  ...,  0.0293,  0.2318,  1.5191]],\n",
            "\n",
            "        [[-1.8246, -0.0780,  0.3633,  ...,  0.3681, -0.5062,  0.3812],\n",
            "         [ 0.3369,  1.0350,  0.4072,  ...,  0.8691,  0.2472,  0.0161],\n",
            "         [ 1.3340, -0.4751, -0.2681,  ...,  0.8271,  0.7438, -0.3193],\n",
            "         ...,\n",
            "         [ 2.7389, -0.0995,  1.2312,  ...,  1.2554, -1.3232, -1.8884],\n",
            "         [-0.6808,  0.8301,  0.2157,  ...,  1.0534, -0.4625,  0.1022],\n",
            "         [-0.8888,  0.1146, -0.5674,  ..., -1.5385,  0.7127, -2.6624]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.5852, -0.2766,  1.3170,  ..., -0.3248, -0.5487, -0.9443],\n",
            "         [ 0.5518, -0.3540,  1.2428,  ..., -0.3879, -0.4808, -0.9599],\n",
            "         [ 0.3882, -0.3689,  1.1272,  ..., -0.2569, -0.3830, -0.7018],\n",
            "         ...,\n",
            "         [ 0.5503, -0.2225,  1.0893,  ..., -0.1137, -0.7758, -0.7008],\n",
            "         [ 0.5692, -0.2425,  1.2106,  ..., -0.2400, -0.7092, -0.8356],\n",
            "         [ 0.5044, -0.2173,  1.1080,  ..., -0.1460, -0.6698, -0.8179]],\n",
            "\n",
            "        [[ 0.3743, -0.2812,  1.0298,  ..., -0.3397, -0.4544, -0.7279],\n",
            "         [ 0.4522, -0.3566,  0.9191,  ..., -0.3078, -0.4533, -0.7274],\n",
            "         [ 0.4280, -0.3445,  0.9082,  ..., -0.3085, -0.6077, -0.7014],\n",
            "         ...,\n",
            "         [ 0.4406, -0.2146,  1.1347,  ..., -0.0651, -0.5442, -0.7455],\n",
            "         [ 0.5943, -0.2095,  1.0161,  ..., -0.3765, -0.5468, -0.7714],\n",
            "         [ 0.5668, -0.2977,  0.9458,  ..., -0.3169, -0.5289, -0.6030]]],\n",
            "       device='cuda:0')\n",
            "diff loss tensor(1.7803, device='cuda:0')\n",
            "diff loss clipped tensor(1.7803, device='cuda:0')\n",
            "diff losses noise tensor([[[ 1.5882,  0.8186,  0.8184,  ..., -0.2194, -0.0332, -0.1975],\n",
            "         [-0.5740,  0.0158,  1.0430,  ..., -0.9225,  1.3034, -0.9740],\n",
            "         [-0.7156, -0.3191, -1.3697,  ...,  0.5802,  0.9400,  0.8821],\n",
            "         ...,\n",
            "         [ 0.6487, -0.5402,  2.3788,  ...,  1.2857,  0.6396,  0.4358],\n",
            "         [ 0.2762, -0.0162, -0.0431,  ...,  0.5927,  0.5648,  0.4933],\n",
            "         [ 0.9801,  0.5988,  1.8616,  ..., -0.4652,  0.0943, -0.6246]],\n",
            "\n",
            "        [[-2.0868,  0.2675, -0.5250,  ..., -0.0393,  0.9779, -0.6105],\n",
            "         [ 0.1099, -1.9306, -0.2584,  ...,  1.3242, -1.2738, -0.6918],\n",
            "         [ 0.2414, -0.5596, -0.6500,  ...,  0.6633, -0.4443,  0.5826],\n",
            "         ...,\n",
            "         [-0.9809, -0.4639,  0.6530,  ..., -0.0538, -0.1549,  1.3046],\n",
            "         [-1.7786, -0.1067, -1.4188,  ...,  2.1026, -0.2505,  1.3995],\n",
            "         [ 0.9720,  1.5694,  0.4809,  ..., -2.2429, -0.1109, -2.0561]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.6634, -0.3935,  1.0985,  ..., -0.4986, -0.2917, -0.8190],\n",
            "         [ 0.6141, -0.4140,  1.0430,  ..., -0.4511, -0.3822, -0.7663],\n",
            "         [ 0.5624, -0.3381,  0.9978,  ..., -0.2956, -0.5123, -0.8901],\n",
            "         ...,\n",
            "         [ 0.6761, -0.2193,  0.8966,  ..., -0.0938, -0.4854, -0.8364],\n",
            "         [ 0.5999, -0.1222,  0.8273,  ..., -0.0215, -0.4370, -0.6775],\n",
            "         [ 0.8020, -0.0537,  0.8113,  ..., -0.0475, -0.4219, -0.7545]],\n",
            "\n",
            "        [[ 0.1908, -0.4385,  1.0729,  ..., -0.3415, -0.0893, -0.2762],\n",
            "         [ 0.1565, -0.3308,  1.0884,  ..., -0.2973, -0.1372, -0.2624],\n",
            "         [ 0.1296, -0.2585,  0.9014,  ..., -0.1725, -0.1007, -0.1088],\n",
            "         ...,\n",
            "         [ 0.1237, -0.3514,  0.6662,  ..., -0.3319, -0.1203,  0.0687],\n",
            "         [ 0.1983, -0.3391,  0.7638,  ..., -0.4529, -0.2326, -0.0210],\n",
            "         [ 0.1466, -0.3634,  0.6762,  ..., -0.4257, -0.1820, -0.1083]]],\n",
            "       device='cuda:0')\n",
            "diff loss tensor(0.7697, device='cuda:0')\n",
            "diff loss clipped tensor(0.7697, device='cuda:0')\n",
            "diff losses noise tensor([[[-5.3993e-01,  5.0898e-02, -7.4972e-01,  ...,  1.4750e+00,\n",
            "           1.2854e+00,  2.6834e-01],\n",
            "         [-4.5956e-01, -1.6899e-02,  2.4290e-02,  ..., -1.1781e-01,\n",
            "           2.7590e-01, -1.1764e-01],\n",
            "         [-1.7701e+00,  6.9156e-01, -1.0548e+00,  ...,  3.8726e-01,\n",
            "           4.0791e-01, -2.0912e-01],\n",
            "         ...,\n",
            "         [-9.0377e-01, -5.6722e-01,  2.5617e-01,  ..., -5.9889e-01,\n",
            "          -3.7074e-01,  5.5257e-04],\n",
            "         [ 7.9380e-01,  4.5696e-04,  9.1886e-01,  ..., -1.0184e+00,\n",
            "           1.0712e-02,  1.2587e+00],\n",
            "         [-3.4075e-01,  4.3832e-01, -2.8414e-01,  ...,  1.1679e+00,\n",
            "           8.3201e-01,  1.8286e+00]],\n",
            "\n",
            "        [[ 1.0048e-01,  9.5075e-01,  1.0038e+00,  ..., -8.2535e-03,\n",
            "           9.8017e-01, -1.1753e-01],\n",
            "         [ 1.0003e+00, -9.3218e-02, -8.2137e-01,  ...,  3.3192e-01,\n",
            "          -8.0081e-01, -4.8658e-01],\n",
            "         [-1.2031e+00,  3.2753e-01,  2.1766e-01,  ...,  3.3786e-01,\n",
            "           2.3082e-01,  3.1113e-01],\n",
            "         ...,\n",
            "         [ 5.5192e-01,  8.9908e-01, -1.8280e-01,  ..., -1.2155e+00,\n",
            "          -2.4054e+00,  6.4609e-01],\n",
            "         [ 6.4989e-01, -4.3218e-02, -2.5917e+00,  ..., -1.1938e+00,\n",
            "           4.9885e-01,  3.5864e-01],\n",
            "         [-1.8508e-01, -5.2909e-01, -2.9275e-01,  ..., -3.8671e-01,\n",
            "           7.5183e-01,  8.0452e-01]]], device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.7161, -0.2831,  1.1434,  ..., -0.1463, -0.5771, -0.9395],\n",
            "         [ 0.6516, -0.2245,  1.1689,  ..., -0.1143, -0.5629, -0.7923],\n",
            "         [ 0.5854, -0.2239,  1.1999,  ..., -0.0676, -0.5775, -0.8550],\n",
            "         ...,\n",
            "         [ 0.7022, -0.2897,  1.1891,  ...,  0.0695, -0.6889, -0.9944],\n",
            "         [ 0.7702, -0.1670,  1.1343,  ...,  0.0846, -0.6251, -0.8565],\n",
            "         [ 0.6894, -0.2262,  1.0127,  ..., -0.0840, -0.5998, -0.8333]],\n",
            "\n",
            "        [[ 0.5836, -0.0586,  0.9821,  ..., -0.2033, -0.5422, -0.6857],\n",
            "         [ 0.6079, -0.0563,  1.0270,  ..., -0.2172, -0.5693, -0.7406],\n",
            "         [ 0.6241,  0.0175,  1.0668,  ..., -0.4081, -0.5293, -0.6861],\n",
            "         ...,\n",
            "         [ 0.5613, -0.0262,  0.9706,  ..., -0.1569, -0.6277, -0.5557],\n",
            "         [ 0.5172, -0.1351,  0.9902,  ..., -0.2719, -0.6260, -0.5868],\n",
            "         [ 0.5663, -0.0668,  1.0112,  ..., -0.2050, -0.7150, -0.5730]]],\n",
            "       device='cuda:0')\n",
            "diff loss tensor(1.0180, device='cuda:0')\n",
            "diff loss clipped tensor(1.0180, device='cuda:0')\n",
            "diff losses noise tensor([[[-1.3708,  0.2184, -0.8980,  ..., -0.1871, -0.0672,  1.8374],\n",
            "         [-2.5364,  0.0670,  0.1279,  ...,  0.3154, -1.0556, -1.8859],\n",
            "         [ 0.3235,  1.2064,  1.5329,  ..., -0.3640,  1.4501,  0.5760],\n",
            "         ...,\n",
            "         [ 2.8622, -0.7074,  0.7066,  ...,  0.2433,  0.7526,  0.4398],\n",
            "         [ 0.0726,  0.2021, -0.7512,  ...,  0.4121, -0.8268,  1.6774],\n",
            "         [ 1.0766,  0.8444,  0.1290,  ...,  0.7984, -0.3786, -0.1017]],\n",
            "\n",
            "        [[ 0.3992,  2.8813, -0.7419,  ...,  0.0844, -0.4186, -0.9770],\n",
            "         [-1.4656, -1.2288, -0.9254,  ..., -0.0937,  3.3947,  0.2383],\n",
            "         [ 0.3680, -0.0817, -0.2415,  ...,  0.4422, -0.1460, -0.9148],\n",
            "         ...,\n",
            "         [ 0.4768, -1.1615, -0.7293,  ..., -0.1102,  0.1247,  0.3840],\n",
            "         [-0.7541, -0.5379,  0.3823,  ..., -0.9196, -1.1181,  0.4820],\n",
            "         [-0.4980,  0.2003,  0.5770,  ...,  0.0612, -0.0182, -0.0670]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.2737, -0.2735,  0.7665,  ..., -0.2889, -0.2074, -0.5432],\n",
            "         [ 0.2935, -0.3136,  0.7689,  ..., -0.2834, -0.1468, -0.5184],\n",
            "         [ 0.3310, -0.2654,  0.7522,  ..., -0.2468, -0.2281, -0.5642],\n",
            "         ...,\n",
            "         [ 0.3367, -0.3150,  0.8066,  ..., -0.1086, -0.4034, -0.4918],\n",
            "         [ 0.2741, -0.3753,  0.8833,  ..., -0.1686, -0.3705, -0.4853],\n",
            "         [ 0.1404, -0.3966,  0.7986,  ..., -0.2665, -0.3149, -0.5105]],\n",
            "\n",
            "        [[ 1.0013, -0.1873,  1.3653,  ..., -0.4350, -0.6209, -1.3616],\n",
            "         [ 1.0452, -0.0659,  1.1369,  ..., -0.3607, -0.6279, -1.3153],\n",
            "         [ 1.1666, -0.3921,  1.2231,  ..., -0.2553, -0.6792, -1.5105],\n",
            "         ...,\n",
            "         [ 1.0626, -0.1398,  1.3466,  ..., -0.1558, -0.6210, -1.4081],\n",
            "         [ 1.0060, -0.1157,  1.3783,  ..., -0.1346, -0.5621, -1.2915],\n",
            "         [ 1.0879, -0.1653,  1.5674,  ..., -0.0407, -0.7435, -1.3342]]],\n",
            "       device='cuda:0')\n",
            "diff loss tensor(1.5934, device='cuda:0')\n",
            "diff loss clipped tensor(1.5934, device='cuda:0')\n",
            "diff losses noise tensor([[[-0.1529,  1.3786,  0.3595,  ..., -0.0942, -0.5013,  0.6624],\n",
            "         [ 0.4118, -0.4768, -0.1057,  ...,  1.1707,  0.8171, -0.0889],\n",
            "         [ 1.4832,  1.3385,  0.4857,  ..., -2.4468,  0.7568,  0.1433],\n",
            "         ...,\n",
            "         [ 0.0309, -0.6703, -0.0617,  ..., -1.7432, -0.7259, -0.0266],\n",
            "         [-0.1547, -0.6383, -0.5189,  ...,  0.9553,  0.6544,  2.0536],\n",
            "         [ 1.9089, -0.2287, -0.7755,  ...,  1.0700, -0.7374, -0.8164]],\n",
            "\n",
            "        [[ 0.1285, -0.0642, -1.2806,  ..., -0.6987,  0.8473,  0.5239],\n",
            "         [ 1.7001, -0.0849, -2.3393,  ...,  0.3532,  0.1980,  0.3827],\n",
            "         [-1.3566, -0.7576,  0.4964,  ..., -0.4501, -0.3590, -1.6819],\n",
            "         ...,\n",
            "         [ 1.0575, -0.6727, -0.1869,  ...,  1.2763,  0.4393, -1.7341],\n",
            "         [ 0.3986, -0.8814,  0.7101,  ..., -1.9654, -0.7860, -2.3600],\n",
            "         [ 2.2159, -0.3485, -0.6892,  ...,  0.8600, -0.4963, -0.0833]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.6454, -0.1331,  0.9702,  ...,  0.0488, -0.5572, -0.7219],\n",
            "         [ 0.7028, -0.2627,  1.0039,  ...,  0.0782, -0.5689, -0.8138],\n",
            "         [ 0.6279, -0.3101,  1.0501,  ...,  0.1451, -0.5347, -0.7053],\n",
            "         ...,\n",
            "         [ 0.4843, -0.1816,  1.1174,  ...,  0.0768, -0.6489, -0.7629],\n",
            "         [ 0.5360, -0.0320,  1.0987,  ...,  0.2028, -0.5702, -0.8432],\n",
            "         [ 0.4364, -0.2350,  1.0993,  ...,  0.0434, -0.5688, -0.7898]],\n",
            "\n",
            "        [[ 0.0690, -0.3646,  0.7467,  ...,  0.0502, -0.3894, -0.4394],\n",
            "         [-0.0870, -0.3095,  0.9801,  ..., -0.0117, -0.2798, -0.2185],\n",
            "         [ 0.2302, -0.2890,  0.9224,  ...,  0.0038, -0.4546, -0.5343],\n",
            "         ...,\n",
            "         [ 0.2914, -0.3347,  1.0066,  ..., -0.1054, -0.5568, -0.5026],\n",
            "         [ 0.2514, -0.4567,  1.0867,  ..., -0.1258, -0.5731, -0.4974],\n",
            "         [ 0.2529, -0.4669,  1.0970,  ..., -0.1802, -0.6145, -0.4874]]],\n",
            "       device='cuda:0')\n",
            "diff loss tensor(1.7425, device='cuda:0')\n",
            "diff loss clipped tensor(1.7425, device='cuda:0')\n",
            "diff losses noise tensor([[[-1.3340, -0.3282,  0.2519,  ..., -0.0548, -1.2384, -0.8832],\n",
            "         [ 0.0053,  1.0259,  0.7813,  ..., -0.2520,  0.0535,  0.1161],\n",
            "         [ 0.5183, -0.1427, -0.5610,  ...,  0.7144, -0.7260,  0.1077],\n",
            "         ...,\n",
            "         [-0.7658, -0.0097, -2.5860,  ..., -0.3604, -1.0659,  0.2178],\n",
            "         [ 2.0313, -1.1041, -0.3630,  ...,  2.7540, -0.1010,  0.8317],\n",
            "         [-0.0161,  0.0635,  0.4915,  ...,  0.3639, -0.1719, -1.5575]],\n",
            "\n",
            "        [[-1.6667,  0.3647,  0.2020,  ...,  0.0388, -0.2726, -0.6605],\n",
            "         [ 0.8032,  0.2898,  0.8880,  ..., -0.0134,  1.3884,  0.9595],\n",
            "         [ 2.2110,  0.0257,  0.5225,  ..., -2.2513, -0.4336, -0.2609],\n",
            "         ...,\n",
            "         [-0.0989, -0.3443, -0.6018,  ...,  0.1327,  0.5203, -1.3404],\n",
            "         [ 1.1947, -0.4665, -0.9960,  ...,  0.3576, -0.5961,  0.0381],\n",
            "         [-0.3337, -0.0366, -1.0328,  ...,  0.9719, -1.9612, -0.3409]]],\n",
            "       device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.9011, -0.1277,  1.3425,  ..., -0.0593, -0.5897, -1.0298],\n",
            "         [ 0.8831, -0.0548,  1.2323,  ..., -0.0284, -0.5758, -1.0793],\n",
            "         [ 0.7499, -0.2357,  1.1893,  ...,  0.0242, -0.6574, -1.0974],\n",
            "         ...,\n",
            "         [ 0.5475, -0.1065,  1.2467,  ..., -0.1038, -0.6654, -0.9680],\n",
            "         [ 0.6568, -0.0923,  1.1319,  ..., -0.0784, -0.7721, -1.0633],\n",
            "         [ 0.6889,  0.0460,  1.1288,  ...,  0.0250, -0.7446, -0.8874]],\n",
            "\n",
            "        [[ 0.4490, -0.3796,  0.9450,  ..., -0.2368, -0.6067, -0.7107],\n",
            "         [ 0.4406, -0.2858,  0.9177,  ..., -0.0474, -0.4903, -0.7126],\n",
            "         [ 0.4683, -0.3838,  0.8716,  ..., -0.2584, -0.4803, -0.7512],\n",
            "         ...,\n",
            "         [ 0.4141, -0.3696,  0.9929,  ..., -0.1226, -0.6083, -0.6592],\n",
            "         [ 0.4315, -0.3788,  1.0360,  ..., -0.1431, -0.6288, -0.6569],\n",
            "         [ 0.3661, -0.2759,  1.0856,  ..., -0.0019, -0.6316, -0.6224]]],\n",
            "       device='cuda:0')\n",
            "diff loss tensor(1.9879, device='cuda:0')\n",
            "diff loss clipped tensor(1.9879, device='cuda:0')\n",
            "diff losses noise tensor([[[ 8.7270e-02,  6.3917e-01,  6.2149e-01,  ..., -1.5991e+00,\n",
            "          -4.1385e-01,  1.1855e-01],\n",
            "         [ 8.2571e-03,  6.1671e-02,  7.5866e-01,  ..., -2.2635e-01,\n",
            "           3.1987e-01,  1.0906e+00],\n",
            "         [-1.5355e-02,  2.1861e+00, -2.8939e-01,  ..., -5.7728e-01,\n",
            "           1.4440e+00, -1.1650e+00],\n",
            "         ...,\n",
            "         [-1.1746e+00,  1.5869e+00,  2.9258e-02,  ..., -2.3325e-03,\n",
            "           6.8641e-01, -1.3563e+00],\n",
            "         [ 1.9190e+00,  6.5840e-01, -9.7266e-01,  ..., -8.6182e-01,\n",
            "           1.1986e+00, -2.7311e-01],\n",
            "         [-5.9780e-01, -7.4995e-01, -3.8486e-01,  ..., -8.4576e-01,\n",
            "          -3.6852e-01, -4.7585e-01]],\n",
            "\n",
            "        [[ 4.2559e-02, -1.4341e+00,  1.8519e-01,  ..., -7.6820e-01,\n",
            "           6.2943e-01, -4.9718e-01],\n",
            "         [-8.9505e-01, -6.1520e-01, -1.0784e+00,  ...,  1.9374e+00,\n",
            "          -1.2591e-01, -1.6957e-01],\n",
            "         [ 6.3282e-01,  5.3007e-02,  1.8046e+00,  ...,  2.1314e+00,\n",
            "           1.7050e+00, -2.4722e-02],\n",
            "         ...,\n",
            "         [ 1.1700e+00, -1.3297e+00, -2.9897e-02,  ..., -7.7322e-01,\n",
            "          -9.1757e-01,  5.5359e-01],\n",
            "         [ 9.3327e-01, -8.6814e-01, -1.6991e-02,  ...,  9.6130e-01,\n",
            "           8.6716e-01,  1.6315e+00],\n",
            "         [ 7.2993e-02,  2.5673e+00,  1.1203e+00,  ..., -1.0050e+00,\n",
            "          -1.0040e+00, -9.4370e-01]]], device='cuda:0')\n",
            "diff losses pred noise tensor([[[ 0.7111, -0.1878,  1.1739,  ..., -0.0949, -0.5676, -0.8939],\n",
            "         [ 0.6301, -0.1462,  1.1557,  ..., -0.1990, -0.5812, -1.0070],\n",
            "         [ 0.6351, -0.2334,  1.1001,  ..., -0.1380, -0.5813, -0.8977],\n",
            "         ...,\n",
            "         [ 0.6503, -0.0958,  1.3425,  ..., -0.2893, -0.4501, -0.9111],\n",
            "         [ 0.5696, -0.1223,  1.1932,  ..., -0.2585, -0.4524, -0.8401],\n",
            "         [ 0.5169, -0.1466,  1.1930,  ..., -0.1062, -0.5453, -0.8761]],\n",
            "\n",
            "        [[ 0.2962, -0.3618,  0.9879,  ..., -0.3922, -0.7579, -0.7692],\n",
            "         [ 0.2189, -0.4988,  1.0460,  ..., -0.3459, -0.5465, -0.6257],\n",
            "         [ 0.3369, -0.5231,  1.0013,  ..., -0.4384, -0.5300, -0.7512],\n",
            "         ...,\n",
            "         [ 0.4436, -0.1918,  1.0548,  ..., -0.2090, -0.3798, -0.8583],\n",
            "         [ 0.5499, -0.0861,  1.2922,  ..., -0.2933, -0.3100, -0.7313],\n",
            "         [ 0.7197, -0.0528,  1.0821,  ..., -0.1587, -0.4139, -0.7597]]],\n",
            "       device='cuda:0')\n",
            "diff loss tensor(1.9493, device='cuda:0')\n",
            "diff loss clipped tensor(1.9493, device='cuda:0')\n",
            "Epoch 2, Train Loss: 7.8016, Val Loss: 8.7411\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}