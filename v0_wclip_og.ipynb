{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "k-OWRYMLzzG0",
        "lCVCpLwsz2ZY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## pip installs"
      ],
      "metadata": {
        "id": "k-OWRYMLzzG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Levenshtein\n",
        "!pip install einops\n",
        "!pip install einops_exts\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install black\n",
        "!pip install fair-esm\n",
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOlB53XWXSmW",
        "outputId": "24f132b4-6d80-4e28-c649-60343fa7018e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Levenshtein\n",
            "  Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.8.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.25.1 rapidfuzz-3.9.6\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Collecting einops_exts\n",
            "  Downloading einops_exts-0.0.4-py3-none-any.whl.metadata (621 bytes)\n",
            "Requirement already satisfied: einops>=0.4 in /usr/local/lib/python3.10/dist-packages (from einops_exts) (0.8.0)\n",
            "Downloading einops_exts-0.0.4-py3-none-any.whl (3.9 kB)\n",
            "Installing collected packages: einops_exts\n",
            "Successfully installed einops_exts-0.0.4\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting black\n",
            "  Downloading black-24.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from black) (24.1)\n",
            "Collecting pathspec>=0.9.0 (from black)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black) (4.2.2)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black) (4.12.2)\n",
            "Downloading black-24.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: pathspec, mypy-extensions, black\n",
            "Successfully installed black-24.8.0 mypy-extensions-1.0.0 pathspec-0.12.1\n",
            "Collecting fair-esm\n",
            "  Downloading fair_esm-2.0.0-py3-none-any.whl.metadata (37 kB)\n",
            "Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fair-esm\n",
            "Successfully installed fair-esm-2.0.0\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.17.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.12.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading wandb-0.17.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.12.0-py2.py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.12.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataset"
      ],
      "metadata": {
        "id": "lCVCpLwsz2ZY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYIaRxvBMU0G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import re\n",
        "import esm\n",
        "from einops import rearrange, repeat\n",
        "import math\n",
        "import numpy as np\n",
        "from torch import einsum\n",
        "import wandb\n",
        "wandb.login()\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Programmable Biology Group/Srikar/Code/proteins/flamingo-diffusion/data_dump/old_dat/')\n",
        "\n",
        "# ESM Model Setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "batch_converter = alphabet.get_batch_converter()\n",
        "esm_model = esm_model.to(device)\n",
        "esm_model.eval()\n",
        "for param in esm_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Data Preprocessing\n",
        "def preprocess_snp_data(file_path):\n",
        "    snp_df = pd.read_csv(file_path)\n",
        "\n",
        "    def transform_energy_scores(energy_scores):\n",
        "        transformed_scores = []\n",
        "        for score in energy_scores:\n",
        "            score = re.sub(r'[\\s\\n]+', ',', score)\n",
        "            score = re.sub(r'\\[\\s*,', '[', score)\n",
        "            score = re.sub(r'^[\\s,]+', '', score)\n",
        "            transformed_scores.append(score)\n",
        "        return transformed_scores\n",
        "\n",
        "    snp_df['energy_scores'] = transform_energy_scores(snp_df['energy_scores'])\n",
        "    snp_df['energy_scores_lengths'] = snp_df['energy_scores'].apply(\n",
        "        lambda x: x.count(',') + 1 - (1 if x.startswith(',') else 0)\n",
        "    )\n",
        "\n",
        "    snp_df['peptide_source_RCSB_lengths'] = snp_df['peptide_source_RCSB'].apply(len)\n",
        "    snp_df['protein_RCSB_lengths'] = snp_df['protein_RCSB'].apply(len)\n",
        "    snp_df['protein_derived_seq_length'] = snp_df['protein_derived_sequence'].apply(len)\n",
        "    snp_df['peptide_derived_seq_length'] = snp_df['peptide_derived_sequence'].apply(len)\n",
        "\n",
        "    return snp_df\n",
        "\n",
        "def filter_datasets(dataset):\n",
        "    return dataset[dataset['protein_RCSB'] != dataset['peptide_source_RCSB']]\n",
        "\n",
        "# Dataset Class\n",
        "class ProteinInteractionDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = dataframe\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        peptide_seq = row['peptide_derived_sequence']\n",
        "        protein_seq = row['protein_derived_sequence']\n",
        "        energy_scores = row['energy_scores']\n",
        "\n",
        "        energy_scores = re.findall(r'-?\\d+\\.?\\d*(?:e[-+]?\\d+)?', energy_scores)\n",
        "        energy_scores = [float(score) for score in energy_scores]\n",
        "        energy_scores = self.one_hot_encode_energy_scores(energy_scores)\n",
        "\n",
        "        # Convert energy scores to tensor\n",
        "        energy_scores = torch.tensor(energy_scores, dtype=torch.float32)\n",
        "\n",
        "        return energy_scores, protein_seq, peptide_seq\n",
        "\n",
        "    @staticmethod\n",
        "    def one_hot_encode_energy_scores(scores):\n",
        "        return [1 if score <= -1 else 0 for score in scores]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model"
      ],
      "metadata": {
        "id": "b5j2iJtxz8rB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ESM Encoder-Decoder (reduce latent to 64 as paper says its easier to diffuse on)\n",
        "class RefinedESMEncoderDecoder(nn.Module):\n",
        "    def __init__(self, esm_dim=1280, latent_dim=64):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(esm_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, latent_dim)\n",
        "        )\n",
        "        self.decoder = nn.TransformerDecoder(\n",
        "            nn.TransformerDecoderLayer(d_model=latent_dim, nhead=8),\n",
        "            num_layers=3\n",
        "        )\n",
        "        self.final_layer = nn.Linear(latent_dim, 21)  # 20 amino acids + unknown\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent = torch.tanh(self.encoder(x))\n",
        "        decoded = self.decoder(latent, latent)\n",
        "        return self.final_layer(decoded)\n",
        "\n",
        "# CLIP Model with classifier free guidance schedule (90/10)\n",
        "class CLIPModel(nn.Module):\n",
        "    def __init__(self, embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.antibody_encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=1280, nhead=8),\n",
        "            num_layers=3\n",
        "        )\n",
        "        self.protein_encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=1280, nhead=8),\n",
        "            num_layers=3\n",
        "        )\n",
        "        self.project_antibody = nn.Linear(1280, embed_dim)\n",
        "        self.project_protein = nn.Linear(1280, embed_dim)\n",
        "\n",
        "    def forward(self, antibody_emb, protein_emb):\n",
        "        antibody_vec = self.antibody_encoder(antibody_emb)\n",
        "        protein_vec = self.protein_encoder(protein_emb)\n",
        "        return F.normalize(self.project_antibody(antibody_vec[:, 0]), dim=-1), \\\n",
        "               F.normalize(self.project_protein(protein_vec[:, 0]), dim=-1)\n",
        "\n",
        "# One hot encoding of antigen sequence + Binary motif (epitope) representation\n",
        "class RefinedRepresentation(nn.Module):\n",
        "    def __init__(self, seq_len):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def forward(self, sequence, energy_scores):\n",
        "        # One-hot encoding\n",
        "        one_hot = F.one_hot(sequence, num_classes=21)\n",
        "\n",
        "        # Binary motif channel\n",
        "        motif_channel = (energy_scores <= -1).float().unsqueeze(-1)\n",
        "\n",
        "        # Combine representations\n",
        "        combined = torch.cat([one_hot, motif_channel], dim=-1)\n",
        "        return combined\n",
        "\n",
        "# Updated Denoiser Model\n",
        "class RefinedDenoiser(nn.Module):\n",
        "    def __init__(self, latent_dim, protein_dim, clip_dim):\n",
        "        super().__init__()\n",
        "        self.protein_binder_transformer = nn.TransformerEncoderLayer(d_model=latent_dim, nhead=8)\n",
        "        self.target_protein_transformer = nn.TransformerEncoderLayer(d_model=protein_dim, nhead=8)\n",
        "        self.cross_attention = nn.MultiheadAttention(embed_dim=latent_dim, num_heads=8)\n",
        "        self.final_layer = nn.Linear(latent_dim, latent_dim)\n",
        "\n",
        "    def forward(self, x, protein_emb, clip_emb, motif_emb, t, use_classifier_free=False):\n",
        "        if use_classifier_free:\n",
        "            # For unconditional generation, set conditioning inputs to zero\n",
        "            protein_emb = torch.zeros_like(protein_emb)\n",
        "            clip_emb = torch.zeros_like(clip_emb)\n",
        "            motif_emb = torch.zeros_like(motif_emb)\n",
        "\n",
        "        x = self.protein_binder_transformer(x)\n",
        "        protein_emb = self.target_protein_transformer(protein_emb)\n",
        "        x, _ = self.cross_attention(x, protein_emb, protein_emb)\n",
        "        x = x + clip_emb + motif_emb # esm reduced + clip + onehot + binary motif (antigen represention)\n",
        "        return self.final_layer(x)\n",
        "\n",
        "# Updated LatentDiffusion Model\n",
        "class RefinedLatentDiffusion(nn.Module):\n",
        "    def __init__(self, esm_model, num_steps, latent_dim, protein_dim, clip_dim, device):\n",
        "        super().__init__()\n",
        "        self.esm_model = esm_model\n",
        "        self.num_steps = num_steps\n",
        "        self.latent_dim = latent_dim\n",
        "        self.protein_dim = protein_dim\n",
        "        self.clip_dim = clip_dim\n",
        "        self.device = device\n",
        "\n",
        "        self.esm_encoder_decoder = RefinedESMEncoderDecoder(esm_dim=1280, latent_dim=latent_dim)\n",
        "        self.refined_representation = RefinedRepresentation(seq_len=1000)  # Adjust seq_len as needed\n",
        "        self.clip_model = CLIPModel(embed_dim=clip_dim)\n",
        "        self.denoiser = RefinedDenoiser(latent_dim=latent_dim, protein_dim=protein_dim, clip_dim=clip_dim)\n",
        "\n",
        "        # Define beta schedule\n",
        "        self.beta = torch.linspace(1e-4, 0.02, num_steps).to(device)\n",
        "        self.alpha = 1 - self.beta\n",
        "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
        "        self.sqrt_alpha_bar = torch.sqrt(self.alpha_bar)\n",
        "        self.sqrt_one_minus_alpha_bar = torch.sqrt(1 - self.alpha_bar)\n",
        "\n",
        "    def q_sample(self, x0, t, noise=None):\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x0).to(self.device)\n",
        "        return (\n",
        "            self.sqrt_alpha_bar[t, None, None] * x0 +\n",
        "            self.sqrt_one_minus_alpha_bar[t, None, None] * noise\n",
        "        )\n",
        "\n",
        "    def p_losses(self, x0, protein_emb, clip_emb, motif_emb, t, target_seq, noise=None):\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x0).to(self.device)\n",
        "\n",
        "        x_noisy = self.q_sample(x0, t, noise=noise)\n",
        "\n",
        "        # Classifier-free guidance: 10% of the time, use unconditional generation\n",
        "        use_classifier_free = random.random() < 0.1\n",
        "        predicted_noise = self.denoiser(x_noisy, protein_emb, clip_emb, motif_emb, t, use_classifier_free)\n",
        "\n",
        "        loss = F.mse_loss(predicted_noise, noise)\n",
        "\n",
        "        # CLIP loss (only when not using classifier-free guidance)\n",
        "        if not use_classifier_free:\n",
        "            binder_clip, target_clip = self.clip_model(x0, protein_emb)\n",
        "            clip_loss = -torch.sum(binder_clip * target_clip, dim=-1).mean()\n",
        "        else:\n",
        "            clip_loss = torch.tensor(0.0).to(self.device)\n",
        "\n",
        "        # Decoder loss\n",
        "        decoded_seq = self.esm_encoder_decoder(x0)\n",
        "        ce_loss = F.cross_entropy(decoded_seq.view(-1, decoded_seq.size(-1)), target_seq.view(-1))\n",
        "\n",
        "        total_loss = loss + 0.1 * clip_loss + ce_loss\n",
        "        return total_loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def p_sample(self, x, protein_emb, clip_emb, motif_emb, t, guidance_scale=3.0):\n",
        "        betas_t = self.beta[t][:, None, None]\n",
        "        sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alpha_bar[t][:, None, None]\n",
        "        sqrt_recip_alphas_t = torch.sqrt(1.0 / self.alpha[t])[:, None, None]\n",
        "\n",
        "        # Generate both conditional and unconditional predictions\n",
        "        noise_pred_cond = self.denoiser(x, protein_emb, clip_emb, motif_emb, t, use_classifier_free=False)\n",
        "        noise_pred_uncond = self.denoiser(x, protein_emb, clip_emb, motif_emb, t, use_classifier_free=True)\n",
        "\n",
        "        # Apply classifier-free guidance\n",
        "        noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_cond - noise_pred_uncond)\n",
        "\n",
        "        model_mean = sqrt_recip_alphas_t * (\n",
        "            x - betas_t * noise_pred / sqrt_one_minus_alphas_cumprod_t\n",
        "        )\n",
        "\n",
        "        if t[0] > 0:\n",
        "            noise = torch.randn_like(x).to(self.device)\n",
        "            return model_mean + torch.sqrt(betas_t) * noise\n",
        "        else:\n",
        "            return model_mean\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, num_samples, sequence_length, protein_emb, clip_emb, motif_emb, guidance_scale=3.0):\n",
        "        device = next(self.parameters()).device\n",
        "        shape = (num_samples, sequence_length, self.latent_dim)\n",
        "        x = torch.randn(shape, device=device)\n",
        "        protein_emb = protein_emb.to(device)\n",
        "        clip_emb = clip_emb.to(device)\n",
        "        motif_emb = motif_emb.to(device)\n",
        "\n",
        "        for t in reversed(range(0, self.num_steps)):\n",
        "            t_batch = torch.full((num_samples,), t, device=device, dtype=torch.long)\n",
        "            x = self.p_sample(x, protein_emb, clip_emb, motif_emb, t_batch, guidance_scale)\n",
        "\n",
        "        return x\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample_without_guidance(self, num_samples, sequence_length):\n",
        "        device = next(self.parameters()).device\n",
        "        shape = (num_samples, sequence_length, self.latent_dim)\n",
        "        x = torch.randn(shape, device=device)\n",
        "\n",
        "        for t in reversed(range(0, self.num_steps)):\n",
        "            t_batch = torch.full((num_samples,), t, device=device, dtype=torch.long)\n",
        "            betas_t = self.beta[t][:, None, None]\n",
        "            sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alpha_bar[t][:, None, None]\n",
        "            sqrt_recip_alphas_t = torch.sqrt(1.0 / self.alpha[t])[:, None, None]\n",
        "\n",
        "            # Unconditional prediction\n",
        "            noise_pred = self.denoiser(x, None, None, None, t_batch, use_classifier_free=True)\n",
        "\n",
        "            model_mean = sqrt_recip_alphas_t * (\n",
        "                x - betas_t * noise_pred / sqrt_one_minus_alphas_cumprod_t\n",
        "            )\n",
        "\n",
        "            if t > 0:\n",
        "                noise = torch.randn_like(x).to(device)\n",
        "                x = model_mean + torch.sqrt(betas_t) * noise\n",
        "            else:\n",
        "                x = model_mean\n",
        "\n",
        "        return x\n",
        "\n",
        "def generate_protein_binders(model, protein_seq, motif, num_samples=1, guidance_scale=3.0):\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Generate protein embedding\n",
        "    with torch.no_grad():\n",
        "        protein_tokens = model.esm_model.encode(protein_seq)\n",
        "        protein_embedding = model.esm_model(protein_tokens.to(device), repr_layers=[33], return_contacts=False)[\"representations\"][33]\n",
        "\n",
        "    # Process motif based on input type\n",
        "    if isinstance(motif, str):\n",
        "        # Motif is a sequence\n",
        "        motif_tokens = model.esm_model.encode(motif)\n",
        "        with torch.no_grad():\n",
        "            motif_embedding = model.esm_model(motif_tokens.to(device), repr_layers=[33], return_contacts=False)[\"representations\"][33]\n",
        "        motif_repr = model.refined_representation(motif_tokens, torch.ones_like(motif_embedding[:, :, 0]))\n",
        "    elif isinstance(motif, torch.Tensor):\n",
        "        # Motif is a binary tensor\n",
        "        motif_embedding = motif.float().to(device)\n",
        "        motif_repr = model.refined_representation(protein_tokens, motif_embedding)\n",
        "    else:\n",
        "        raise ValueError(\"Motif must be either a string (sequence) or a torch.Tensor (binary representation)\")\n",
        "\n",
        "    # Create refined representations\n",
        "    protein_repr = model.refined_representation(protein_tokens, torch.zeros_like(protein_embedding[:, :, 0]))\n",
        "\n",
        "    # Process through ESM encoder-decoder\n",
        "    protein_latent = model.esm_encoder_decoder.encoder(protein_embedding)\n",
        "    motif_latent = model.esm_encoder_decoder.encoder(motif_embedding)\n",
        "\n",
        "    # CLIP processing\n",
        "    protein_clip, motif_clip = model.clip_model(protein_repr, motif_repr)\n",
        "\n",
        "    # Sample from the model\n",
        "    latent_samples = model.sample(num_samples, protein_latent.shape[1], protein_latent, protein_clip, motif_latent, guidance_scale)\n",
        "\n",
        "    # Decode the latent samples to amino acid sequences\n",
        "    generated_sequences = model.esm_encoder_decoder.decoder(latent_samples)\n",
        "\n",
        "    return generated_sequences\n",
        "\n",
        "def generate_protein_binders_without_guidance(model, sequence_length, num_samples=1):\n",
        "    # Sample from the model without guidance\n",
        "    latent_samples = model.sample_without_guidance(num_samples, sequence_length)\n",
        "\n",
        "    # Decode the latent samples to amino acid sequences\n",
        "    generated_sequences = model.esm_encoder_decoder.decoder(latent_samples)\n",
        "\n",
        "    return generated_sequences\n",
        "\n",
        "\n",
        "\n",
        "def train(model, dataloader, optimizer, num_epochs, device):\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch in dataloader:\n",
        "            energy_scores, protein_seq, peptide_seq = batch\n",
        "            energy_scores = energy_scores.to(device)\n",
        "\n",
        "            # Generate ESM embeddings\n",
        "            with torch.no_grad():\n",
        "                protein_embedding = model.esm_model(protein_seq, repr_layers=[33], return_contacts=False)[\"representations\"][33]\n",
        "                peptide_embedding = model.esm_model(peptide_seq, repr_layers=[33], return_contacts=False)[\"representations\"][33]\n",
        "\n",
        "            # Create refined representations\n",
        "            protein_repr = model.refined_representation(protein_seq, energy_scores)\n",
        "            peptide_repr = model.refined_representation(peptide_seq, torch.zeros_like(energy_scores))\n",
        "\n",
        "            # Process through ESM encoder-decoder\n",
        "            protein_latent = model.esm_encoder_decoder.encoder(protein_embedding)\n",
        "            peptide_latent = model.esm_encoder_decoder.encoder(peptide_embedding)\n",
        "\n",
        "            # Motif embedding\n",
        "            motif_emb = (energy_scores <= -1).float().unsqueeze(-1)\n",
        "\n",
        "            # Create positive and negative pairs for CLIP\n",
        "            positive_pairs = (protein_repr, peptide_repr)\n",
        "            negative_pairs = create_negative_pairs(protein_repr, peptide_repr)\n",
        "\n",
        "            # CLIP processing\n",
        "            clip_loss = model.clip_model(positive_pairs, negative_pairs)\n",
        "\n",
        "            # Diffusion process\n",
        "            t = torch.randint(0, model.num_steps, (protein_embedding.shape[0],), device=device).long()\n",
        "            diff_loss = model.p_losses(peptide_latent, protein_latent, protein_clip, motif_emb, t, peptide_seq)\n",
        "\n",
        "            # Total loss\n",
        "            loss = diff_loss + clip_loss\n",
        "\n",
        "            # Backpropagation and optimization steps\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Logging\n",
        "            wandb.log({\"batch_loss\": loss.item(), \"diff_loss\": diff_loss.item(), \"clip_loss\": clip_loss.item()})\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
        "\n",
        "def create_negative_pairs(protein_repr, peptide_repr):\n",
        "    # Shuffle the peptide representations to create negative pairs\n",
        "    neg_peptide_repr = peptide_repr[torch.randperm(peptide_repr.size(0))]\n",
        "    return (protein_repr, neg_peptide_repr)\n",
        "\n",
        "def main():\n",
        "    # Load and preprocess data\n",
        "    train_snp = preprocess_snp_data('training_dataset.csv')\n",
        "    val_snp = preprocess_snp_data('validation_dataset.csv')\n",
        "    test_snp = preprocess_snp_data('testing_dataset.csv')\n",
        "\n",
        "    train_snp = filter_datasets(train_snp)\n",
        "    val_snp = filter_datasets(val_snp)\n",
        "    test_snp = filter_datasets(test_snp)\n",
        "\n",
        "    # Calculate max_length\n",
        "    all_seqs = pd.concat([\n",
        "        train_snp['peptide_derived_sequence'], train_snp['protein_derived_sequence'],\n",
        "        val_snp['peptide_derived_sequence'], val_snp['protein_derived_sequence'],\n",
        "        test_snp['peptide_derived_sequence'], test_snp['protein_derived_sequence']\n",
        "    ])\n",
        "    max_length = max(len(seq) for seq in all_seqs)\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = ProteinInteractionDataset(train_snp)\n",
        "    val_dataset = ProteinInteractionDataset(val_snp)\n",
        "    test_dataset = ProteinInteractionDataset(test_snp)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
        "\n",
        "    # Initialize LatentDiffusion model\n",
        "    latent_dim = 64\n",
        "    protein_dim = esm_model.embed_dim\n",
        "    num_steps = 1000\n",
        "    model = RefinedLatentDiffusion(esm_model, num_steps, latent_dim, protein_dim, clip_dim, device)\n",
        "    model.to(device)\n",
        "\n",
        "    # Training\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "    num_epochs = 10\n",
        "\n",
        "    train(model, train_loader, optimizer, num_epochs, device)\n",
        "\n",
        "    # Generation (dummy examples)\n",
        "    model.eval()\n",
        "\n",
        "    # Example usage of generation with guidance (sequence-based motif)\n",
        "    protein_seq = \"MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRGYVLAGG\"\n",
        "    motif_seq = \"LRSLGY\"\n",
        "    generated_binders_seq = generate_protein_binders(model, protein_seq, motif_seq, num_samples=3, guidance_scale=3.0)\n",
        "\n",
        "    print(\"Generated protein binders with guidance (sequence-based motif):\")\n",
        "    for i, seq in enumerate(generated_binders_seq):\n",
        "        print(f\"Binder {i+1}: {seq}\")\n",
        "\n",
        "    # Example usage of generation with guidance (binary motif)\n",
        "    binary_motif = torch.zeros(len(protein_seq))\n",
        "    binary_motif[30:36] = 1  # Assuming the motif is in this region\n",
        "    generated_binders_binary = generate_protein_binders(model, protein_seq, binary_motif, num_samples=3, guidance_scale=3.0)\n",
        "\n",
        "    print(\"\\nGenerated protein binders with guidance (binary motif):\")\n",
        "    for i, seq in enumerate(generated_binders_binary):\n",
        "        print(f\"Binder {i+1}: {seq}\")\n",
        "\n",
        "    # Example usage of generation without guidance\n",
        "    generated_binders_no_guidance = generate_protein_binders_without_guidance(model, sequence_length=100, num_samples=3)\n",
        "\n",
        "    print(\"\\nGenerated protein binders without guidance:\")\n",
        "    for i, seq in enumerate(generated_binders_no_guidance):\n",
        "        print(f\"Binder {i+1}: {seq}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "HbV8-2KMz-CL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
